# from utils import clean_up_text
import re

def has_complete_questions(texts, times):
    """æ£€æŸ¥æ¯æ¡è¯„è®ºæ˜¯å¦éƒ½åŒ…å«æŒ‡å®šæ•°é‡çš„å®Œæ•´è¥¿ç­ç‰™è¯­ç–‘é—®å¥ï¼ˆÂ¿...?)"""
    
    if not texts:
        return 0, f"âŒ No comments provided"
    
    # ç¡®ä¿ texts æ˜¯åˆ—è¡¨æ ¼å¼
    if isinstance(texts, str):
        comments = [texts]
    elif isinstance(texts, list):
        comments = texts
    else:
        comments = [str(texts)]
    
    # å®Œæ•´ç–‘é—®å¥çš„æ­£åˆ™æ¨¡å¼ï¼šÂ¿å¼€å¤´ï¼Œ?ç»“å°¾ï¼Œä¸­é—´ä¸åŒ…å«å…¶ä»–Â¿æˆ–?
    complete_question_pattern = r'Â¿[^Â¿?]*\?'
    
    comment_details = []
    all_match = True
    
    # æ£€æŸ¥æ¯ä¸ªè¯„è®º
    for i, comment in enumerate(comments):
        comment_text = str(comment).strip()
        
        # æŸ¥æ‰¾å®Œæ•´çš„ç–‘é—®å¥
        matches = re.findall(complete_question_pattern, comment_text, re.DOTALL)
        question_count = len(matches)
        
        # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè¦æ±‚
        matches_requirement = (question_count == times)
        if not matches_requirement:
            all_match = False
        
        # è®°å½•è¯¦æƒ…
        status = "âœ…" if matches_requirement else "âŒ"
        if matches:
            display_questions = [q[:30] + "..." if len(q) > 30 else q for q in matches[:3]]
            comment_details.append(f"Comment {i+1}: {question_count} questions {status} ({', '.join(display_questions)})")
        else:
            comment_details.append(f"Comment {i+1}: {question_count} questions {status}")
    
    detail_info = " | ".join(comment_details)
    
    # è¿”å›ç»“æœ
    if all_match:
        return 1, f"âœ… All {len(comments)} comments have exactly {times} questions: {detail_info}"
    else:
        return 0, f"âŒ Some comments do NOT have exactly {times} questions: {detail_info}"


def has_complete_exclamations(texts, min_count, max_count=None):
    """æ£€æŸ¥æ˜¯å¦åŒ…å«æŒ‡å®šæ•°é‡èŒƒå›´çš„å®Œæ•´è¥¿ç­ç‰™è¯­æ„Ÿå¹å¥
    
    ç‰¹æ®Šé€»è¾‘ï¼š
    - å¦‚æœè¦æ±‚min_count=0ï¼Œåˆ™æ²¡æœ‰æ„Ÿå¹å¥ä¸ç®—é”™è¯¯
    - å¦‚æœè¦æ±‚min_count>0ï¼Œåˆ™æ²¡æœ‰æ„Ÿå¹å¥ç®—é”™è¯¯
    """
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # å¤„ç†å•ä¸ªæ–‡æœ¬
    if isinstance(texts, str):
        text = texts
    elif isinstance(texts, list):
        text = ' '.join(texts)  # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
    else:
        text = str(texts)
    
    # å®Œæ•´æ„Ÿå¹å¥çš„æ­£åˆ™æ¨¡å¼ï¼šÂ¡å¼€å¤´ï¼Œ!ç»“å°¾
    complete_exclamation_pattern = r'Â¡[^Â¡!]*!'
    
    # æŸ¥æ‰¾å®Œæ•´çš„æ„Ÿå¹å¥
    matches = re.findall(complete_exclamation_pattern, text, re.DOTALL)
    exclamation_count = len(matches)
    
    # è®¾ç½®é»˜è®¤æœ€å¤§å€¼
    if max_count is None:
        max_count = 1000
    
    # ğŸ†• ç‰¹æ®Šé€»è¾‘ï¼šå¤„ç†"æ²¡æœ‰æ„Ÿå¹å¥"çš„æƒ…å†µ
    if exclamation_count == 0:
        if min_count == 0:
            # è¦æ±‚0ä¸ªï¼Œå®é™…0ä¸ª â†’ æ­£ç¡®
            return 1, f"âœ… Found 0 complete exclamations as required (expected: {min_count}-{max_count}). No exclamations needed."
        else:
            # è¦æ±‚>0ä¸ªï¼Œå®é™…0ä¸ª â†’ é”™è¯¯
            return 0, f"âŒ No complete exclamations found but {min_count}-{max_count} required. Task requires exclamatory sentences with Â¡...! format."
    
    # æ£€æŸ¥æ˜¯å¦åœ¨èŒƒå›´å†…
    meets_requirement = min_count <= exclamation_count <= max_count
    
    # æ˜¾ç¤ºæ‰¾åˆ°çš„æ„Ÿå¹å¥ï¼ˆå‰3ä¸ªï¼‰
    display_exclamations = [exc[:30] + "..." if len(exc) > 30 else exc for exc in matches[:3]]
    exclamation_info = f"Found: {', '.join(display_exclamations)}"
    if len(matches) > 3:
        exclamation_info += f" (and {len(matches)-3} more)"
    
    # è¿”å›ç»“æœ
    if meets_requirement:
        return 1, f"âœ… Found {exclamation_count} complete exclamations (required: {min_count}-{max_count}). {exclamation_info}"
    else:
        if exclamation_count < min_count:
            return 0, f"âŒ Found only {exclamation_count} complete exclamations, need at least {min_count}. {exclamation_info}"
        else:
            return 0, f"âŒ Found {exclamation_count} complete exclamations, exceeds maximum {max_count}. {exclamation_info}"



def has_spanish_word_count(texts, min_count, max_count):
    """æ£€æŸ¥æ¯æ¡è¥¿ç­ç‰™è¯­è¯„è®ºçš„å•è¯æ•°é‡æ˜¯å¦éƒ½åœ¨æŒ‡å®šèŒƒå›´å†…"""
    import re
    
    if not texts:
        return 0, f"âŒ No comments provided"
    
    # ç¡®ä¿ texts æ˜¯åˆ—è¡¨æ ¼å¼
    if isinstance(texts, str):
        comments = [texts]
    elif isinstance(texts, list):
        comments = texts
    else:
        comments = [str(texts)]
    
    # è°ƒè¯•ä¿¡æ¯
    print(f"Debug - æ”¶åˆ° {len(comments)} æ¡è¯„è®º")
    print(f"Debug - èŒƒå›´å‚æ•°: min_count={min_count}, max_count={max_count}")
    
    comment_details = []
    all_in_range = True
    
    # ç¡®ä¿èŒƒå›´å‚æ•°æ˜¯æ•°å­—ç±»å‹
    try:
        min_count_float = float(min_count)
        max_count_float = float(max_count)
    except (ValueError, TypeError):
        return 0, f"âŒ Invalid range parameters: min_count={min_count}, max_count={max_count}"
    
    for i, comment in enumerate(comments):
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†
        comment_text = str(comment).strip()
        
        # ğŸ”§ æœ€ç›´æ¥çš„è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨åŸå§‹æ­£åˆ™è¡¨è¾¾å¼ï¼Œç„¶åè°ƒæ•´ "Li Hua" çš„è®¡æ•°
        # 1. æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
        comment_text = re.sub(r'\s+', ' ', comment_text)
        
        # 2. ä½¿ç”¨åŸå§‹çš„è¥¿ç­ç‰™è¯­å•è¯æ­£åˆ™æ¨¡å¼
        spanish_word_pattern = r'\b[a-zA-ZÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼ÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+\b'
        words = re.findall(spanish_word_pattern, comment_text)
        
        # 3. è®¡ç®— "Li Hua" çš„å‡ºç°æ¬¡æ•°å¹¶è°ƒæ•´æ€»æ•°
        li_count = len([word for word in words if word.lower() == 'li'])
        hua_count = len([word for word in words if word.lower() == 'hua'])
        
        # å‡è®¾æ¯ä¸ª "Li" éƒ½ç´§è·Ÿä¸€ä¸ª "Hua"ï¼Œæ‰€ä»¥ "Li Hua" çš„æ¬¡æ•°æ˜¯ min(li_count, hua_count)
        li_hua_pairs = min(li_count, hua_count)
        
        # è°ƒæ•´è¯æ•°ï¼šå‡å»å¤šç®—çš„ "Li Hua" æ¬¡æ•°
        adjusted_word_count = len(words) - li_hua_pairs
        
        print(f"Debug - è¯„è®º {i+1}:")
        print(f"Debug - åŸå§‹è¯æ•°: {len(words)}")
        print(f"Debug - Li å‡ºç°æ¬¡æ•°: {li_count}")
        print(f"Debug - Hua å‡ºç°æ¬¡æ•°: {hua_count}")
        print(f"Debug - Li Hua å¯¹æ•°: {li_hua_pairs}")
        print(f"Debug - è°ƒæ•´åè¯æ•°: {adjusted_word_count}")
        
        word_count = adjusted_word_count
        
        # æ£€æŸ¥æ˜¯å¦åœ¨èŒƒå›´å†…
        in_range = min_count_float <= word_count <= max_count_float
        if not in_range:
            all_in_range = False
        
        # è®°å½•è¯¦æƒ…
        status = "âœ…" if in_range else "âŒ"
        comment_details.append(f"Comment {i+1}: {word_count} words {status}")
    
    detail_info = " | ".join(comment_details)
    
    # æ˜¾ç¤ºèŒƒå›´
    min_display = int(round(min_count_float))
    max_display = int(round(max_count_float))
    
    # è¿”å›ç»“æœ
    if all_in_range:
        return 1, f"âœ… All {len(comments)} comments within range [{min_display}, {max_display}]: {detail_info}"
    else:
        return 0, f"âŒ Some of {len(comments)} comments NOT within range [{min_display}, {max_display}]: {detail_info}"





import re

def has_spanish_accent_count(texts, *args):
    """æ£€æŸ¥æ–‡æœ¬ä¸­è¥¿ç­ç‰™è¯­é‡éŸ³ç¬¦å·çš„æ•°é‡æ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…"""
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    if not texts:
        return 0, f"âŒ No texts provided"
    
    # ğŸ”§ ä¿®å¤ï¼šæ›´å¥å£®çš„å‚æ•°è§£æ
    print(f"Debug - åŸå§‹å‚æ•°: {args}")
    
    if len(args) == 1:
        param = args[0]
        if isinstance(param, (list, tuple)) and len(param) >= 2:
            min_count, max_count = param[0], param[1]
        elif isinstance(param, (list, tuple)) and len(param) == 1:
            min_count = max_count = param[0]
        else:
            min_count = max_count = param
    elif len(args) == 2:
        min_count, max_count = args
    else:
        return 0, f"âŒ Invalid number of arguments: {len(args)}"
    
    # ç¡®ä¿å‚æ•°æ˜¯æ•´æ•°
    try:
        min_count = int(min_count)
        max_count = int(max_count)
    except (ValueError, TypeError) as e:
        return 0, f"âŒ Invalid count parameters: min_count={min_count}, max_count={max_count}, error={e}"
    
    print(f"Debug - è§£æåå‚æ•°: min_count={min_count}, max_count={max_count}")
    
    cleaned_up_texts = [clean_up_text(str(text)) for text in texts]
    
    def count_spanish_accent_marks(texts_list):
        """ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­è¥¿ç­ç‰™è¯­é‡éŸ³ç¬¦å·çš„æ•°é‡"""
        # è¥¿ç­ç‰™è¯­é‡éŸ³ç¬¦å·å­—ç¬¦
        spanish_accented_chars = [
            # é‡éŸ³ç¬¦å·ï¼ˆacute accentï¼‰
            'Ã¡', 'Ã©', 'Ã­', 'Ã³', 'Ãº',  # å°å†™å¸¦é‡éŸ³çš„å…ƒéŸ³
            'Ã', 'Ã‰', 'Ã', 'Ã“', 'Ãš',  # å¤§å†™å¸¦é‡éŸ³çš„å…ƒéŸ³
            # åˆ†éŸ³ç¬¦ï¼ˆdiaeresisï¼‰
            'Ã¼', 'Ãœ',                 # å¸¦åˆ†éŸ³ç¬¦çš„u
            # æ³¢æµªå·ï¼ˆtildeï¼‰
            'Ã±', 'Ã‘'                  # å¸¦æ³¢æµªå·çš„n
        ]
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
        combined_text = ' '.join(texts_list)
        
        # ç›´æ¥åœ¨æ•´ä¸ªæ–‡æœ¬ä¸­æŸ¥æ‰¾æ‰€æœ‰é‡éŸ³ç¬¦å·
        accent_matches = re.findall(r'[Ã¡Ã©Ã­Ã³ÃºÃ¼Ã±ÃÃ‰ÃÃ“ÃšÃœÃ‘]', combined_text)
        total_accent_count = len(accent_matches)
        
        # æŸ¥æ‰¾åŒ…å«é‡éŸ³ç¬¦å·çš„å•è¯
        words_with_accents = []
        words = re.findall(r'\b[\w\u00C0-\u017F]+\b', combined_text)
        
        for word in words:
            if any(char in spanish_accented_chars for char in word):
                words_with_accents.append(word)
        
        # ç»Ÿè®¡æ¯ç§é‡éŸ³ç¬¦å·çš„æ•°é‡
        accent_distribution = {}
        for accent in accent_matches:
            accent_distribution[accent] = accent_distribution.get(accent, 0) + 1
        
        return total_accent_count, words_with_accents, accent_matches, accent_distribution
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„é‡éŸ³ç¬¦å·
    accent_count, accented_words, accent_list, accent_dist = count_spanish_accent_marks(cleaned_up_texts)
    
    print(f"Debug - æ€»é‡éŸ³ç¬¦å·æ•°: {accent_count}")
    print(f"Debug - é‡éŸ³ç¬¦å·åˆ†å¸ƒ: {accent_dist}")
    print(f"Debug - å¸¦é‡éŸ³çš„è¯: {accented_words[:10]}")
    
    # æ„å»ºè¯¦ç»†çš„é‡éŸ³ç¬¦å·ä¿¡æ¯
    accent_detail = []
    for accent, count in accent_dist.items():
        accent_detail.append(f"{accent}Ã—{count}")
    
    # å»é‡æ˜¾ç¤ºé‡éŸ³ç¬¦å·ç±»å‹
    unique_accents = list(set(accent_list))
    accent_summary = f"[{', '.join(unique_accents)}]" if unique_accents else "[]"
    accent_breakdown = f"({', '.join(accent_detail)})" if accent_detail else "(æ— )"
    
    # é™åˆ¶æ˜¾ç¤ºçš„è¯æ±‡æ•°é‡
    display_words = accented_words[:10]
    words_info = f"{display_words}"
    if len(accented_words) > 10:
        words_info += f" (+{len(accented_words)-10} more)"
    
    # ğŸ”§ ä¿®å¤ï¼šç»Ÿä¸€çš„é€»è¾‘å¤„ç†
    if min_count == max_count:
        # ç²¾ç¡®åŒ¹é…
        required_count = min_count
        requirement_text = f"exactly {required_count}"
        
        if accent_count == required_count:
            return 1, f"âœ… Text contains exactly {required_count} spanish accent marks. Found {accent_count} accents: {accent_summary} {accent_breakdown}. Words with accents: {words_info}. Requirement met."
        elif accent_count < required_count:
            return 0, f"âŒ Text contains {accent_count} spanish accent marks (required: {requirement_text}). Found accents: {accent_summary} {accent_breakdown}. Words with accents: {words_info}. Too few accent marks."
        else:
            return 0, f"âŒ Text contains {accent_count} spanish accent marks (required: {requirement_text}). Found accents: {accent_summary} {accent_breakdown}. Words with accents: {words_info}. Too many accent marks."
    else:
        # èŒƒå›´åŒ¹é…
        requirement_text = f"{min_count}-{max_count}"
        
        if min_count <= accent_count <= max_count:
            return 1, f"âœ… Text contains {accent_count} spanish accent marks (required: {requirement_text}). Found accents: {accent_summary} {accent_breakdown}. Words with accents: {words_info}. Requirement met."
        elif accent_count < min_count:
            return 0, f"âŒ Text contains {accent_count} spanish accent marks (required: {requirement_text}). Found accents: {accent_summary} {accent_breakdown}. Words with accents: {words_info}. Too few accent marks."
        else:
            return 0, f"âŒ Text contains {accent_count} spanish accent marks (required: {requirement_text}). Found accents: {accent_summary} {accent_breakdown}. Words with accents: {words_info}. Too many accent marks."


# ğŸ”§ æµ‹è¯•å‡½æ•°
def test_function():
    test_texts = [
        "DescripciÃ³n: Oficina moderna.",
        "DescripciÃ³n: Espacio versÃ¡til."
    ]
    
    print("=== æµ‹è¯•ä¸åŒçš„è°ƒç”¨æ–¹å¼ ===")
    
    print("\n1. æµ‹è¯• [12, 12] æ ¼å¼:")
    result1 = has_spanish_accent_count(test_texts, [12, 12])
    print(f"ç»“æœ: {result1[1][:100]}...")
    
    print("\n2. æµ‹è¯• 12, 12 æ ¼å¼:")
    result2 = has_spanish_accent_count(test_texts, 12, 12)
    print(f"ç»“æœ: {result2[1][:100]}...")
    
    print("\n3. æµ‹è¯•å•ä¸ªå‚æ•° 12:")
    result3 = has_spanish_accent_count(test_texts, 12)
    print(f"ç»“æœ: {result3[1][:100]}...")

# å–æ¶ˆæ³¨é‡Šæ¥æµ‹è¯•
# test_function()



def has_correct_compound_hyphen_usage(texts, num):
    """æ£€æŸ¥æ¯ä¸ªæ–‡æœ¬ä¸­å¤åˆè¯è¿å­—ç¬¦ä½¿ç”¨æ˜¯å¦æ­£ç¡®"""
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_compound_hyphen_errors(text):
        """æ£€æŸ¥æ–‡æœ¬ä¸­çš„å¤åˆè¯è¿å­—ç¬¦é”™è¯¯"""
        
        # åº”è¯¥æœ‰è¿å­—ç¬¦ä½†ç¼ºå¤±çš„æƒ…å†µï¼ˆå¸¸è§é”™è¯¯ï¼‰
        should_have_hyphen = [
            # å›½ç±ç»„åˆ
            (r'\b(franco|hispano|sino|anglo|austro|italo|greco|germano)(aleman|americano|japones|sajon|hungaro|espaÃ±ol|romano|britanico)\b', 
             r'\1-\2'),
            # å­¦ç§‘äº¤å‰
            (r'\b(bio|geo|psico|socio|neuro|cardio|gastro)(quimica|politica|social|cultural|linguistica|vascular|intestinal)\b', 
             r'\1-\2'),
            # å½¢å®¹è¯ç»„åˆ
            (r'\b(politico|teorico|cientifico|fisico|medico|juridico)(economico|practico|tecnico|quimico|legal|social)\b', 
             r'\1-\2'),
            # å¯¹ç«‹æ¦‚å¿µ
            (r'\b(amor|causa|entrada|norte|este|bien|vida)(odio|efecto|salida|sur|oeste|mal|muerte)\b', 
             r'\1-\2'),
            # æ—¶é—´æ¦‚å¿µ
            (r'\b(pre|post|anti|pro)(guerra|moderno|fascista|democratico|revolucionario)\b', 
             r'\1-\2'),
        ]
        
        # ä¸åº”è¯¥æœ‰è¿å­—ç¬¦ä½†é”™è¯¯æ·»åŠ çš„æƒ…å†µ
        should_not_have_hyphen = [
            # å›ºå®šå¤åˆè¯
            r'\b(ferro-carril|auto-movil|super-mercado|inter-nacional|multi-media)\b',
            # åŠ¨è¯+åè¯ç»“æ„
            r'\b(lava-vajillas|abre-latas|guarda-espaldas|rasca-cielos|salva-vidas)\b',
            # æ¤ç‰©åŠ¨ç‰©å
            r'\b(gira-sol|peti-rojo|coli-flor|agua-cate)\b',
            # æ—¶é—´è¯æ±‡
            r'\b(medio-dia|media-noche|cumple-aÃ±os)\b',
        ]
        
        errors = []
        corrections = []
        
        # æ£€æŸ¥ç¼ºå¤±è¿å­—ç¬¦çš„é”™è¯¯
        for pattern, replacement in should_have_hyphen:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                error_word = match.group()
                correct_word = re.sub(pattern, replacement, error_word, flags=re.IGNORECASE)
                errors.append({
                    'type': 'missing_hyphen',
                    'error': error_word,
                    'correct': correct_word,
                    'position': match.span()
                })
        
        # æ£€æŸ¥å¤šä½™è¿å­—ç¬¦çš„é”™è¯¯
        for pattern in should_not_have_hyphen:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                error_word = match.group()
                correct_word = error_word.replace('-', '')
                errors.append({
                    'type': 'extra_hyphen',
                    'error': error_word,
                    'correct': correct_word,
                    'position': match.span()
                })
        
        return len(errors), errors
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡æœ¬
    total_errors = 0
    all_errors = []
    
    for i, text in enumerate(cleaned_up_texts):
        error_count, errors = check_compound_hyphen_errors(text)
        total_errors += error_count
        
        if errors:
            text_errors = {
                'text_index': i,
                'error_count': error_count,
                'errors': errors
            }
            all_errors.append(text_errors)
    
    # æ„å»ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
    if total_errors > num:
        error_details = []
        for text_error in all_errors:
            for error in text_error['errors']:
                if error['type'] == 'missing_hyphen':
                    error_details.append(f"'{error['error']}' â†’ '{error['correct']}'")
                else:
                    error_details.append(f"'{error['error']}' â†’ '{error['correct']}'")
        
        error_summary = "; ".join(error_details[:10])  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
        if len(error_details) > 10:
            error_summary += f" ... (+{len(error_details)-10} more errors)"
            
        return 0, f"âŒ Found {total_errors} compound word hyphen errors (allowed: {num}). Errors: {error_summary}. Does not meet the requirement."
    
    return 1, f"âœ… Compound word hyphen usage is correct. Found {total_errors} errors (allowed: {num}). Requirement met."

def has_correct_total_double_negatives(texts, min_total, max_total, debug=False):
    """æ£€æŸ¥è¥¿ç­ç‰™è¯­æ–‡æœ¬ä¸­çš„åŒé‡å¦å®šæ€»æ•°æ˜¯å¦ç¬¦åˆè¦æ±‚
    
    Args:
        texts: æ–‡æœ¬åˆ—è¡¨
        min_total: æœ€å°‘åŒé‡å¦å®šæ€»æ•°
        max_total: æœ€å¤šåŒé‡å¦å®šæ€»æ•°
        debug: æ˜¯å¦è¾“å‡ºè°ƒè¯•ä¿¡æ¯
    """
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    # ğŸ”§ å®Œæ•´çš„åŒé‡å¦å®šç»“æ„æ¨¡å¼
    correct_patterns = [
        # ==================== 1. "No es + å¦å®šå‰ç¼€è¯" ç»“æ„ ====================
        r'\bno\s+es\s+imposible\b',                                    # no es imposible
        r'\bno\s+es\s+improbable\b',                                   # no es improbable
        r'\bno\s+es\s+impensable\b',                                   # no es impensable
        r'\bno\s+es\s+increÃ­ble\b',                                    # no es increÃ­ble
        r'\bno\s+es\s+innecesario\b',                                  # no es innecesario
        r'\bno\s+es\s+inÃºtil\b',                                       # no es inÃºtil
        r'\bno\s+es\s+injusto\b',                                      # no es injusto
        r'\bno\s+es\s+incorrecto\b',                                   # no es incorrecto
        r'\bno\s+es\s+incierto\b',                                     # no es incierto
        r'\bno\s+es\s+inseguro\b',                                     # no es inseguro
        r'\bno\s+es\s+invÃ¡lido\b',                                     # no es invÃ¡lido
        r'\bno\s+es\s+inadecuado\b',                                   # no es inadecuado
        r'\bno\s+es\s+inaceptable\b',                                  # no es inaceptable
        r'\bno\s+es\s+inalcanzable\b',                                 # no es inalcanzable
        r'\bno\s+es\s+inevitable\b',                                   # no es inevitable
        r'\bno\s+es\s+inexplicable\b',                                 # no es inexplicable
        r'\bno\s+es\s+invisible\b',                                    # no es invisible
        r'\bno\s+es\s+imposible\s+que\b',                              # no es imposible que
        r'\bno\s+es\s+improbable\s+que\b',                             # no es improbable que
        
        # é€šç”¨å¦å®šå‰ç¼€æ¨¡å¼
        r'\bno\s+es\s+i[mn]\w*\b',                                     # no es + i/im/in å¼€å¤´çš„è¯
        r'\bno\s+es\s+des\w*\b',                                       # no es + des å¼€å¤´çš„è¯
        
        # ==================== 2. "No es + å½¢å®¹è¯/åè¯ + que no" ç»“æ„ ====================
        r'\bno\s+es\s+cierto\s+que\s+no\s+\w+',                       # No es cierto que no + åŠ¨è¯
        r'\bno\s+es\s+verdad\s+que\s+no\s+\w+',                       # No es verdad que no + åŠ¨è¯
        r'\bno\s+es\s+posible\s+que\s+no\s+\w+',                      # No es posible que no + åŠ¨è¯
        r'\bno\s+es\s+probable\s+que\s+no\s+\w+',                     # No es probable que no + åŠ¨è¯
        r'\bno\s+es\s+seguro\s+que\s+no\s+\w+',                       # No es seguro que no + åŠ¨è¯
        r'\bno\s+es\s+normal\s+que\s+no\s+\w+',                       # No es normal que no + åŠ¨è¯
        r'\bno\s+es\s+raro\s+que\s+no\s+\w+',                         # No es raro que no + åŠ¨è¯
        r'\bno\s+es\s+extraÃ±o\s+que\s+no\s+\w+',                      # No es extraÃ±o que no + åŠ¨è¯
        r'\bno\s+es\s+comÃºn\s+que\s+no\s+\w+',                        # No es comÃºn que no + åŠ¨è¯
        r'\bno\s+es\s+fÃ¡cil\s+que\s+no\s+\w+',                        # No es fÃ¡cil que no + åŠ¨è¯
        r'\bno\s+es\s+difÃ­cil\s+que\s+no\s+\w+',                      # No es difÃ­cil que no + åŠ¨è¯
        r'\bno\s+es\s+lÃ³gico\s+que\s+no\s+\w+',                       # No es lÃ³gico que no + åŠ¨è¯
        r'\bno\s+es\s+justo\s+que\s+no\s+\w+',                        # No es justo que no + åŠ¨è¯
        r'\bno\s+es\s+correcto\s+que\s+no\s+\w+',                     # No es correcto que no + åŠ¨è¯
        r'\bno\s+es\s+bueno\s+que\s+no\s+\w+',                        # No es bueno que no + åŠ¨è¯
        r'\bno\s+es\s+malo\s+que\s+no\s+\w+',                         # No es malo que no + åŠ¨è¯
        r'\bno\s+es\s+necesario\s+que\s+no\s+\w+',                    # No es necesario que no + åŠ¨è¯
        r'\bno\s+es\s+importante\s+que\s+no\s+\w+',                   # No es importante que no + åŠ¨è¯
        r'\bno\s+es\s+suficiente\s+que\s+no\s+\w+',                   # No es suficiente que no + åŠ¨è¯
        
        # ==================== 3. "No es que no" åŸºæœ¬ç»“æ„ ====================
        r'\bno\s+es\s+que\s+no\s+\w+',                                # No es que no + åŠ¨è¯
        r'\bno\s+es\s+que\s+no\s+\w+\s+\w+',                          # No es que no + åŠ¨è¯ + å®¾è¯­
        
        # ==================== 4. ğŸ”§ æ–°å¢ï¼šå¤æ‚åµŒå¥—åŒé‡å¦å®šç»“æ„ ====================
        r'\bno\s+quiero\s+que\s+\w+\s+que\s+no\s+\w+',                # no quiero que X que no Y
        r'\bno\s+deseo\s+que\s+\w+\s+que\s+no\s+\w+',                 # no deseo que X que no Y
        r'\bno\s+espero\s+que\s+\w+\s+que\s+no\s+\w+',                # no espero que X que no Y
        r'\bno\s+pretendo\s+que\s+\w+\s+que\s+no\s+\w+',              # no pretendo que X que no Y
        r'\bno\s+busco\s+que\s+\w+\s+que\s+no\s+\w+',                 # no busco que X que no Y
        r'\bno\s+intento\s+que\s+\w+\s+que\s+no\s+\w+',               # no intento que X que no Y
        r'\bno\s+trato\s+que\s+\w+\s+que\s+no\s+\w+',                 # no trato que X que no Y
        r'\bno\s+procuro\s+que\s+\w+\s+que\s+no\s+\w+',               # no procuro que X que no Y
        
        # æ›´çµæ´»çš„åµŒå¥—æ¨¡å¼
        r'\bno\s+\w+\s+que\s+\w+\s+que\s+no\s+\w+',                   # no X que Y que no Z (é€šç”¨)
        r'\bno\s+\w+\s+que\s+\w+\s+\w+\s+que\s+no\s+\w+',             # no X que Y Z que no W (æ›´é•¿)
        
        # ==================== 5. "dejar de"ç»“æ„çš„åŒé‡å¦å®š ====================
        r'\bno\s+dej[aoÃ³eÃ©]\s+de\s+\w+',                              # no deja/dejo/dejÃ³ de + åŠ¨è¯
        r'\bno\s+dejan\s+de\s+\w+',                                   # no dejan de + åŠ¨è¯
        r'\bno\s+dejamos\s+de\s+\w+',                                 # no dejamos de + åŠ¨è¯
        r'\bno\s+dejas\s+de\s+\w+',                                   # no dejas de + åŠ¨è¯
        r'\bno\s+dejarÃ¡\s+de\s+\w+',                                  # no dejarÃ¡ de + åŠ¨è¯
        r'\bno\s+dejarÃ¡n\s+de\s+\w+',                                 # no dejarÃ¡n de + åŠ¨è¯
        r'\bno\s+dejarÃ©\s+de\s+\w+',                                  # no dejarÃ© de + åŠ¨è¯
        r'\bno\s+dejarÃ¡s\s+de\s+\w+',                                 # no dejarÃ¡s de + åŠ¨è¯
        r'\bno\s+dejaremos\s+de\s+\w+',                               # no dejaremos de + åŠ¨è¯
        r'\bno\s+dejarÃ­a\s+de\s+\w+',                                 # no dejarÃ­a de + åŠ¨è¯
        r'\bno\s+dejarÃ­an\s+de\s+\w+',                                # no dejarÃ­an de + åŠ¨è¯
        r'\bno\s+dejarÃ­as\s+de\s+\w+',                                # no dejarÃ­as de + åŠ¨è¯
        r'\bno\s+dejarÃ­amos\s+de\s+\w+',                              # no dejarÃ­amos de + åŠ¨è¯
        r'\bno\s+he\s+dejado\s+de\s+\w+',                             # no he dejado de + åŠ¨è¯
        r'\bno\s+has\s+dejado\s+de\s+\w+',                            # no has dejado de + åŠ¨è¯
        r'\bno\s+ha\s+dejado\s+de\s+\w+',                             # no ha dejado de + åŠ¨è¯
        r'\bno\s+hemos\s+dejado\s+de\s+\w+',                          # no hemos dejado de + åŠ¨è¯
        r'\bno\s+han\s+dejado\s+de\s+\w+',                            # no han dejado de + åŠ¨è¯
        r'\bsin\s+dejar\s+de\s+\w+',                                  # sin dejar de + åŠ¨è¯
        
        # ==================== 6. "quien"ç»“æ„çš„åŒé‡å¦å®š ====================
        r'\bno\s+hay\s+quien\s+no\s+\w+',                             # no hay quien no + åŠ¨è¯
        r'\bni\s+quien\s+no\s+\w+',                                   # ni quien no + åŠ¨è¯
        
        # ==================== 7. "no hay + åè¯ + que no"ç»“æ„ ====================
        r'\bno\s+hay\s+\w+\s+que\s+no\s+\w+',                         # no hay X que no + åŠ¨è¯
        r'\bni\s+\w+\s+que\s+no\s+\w+',                               # ni X que no + åŠ¨è¯
        
        # ==================== 8. ç»å…¸åŒé‡å¦å®š (no + åŠ¨è¯ + å¦å®šè¯) ====================
        # no + åŠ¨è¯ + nada
        r'\bno\s+\w+\s+nada\b',                                       # no + åŠ¨è¯ + nada (é€šç”¨)
        
        # no + åŠ¨è¯ + nadie
        r'\bno\s+\w+\s+a\s+nadie\b',                                  # no + åŠ¨è¯ + a nadie
        r'\bno\s+\w+\s+nadie\b',                                      # no + åŠ¨è¯ + nadie
        
        # no + åŠ¨è¯ + ningÃºn/ninguna/ninguno
        r'\bno\s+\w+\s+ningun[oaÃ³s]?\b',                              # no + åŠ¨è¯ + ningÃºn/ninguna/ninguno
        
        # no + åŠ¨è¯ + nunca/jamÃ¡s
        r'\bno\s+\w+\s+(nunca|jamÃ¡s)\b',                              # no + åŠ¨è¯ + nunca/jamÃ¡s
        
        # no + åŠ¨è¯ + tampoco
        r'\bno\s+\w+\s+tampoco\b',                                    # no + åŠ¨è¯ + tampoco
        
        # ==================== 9. "poder no"ç»“æ„çš„åŒé‡å¦å®š ====================
        r'\bno\s+pued[eo]\s+no\s+\w+',                                # no puedo/puede no + åŠ¨è¯
        r'\bno\s+puedes\s+no\s+\w+',                                  # no puedes no + åŠ¨è¯
        r'\bno\s+podemos\s+no\s+\w+',                                 # no podemos no + åŠ¨è¯
        r'\bno\s+pueden\s+no\s+\w+',                                  # no pueden no + åŠ¨è¯
        r'\bno\s+podr[Ã©Ã¡Ã¡s]\s+no\s+\w+',                              # no podrÃ©/podrÃ¡/podrÃ¡s no + åŠ¨è¯
        r'\bno\s+podremos\s+no\s+\w+',                                # no podremos no + åŠ¨è¯
        r'\bno\s+podrÃ¡n\s+no\s+\w+',                                  # no podrÃ¡n no + åŠ¨è¯
        r'\bno\s+podrÃ­a[ns]?\s+no\s+\w+',                             # no podrÃ­a/podrÃ­an no + åŠ¨è¯
        
        # ==================== 10. å…¶ä»–å¤æ‚ç»“æ„ ====================
        r'\bno\s+\w+\s+sin\s+(nada|nadie|ningÃºn|ninguna|ninguno)\b',  # no X sin nada/nadie/ningÃºn
        r'\bno\s+\w+\s+mÃ¡s\s+que\s+(nada|nadie)\b',                   # no X mÃ¡s que nada/nadie
        r'\bno\s+creo\s+que\s+no\s+\w+',                              # no creo que no + åŠ¨è¯
        r'\bno\s+pienso\s+que\s+no\s+\w+',                            # no pienso que no + åŠ¨è¯
        r'\bno\s+me\s+parece\s+que\s+no\s+\w+',                       # no me parece que no + åŠ¨è¯
        r'\bno\s+considero\s+que\s+no\s+\w+',                         # no considero que no + åŠ¨è¯
        r'\bno\s+opino\s+que\s+no\s+\w+',                             # no opino que no + åŠ¨è¯
        
        # ==================== 11. æ¡ä»¶å¥ä¸­çš„åŒé‡å¦å®š ====================
        r'\bsi\s+no\s+\w+,?\s+no\s+\w+',                              # si no X, no Y
        r'\bcuando\s+no\s+\w+,?\s+no\s+\w+',                          # cuando no X, no Y
        r'\bmientras\s+no\s+\w+,?\s+no\s+\w+',                        # mientras no X, no Y
        
        # ==================== 12. æ„Ÿå¹å¥å’Œç–‘é—®å¥ä¸­çš„åŒé‡å¦å®š ====================
        r'\bÂ¿[^?]*no\s+\w+[^?]*no\s+\w+[^?]*\?',                      # Â¿...no...no...?
        r'\bÂ¡[^!]*no\s+\w+[^!]*no\s+\w+[^!]*!',                       # Â¡...no...no...!
        
        # ==================== 13. å¸¦æœ‰æƒ…æ€åŠ¨è¯çš„åŒé‡å¦å®š ====================
        r'\bno\s+deb[eo]\s+no\s+\w+',                                 # no debo/debe no + åŠ¨è¯
        r'\bno\s+debes\s+no\s+\w+',                                   # no debes no + åŠ¨è¯
        r'\bno\s+debemos\s+no\s+\w+',                                 # no debemos no + åŠ¨è¯
        r'\bno\s+deben\s+no\s+\w+',                                   # no deben no + åŠ¨è¯
        r'\bno\s+sol[eÃ­]a\s+no\s+\w+',                                # no solÃ­a/suelo no + åŠ¨è¯
        r'\bno\s+sueles\s+no\s+\w+',                                  # no sueles no + åŠ¨è¯
        r'\bno\s+solemos\s+no\s+\w+',                                 # no solemos no + åŠ¨è¯
        r'\bno\s+suelen\s+no\s+\w+',                                  # no suelen no + åŠ¨è¯
        
        # ==================== 14. æ—¶æ€å¤åˆçš„åŒé‡å¦å®š ====================
        r'\bno\s+h[aeo]\w*\s+\w+\s+(nunca|jamÃ¡s)\b',                  # no he/ha/hemos + è¿‡å»åˆ†è¯ + nunca/jamÃ¡s
        r'\bno\s+habÃ­a[sn]?\s+\w+\s+(nunca|jamÃ¡s)\b',                 # no habÃ­a/habÃ­as/habÃ­an + è¿‡å»åˆ†è¯ + nunca/jamÃ¡s
        
        # ==================== 15. å¤æ‚çš„ä»å¥ç»“æ„ ====================
        r'\bno\s+\w+\s+que\s+no\s+\w+\s+que\s+no\s+\w+',              # no X que no Y que no Z
        r'\bno\s+\w+\s+cuando\s+no\s+\w+',                            # no X cuando no Y
        r'\bno\s+\w+\s+donde\s+no\s+\w+',                             # no X donde no Y
        r'\bno\s+\w+\s+como\s+no\s+\w+',                              # no X como no Y
        
        # ==================== 16. ç‰¹æ®Šè¡¨è¾¾ ====================
        r'\bno\s+\w+\s+ni\s+por\s+nada\b',                            # no X ni por nada
        r'\bno\s+\w+\s+para\s+nada\b',                                # no X para nada
        r'\bno\s+\w+\s+en\s+absoluto\b',                              # no X en absoluto
        r'\bno\s+\w+\s+de\s+ninguna\s+manera\b',                      # no X de ninguna manera
        r'\bno\s+\w+\s+bajo\s+ninguna\s+circunstancia\b',             # no X bajo ninguna circunstancia
        r'\bno\s+\w+\s+en\s+ningÃºn\s+momento\b',                      # no X en ningÃºn momento
        r'\bno\s+\w+\s+por\s+ningÃºn\s+motivo\b',                      # no X por ningÃºn motivo
        r'\bno\s+\w+\s+de\s+ningÃºn\s+modo\b',                         # no X de ningÃºn modo
    ]
    
    # ğŸ”§ éåŒé‡å¦å®šçš„æ¨¡å¼ï¼ˆæ’é™¤è¯¯åˆ¤ï¼‰
    non_double_negative_patterns = [
        # å¹¶åˆ—å¦å®šï¼ˆä¸æ˜¯åŒé‡å¦å®šï¼‰
        r'\bno\s+\w+\s+ni\s+\w+\b(?!\s+(que\s+no|tampoco|nunca|jamÃ¡s))',  # no come ni bebe (ä½†ä¸æ’é™¤ç‰¹æ®Šæƒ…å†µ)
        r'\bni\s+\w+\s+ni\s+\w+\b(?!\s+(que\s+no|tampoco|nunca|jamÃ¡s))',  # ni come ni bebe
        
        # ç®€å•å¦å®šï¼ˆå•ç‹¬å‡ºç°ï¼‰- ä½†è¦å°å¿ƒï¼Œä¸è¦æ’é™¤çœŸæ­£çš„åŒé‡å¦å®š
        r'\bno\s+es\s+(bueno|malo|fÃ¡cil|difÃ­cil|normal|raro)\b(?!\s+(que\s+no|\w+\s+que\s+no))',  # ç®€å•çš„ no es + å½¢å®¹è¯
    ]
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„åŒé‡å¦å®šæ€»æ•°
    total_double_negatives = 0
    all_matches = []
    found_positions = set()
    
    if debug:
        print("=== åŒé‡å¦å®šæ£€æµ‹è°ƒè¯•ä¿¡æ¯ ===")
    
    # éå†æ‰€æœ‰æ–‡æœ¬
    for text_index, text in enumerate(cleaned_up_texts):
        if debug:
            print(f"\nText {text_index}: '{text}'")
        
        for pattern_index, pattern in enumerate(correct_patterns):
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                match_text = match.group().strip()
                match_span = match.span()
                
                if debug:
                    print(f"  Pattern {pattern_index}: '{pattern}'")
                    print(f"    -> Found: '{match_text}' at {match_span}")
                
                # æ£€æŸ¥ä½ç½®æ˜¯å¦é‡å ï¼ˆå…è®¸3ä¸ªå­—ç¬¦çš„å®¹å·®ï¼‰
                position_key = (text_index, match_span[0], match_span[1])
                overlaps = False
                
                for existing_pos in found_positions:
                    existing_text_idx, existing_start, existing_end = existing_pos
                    if existing_text_idx == text_index:
                        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾è‘—é‡å ï¼ˆè¶…è¿‡3ä¸ªå­—ç¬¦ï¼‰
                        overlap_start = max(match_span[0], existing_start)
                        overlap_end = min(match_span[1], existing_end)
                        overlap_length = max(0, overlap_end - overlap_start)
                        
                        if overlap_length > 3:  # å…è®¸å°çš„é‡å 
                            overlaps = True
                            if debug:
                                print(f"    -> EXCLUDED (overlaps with {existing_pos}, overlap: {overlap_length} chars)")
                            break
                
                if not overlaps:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯çœŸæ­£çš„åŒé‡å¦å®š
                    is_real_double_negative = True
                    for non_pattern in non_double_negative_patterns:
                        if re.search(non_pattern, match_text, re.IGNORECASE):
                            is_real_double_negative = False
                            if debug:
                                print(f"    -> EXCLUDED (matches non-double-negative pattern: '{non_pattern}')")
                            break
                    
                    if is_real_double_negative:
                        found_positions.add(position_key)
                        total_double_negatives += 1
                        all_matches.append(match_text)
                        if debug:
                            print(f"    -> INCLUDED (#{total_double_negatives})")
                    
    if debug:
        print(f"\n=== æœ€ç»ˆç»“æœ ===")
        print(f"æ€»è®¡æ‰¾åˆ° {total_double_negatives} ä¸ªåŒé‡å¦å®š:")
        for i, match in enumerate(all_matches, 1):
            print(f"  {i}. '{match}'")
    
    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæ€»æ•°è¦æ±‚
    if min_total <= total_double_negatives <= max_total:
        unique_examples = list(set(all_matches))
        display_examples = unique_examples[:5]
        
        examples_text = ", ".join([f"'{ex}'" for ex in display_examples])
        if len(unique_examples) > 5:
            examples_text += f" ... (+{len(unique_examples) - 5} more types)"
        
        return 1, f"âœ… Total double negatives: {total_double_negatives} (required: {min_total}-{max_total}). Found examples: {examples_text}. Requirement met."
    else:
        if all_matches:
            unique_examples = list(set(all_matches))[:3]
            examples_text = ", ".join([f"'{ex}'" for ex in unique_examples])
            if len(all_matches) > 3:
                examples_text += f" ... (+{len(set(all_matches)) - 3} more types)"
            examples_info = f" Found examples: {examples_text}."
        else:
            examples_info = " No double negatives found."
        
        return 0, f"âŒ Total double negatives: {total_double_negatives} (required: {min_total}-{max_total}).{examples_info} Does not meet the requirement."


# ğŸ”§ æµ‹è¯•å‡½æ•°ï¼ˆæµ‹è¯•é—®é¢˜æ¡ˆä¾‹ï¼‰
def test_problem_case():
    """æµ‹è¯•é—®é¢˜æ¡ˆä¾‹"""
    test_texts = [
        "Querida [nombre de tu novia],\n\nLamento profundamente el malentendido de ayer. No estaba con otras chicas, sino con mi hermana, buscando el regalo perfecto para ti. Entiendo cÃ³mo pudo parecer otra cosa y no quiero que pienses que no soy honesto contigo.\n\nEspero que puedas comprender la situaciÃ³n y que esto no afecte nuestra relaciÃ³n. Mi intenciÃ³n nunca fue ocultarte nada ni hacerte sentir incÃ³moda. \n\nGracias por tu comprensiÃ³n y paciencia. Te quiero mucho.  \nCon cariÃ±o,  \n[Tu nombre]  \nFecha: 15 de octubre de 2023."
    ]
    
    print("=== æµ‹è¯•é—®é¢˜æ¡ˆä¾‹ ===")
    result, explanation = has_correct_total_double_negatives(test_texts, 1, 999, debug=True)
    print(f"\næœ€ç»ˆè¯„ä¼°ç»“æœ: {result}")
    print(f"è§£é‡Š: {explanation}")

# è¿è¡Œæµ‹è¯•
# if __name__ == "__main__":
#     test_problem_case()


def has_correct_spanish_date_format(texts, num):
    """æ£€æŸ¥æ¯ä¸ªæ–‡æœ¬ä¸­è¥¿ç­ç‰™è¯­æ—¥æœŸæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆæ—¥/æœˆ/å¹´ï¼‰"""
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_spanish_date_errors(text):
        """æ£€æŸ¥æ–‡æœ¬ä¸­çš„è¥¿ç­ç‰™è¯­æ—¥æœŸæ ¼å¼é”™è¯¯"""
        
        # æ­£ç¡®çš„è¥¿ç­ç‰™è¯­æ—¥æœŸæ ¼å¼æ¨¡å¼
        correct_spanish_date_patterns = [
            # æ—¥/æœˆ/å¹´æ ¼å¼ (DD/MM/YYYY, D/M/YY, DD/MM/YYç­‰)
            r'\b([0-3]?\d)/([01]?\d)/(\d{2,4})\b',
            # æ—¥-æœˆ-å¹´æ ¼å¼ (DD-MM-YYYY)
            r'\b([0-3]?\d)-([01]?\d)-(\d{2,4})\b',
            # æ—¥.æœˆ.å¹´æ ¼å¼ (DD.MM.YYYY)
            r'\b([0-3]?\d)\.([01]?\d)\.(\d{2,4})\b',
            # æ—¥ de æœˆ de å¹´æ ¼å¼ (ej: 15 de marzo de 2024)
            r'(\d{1,2})\s+de\s+(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre)\s+de\s+(\d{4})',
            # æ—¥ æœˆ å¹´æ ¼å¼ (æ²¡æœ‰"de") - ä½†è¦ç¡®ä¿ä¸ä¸ä¸Šé¢é‡å¤
            r'(\d{1,2})\s+(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre)\s+(\d{4})(?!\s+de)',  # ğŸ”§ è´Ÿå‘å‰ç»ï¼Œæ’é™¤åé¢è·Ÿ"de"çš„æƒ…å†µ
            # å¸¦"del"çš„æ ¼å¼
            r'(\d{1,2})\s+del?\s+(enero|febrero|marzo|abril|mayo|junio|julio|agosto|septiembre|octubre|noviembre|diciembre)\s+del?\s+(\d{4})',
        ]
        
        # é”™è¯¯çš„è‹±è¯­æ—¥æœŸæ ¼å¼æ¨¡å¼ (æœˆ/æ—¥/å¹´)
        incorrect_english_date_patterns = [
            r'\b([01]?\d)/([0-3]?\d)/(\d{2,4})\b',
            r'\b([01]?\d)-([0-3]?\d)-(\d{2,4})\b',
            r'\b([01]?\d)\.([0-3]?\d)\.(\d{2,4})\b',
        ]
        
        errors = []
        correct_dates = []
        found_positions = set()  # ğŸ”§ æ–°å¢ï¼šè®°å½•å·²æ‰¾åˆ°çš„ä½ç½®ï¼Œé¿å…é‡å¤
        
        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ­£ç¡®çš„è¥¿ç­ç‰™è¯­æ—¥æœŸæ ¼å¼ï¼Œé¿å…é‡å¤è®¡æ•°
        for i, pattern in enumerate(correct_spanish_date_patterns):
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                date_text = match.group()
                match_span = match.span()
                
                # ğŸ”§ æ£€æŸ¥æ˜¯å¦ä¸å·²æ‰¾åˆ°çš„æ—¥æœŸé‡å 
                overlaps = False
                for existing_span in found_positions:
                    # æ£€æŸ¥ä½ç½®é‡å ï¼ˆå…è®¸å°çš„è¯¯å·®ï¼‰
                    if (match_span[0] < existing_span[1] and match_span[1] > existing_span[0]):
                        overlaps = True
                        break
                
                if not overlaps:
                    # éªŒè¯æ—¥æœŸçš„åˆç†æ€§
                    if i <= 2:  # DD/MM/YYYY, DD-MM-YYYY, DD.MM.YYYY æ ¼å¼
                        day, month, year = match.groups()
                        if is_valid_date_values(int(day), int(month), int(year)):
                            correct_dates.append({
                                'date': date_text,
                                'format': 'DD/MM/YYYY',
                                'position': match_span
                            })
                            found_positions.add(match_span)
                    else:  # æ–‡å­—æœˆä»½æ ¼å¼
                        correct_dates.append({
                            'date': date_text,
                            'format': 'DD de mes de YYYY',
                            'position': match_span
                        })
                        found_positions.add(match_span)
        
        # æ£€æŸ¥å¯èƒ½çš„è‹±è¯­æ ¼å¼é”™è¯¯
        for pattern in incorrect_english_date_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                date_text = match.group()
                match_span = match.span()
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»è¢«è¯†åˆ«ä¸ºæ­£ç¡®æ ¼å¼
                already_found = False
                for existing_span in found_positions:
                    if (match_span[0] < existing_span[1] and match_span[1] > existing_span[0]):
                        already_found = True
                        break
                
                if not already_found:
                    month, day, year = match.groups()
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜æ˜¾æ˜¯è‹±è¯­æ ¼å¼
                    if int(month) > 12 or (int(month) <= 12 and int(day) <= 12 and int(month) != int(day)):
                        correct_spanish = f"{day}/{month}/{year}"
                        errors.append({
                            'type': 'english_format',
                            'error': date_text,
                            'correct': correct_spanish,
                            'position': match_span,
                            'explanation': 'Formato inglÃ©s detectado, debe usar formato espaÃ±ol DD/MM/YYYY'
                        })
        
        # æ£€æŸ¥å…¶ä»–å¸¸è§é”™è¯¯æ ¼å¼
        other_wrong_patterns = [
            r'\b(\d{4})/([01]?\d)/([0-3]?\d)\b',
            r'\b(\d{4})-([01]?\d)-([0-3]?\d)\b',
        ]
        
        for pattern in other_wrong_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                match_span = match.span()
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»è¢«è¯†åˆ«ä¸ºæ­£ç¡®æ ¼å¼
                already_found = False
                for existing_span in found_positions:
                    if (match_span[0] < existing_span[1] and match_span[1] > existing_span[0]):
                        already_found = True
                        break
                
                if not already_found:
                    date_text = match.group()
                    year, month, day = match.groups()
                    correct_spanish = f"{day}/{month}/{year}"
                    errors.append({
                        'type': 'wrong_order',
                        'error': date_text,
                        'correct': correct_spanish,
                        'position': match_span,
                        'explanation': 'Orden incorrecto, debe usar formato espaÃ±ol DD/MM/YYYY'
                    })
        
        return len(errors), errors, len(correct_dates), correct_dates
    
    def is_valid_date_values(day, month, year):
        """éªŒè¯æ—¥æœŸæ•°å€¼çš„åˆç†æ€§"""
        if month < 1 or month > 12:
            return False
        if day < 1 or day > 31:
            return False
        if year < 1900 or year > 2100:
            return False
        return True
    
    # æ£€æŸ¥æ¯ä¸ªæ–‡æœ¬
    total_errors = 0
    total_correct = 0
    all_errors = []
    all_correct = []
    
    for i, text in enumerate(cleaned_up_texts):
        error_count, errors, correct_count, correct_dates = check_spanish_date_errors(text)
        total_errors += error_count
        total_correct += correct_count
        
        if errors:
            all_errors.extend(errors)
        if correct_dates:
            all_correct.extend(correct_dates)
    
    # æ„å»ºè¯¦ç»†ä¿¡æ¯
    if total_errors > num:
        error_details = []
        for error in all_errors:
            error_details.append(f"'{error['error']}' â†’ '{error['correct']}' ({error['explanation']})")
        
        error_summary = "; ".join(error_details)
        
        return 0, f"âŒ Found {total_errors} Spanish date format errors (allowed: {num}). Errors: {error_summary}. Does not meet the requirement."
    
    # ğŸ”§ ä¿®å¤ï¼šå»é‡æ˜¾ç¤º
    unique_correct = []
    seen_dates = set()
    for correct in all_correct:
        if correct['date'] not in seen_dates:
            unique_correct.append(correct)
            seen_dates.add(correct['date'])
    
    correct_examples = []
    for correct in unique_correct[:3]:
        correct_examples.append(f"'{correct['date']}' ({correct['format']})")
    
    if len(unique_correct) > 3:
        correct_examples.append(f"... (+{len(unique_correct) - 3} more)")
    
    correct_info = f"Found {len(unique_correct)} correct dates" + (f": {', '.join(correct_examples)}" if correct_examples else "")
    
    return 1, f"âœ… Spanish date format is correct. {correct_info}. Found {total_errors} errors (allowed: {num}). Requirement met."


def has_correct_abbreviation_format_only(texts, max_errors):
    """åªæ£€æŸ¥å·²ç»æ˜¯ç¼©å†™å½¢å¼çš„è¯çš„æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œä¸æ£€æŸ¥å®Œæ•´è¯æ±‡"""
    import re
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_existing_abbreviation_errors(text):
        """åªæ£€æŸ¥æ–‡æœ¬ä¸­å·²å­˜åœ¨çš„ç¼©å†™å½¢å¼çš„æ ¼å¼é”™è¯¯"""
        
        # æ‰©å±•çš„è¥¿ç­ç‰™è¯­æ­£å¼ç¼©å†™è¯å…¸ï¼ˆå°å†™ -> å¤§å†™ï¼‰
        known_abbreviations = {
            # === å›½é™…ç»„ç»‡ ===
            'onu': 'ONU', 'oms': 'OMS', 'otan': 'OTAN', 'unesco': 'UNESCO', 'unicef': 'UNICEF',
            'fmi': 'FMI', 'bid': 'BID', 'oea': 'OEA', 'opep': 'OPEP', 'ocde': 'OCDE',
            'ue': 'UE', 'bce': 'BCE', 'pe': 'PE', 'ce': 'CE', 'cee': 'CEE',
            
            # === ä¼ä¸šç±»å‹ ===
            'sa': 'S.A.', 'sl': 'S.L.', 'slu': 'S.L.U.', 'slp': 'S.L.P.', 'srl': 'S.R.L.',
            's.a.': 'S.A.', 's.l.': 'S.L.', 's.l.u.': 'S.L.U.', 's.l.p.': 'S.L.P.',
            
            # === æ–‡æ¡£å’Œè¡Œæ”¿ ===
            'dni': 'DNI', 'nie': 'NIE', 'nif': 'NIF', 'cif': 'CIF', 'iva': 'IVA',
            'pib': 'PIB', 'pnb': 'PNB', 'ipc': 'IPC', 'irpf': 'IRPF',
            
            # === æŠ€æœ¯ ===
            'cpu': 'CPU', 'gpu': 'GPU', 'ram': 'RAM', 'rom': 'ROM', 'ssd': 'SSD',
            'html': 'HTML', 'http': 'HTTP', 'https': 'HTTPS', 'url': 'URL',
            'gps': 'GPS', 'sms': 'SMS', 'mms': 'MMS', 'app': 'APP', 'pdf': 'PDF',
            'tv': 'TV', 'dvd': 'DVD', 'cd': 'CD', 'wifi': 'WIFI',
            
            # === ä¼ä¸šèŒä½ ===
            'ceo': 'CEO', 'cfo': 'CFO', 'cto': 'CTO', 'coo': 'COO', 'cmo': 'CMO',
            
            # === æœºæ„ ===
            'nasa': 'NASA', 'fbi': 'FBI', 'cia': 'CIA', 'fda': 'FDA',
        }
        
        # å¸¸è§çš„è¥¿ç­ç‰™è¯­æ™®é€šè¯æ±‡ï¼ˆä¸åº”è¢«è§†ä¸ºç¼©å†™é”™è¯¯ï¼‰
        common_spanish_words = {
            'app', 'web', 'blog', 'chat', 'email', 'wifi', 'online', 'software',
            'hardware', 'internet', 'digital', 'virtual', 'global', 'local',
            'el', 'la', 'los', 'las', 'un', 'una', 'de', 'en', 'con', 'por', 'sin',
            'que', 'es', 'no', 'si', 'me', 'te', 'se', 'le', 'lo', 'ya', 'muy'
        }
        
        format_errors = []
        correct_abbreviations = []
        
        # 1. æŸ¥æ‰¾æ­£ç¡®æ ¼å¼çš„ç¼©å†™
        patterns_to_check = [
            # æ ‡å‡†å…¨å¤§å†™ç¼©å†™ (2-10ä¸ªå­—æ¯)
            r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]{2,10}\b',
            # å¸¦ç‚¹å·çš„ç¼©å†™ (å¦‚ S.A., S.L.)
            r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]\.(?:[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]\.)*\b',
            # å¸¦æ•°å­—çš„ç¼©å†™ (å¦‚ 4K, F1)
            r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]*\d+[A-ZÃÃ‰ÃÃ“ÃšÃ‘ÃœK]*\b|\b\d+[A-ZÃÃ‰ÃÃ“ÃšÃ‘ÃœK]+\b'
        ]
        
        for pattern in patterns_to_check:
            matches = re.finditer(pattern, text)
            for match in matches:
                abbrev = match.group()
                abbrev_lower = abbrev.lower()
                
                # è·³è¿‡å¸¸è§è¯æ±‡
                if abbrev_lower in common_spanish_words:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå·²çŸ¥ç¼©å†™
                if abbrev_lower in known_abbreviations:
                    expected_format = known_abbreviations[abbrev_lower]
                    if abbrev == expected_format:
                        correct_abbreviations.append({
                            'abbreviation': abbrev,
                            'position': match.span(),
                            'type': 'correct'
                        })
        
        # 2. æ£€æŸ¥æ ¼å¼é”™è¯¯çš„ç¼©å†™
        error_patterns = [
            # å°å†™çš„å·²çŸ¥ç¼©å†™
            {
                'pattern': r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]{2,10}\b',
                'type': 'lowercase',
                'description': 'Debe estar en mayÃºsculas'
            },
            # æ··åˆå¤§å°å†™
            {
                'pattern': r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]*[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼][A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]*\b',
                'type': 'mixed_case',
                'description': 'Formato de mayÃºsculas inconsistente'
            },
            # å¸¦ç©ºæ ¼çš„ç¼©å†™
            {
                'pattern': r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼](?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼])*\b',
                'type': 'with_spaces',
                'description': 'Contiene espacios entre letras'
            },
            # å¸¦è¿å­—ç¬¦çš„ç¼©å†™
            {
                'pattern': r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]-(?:[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]-)*[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]\b',
                'type': 'with_hyphens',
                'description': 'Contiene guiones entre letras'
            }
        ]
        
        for error_config in error_patterns:
            pattern = error_config['pattern']
            error_type = error_config['type']
            description = error_config['description']
            
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                error_text = match.group()
                clean_text = re.sub(r'[^A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]', '', error_text).lower()
                
                # è·³è¿‡å¸¸è§è¯æ±‡
                if clean_text in common_spanish_words:
                    continue
                
                # åªæŠ¥å‘Šå·²çŸ¥ç¼©å†™çš„æ ¼å¼é”™è¯¯
                if clean_text in known_abbreviations:
                    correct_format = known_abbreviations[clean_text]
                    
                    # ç¡®ä¿é”™è¯¯æ–‡æœ¬å’Œæ­£ç¡®æ ¼å¼ä¸åŒ
                    if error_text != correct_format:
                        format_errors.append({
                            'error': error_text,
                            'correct': correct_format,
                            'type': error_type,
                            'position': match.span(),
                            'description': description
                        })
        
        return len(format_errors), format_errors, len(correct_abbreviations), correct_abbreviations
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„æ ¼å¼é”™è¯¯
    total_errors = 0
    all_errors = []
    all_correct = []
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_abbrevs = check_existing_abbreviation_errors(text)
        total_errors += error_count
        all_errors.extend(errors)
        all_correct.extend(correct_abbrevs)
    
    # å»é‡æ­£ç¡®çš„ç¼©å†™
    unique_correct = []
    seen = set()
    for correct in all_correct:
        if correct['abbreviation'] not in seen:
            unique_correct.append(correct)
            seen.add(correct['abbreviation'])
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_errors <= max_errors:
        correct_examples = [correct['abbreviation'] for correct in unique_correct]
        correct_info = f"Found {len(unique_correct)} correct abbreviations" + (f": {', '.join(correct_examples)}" if correct_examples else "")
        
        error_info = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in all_errors[:3]]
            error_info = f" Format errors: {'; '.join(error_examples)}"
            if len(all_errors) > 3:
                error_info += f" (+{len(all_errors)-3} more)"
        
        return 1, f"âœ… Existing abbreviation formats are acceptable. {correct_info}. Found {total_errors} format errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = [f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})" for error in all_errors[:5]]
        error_summary = "; ".join(error_details)
        
        return 0, f"âŒ Found {total_errors} format errors in existing abbreviations (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."


def has_spanish_abbreviation_count(texts, num):
    """æ£€æµ‹æ–‡æœ¬ä¸­è¥¿ç­ç‰™è¯­æ ¼å¼æ­£ç¡®çš„ç¼©å†™æ•°é‡"""
    import re
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def count_correct_abbreviations(text):
        """ç»Ÿè®¡æ–‡æœ¬ä¸­æ ¼å¼æ­£ç¡®çš„è¥¿ç­ç‰™è¯­ç¼©å†™æ•°é‡"""
        
        # æ‰©å±•çš„è¥¿ç­ç‰™è¯­æ­£å¼ç¼©å†™è¯å…¸ï¼ˆå°å†™ -> å¤§å†™ï¼‰- ä¸ä¸Šé¢ä¿æŒä¸€è‡´
        known_abbreviations = {
            # === å›½é™…ç»„ç»‡ ===
            'onu': 'ONU', 'oms': 'OMS', 'otan': 'OTAN', 'unesco': 'UNESCO', 'unicef': 'UNICEF',
            'fmi': 'FMI', 'bid': 'BID', 'oea': 'OEA', 'opep': 'OPEP', 'ocde': 'OCDE',
            'ue': 'UE', 'bce': 'BCE', 'pe': 'PE', 'ce': 'CE', 'cee': 'CEE',
            
            # === ä¼ä¸šç±»å‹ ===
            'sa': 'S.A.', 'sl': 'S.L.', 'slu': 'S.L.U.', 'slp': 'S.L.P.', 'srl': 'S.R.L.',
            's.a.': 'S.A.', 's.l.': 'S.L.', 's.l.u.': 'S.L.U.', 's.l.p.': 'S.L.P.',
            
            # === æ–‡æ¡£å’Œè¡Œæ”¿ ===
            'dni': 'DNI', 'nie': 'NIE', 'nif': 'NIF', 'cif': 'CIF', 'iva': 'IVA',
            'pib': 'PIB', 'pnb': 'PNB', 'ipc': 'IPC', 'irpf': 'IRPF',
            
            # === æŠ€æœ¯ ===
            'cpu': 'CPU', 'gpu': 'GPU', 'ram': 'RAM', 'rom': 'ROM', 'ssd': 'SSD',
            'html': 'HTML', 'http': 'HTTP', 'https': 'HTTPS', 'url': 'URL',
            'gps': 'GPS', 'sms': 'SMS', 'mms': 'MMS', 'app': 'APP', 'pdf': 'PDF',
            'tv': 'TV', 'dvd': 'DVD', 'cd': 'CD', 'wifi': 'WIFI',
            
            # === ä¼ä¸šèŒä½ ===
            'ceo': 'CEO', 'cfo': 'CFO', 'cto': 'CTO', 'coo': 'COO', 'cmo': 'CMO',
            
            # === æœºæ„ ===
            'nasa': 'NASA', 'fbi': 'FBI', 'cia': 'CIA', 'fda': 'FDA',
        }
        
        # å¸¸è§è¯æ±‡æ’é™¤åˆ—è¡¨
        non_abbreviations = {
            'el', 'la', 'los', 'las', 'un', 'una', 'de', 'en', 'con', 'por', 'sin',
            'que', 'es', 'no', 'si', 'me', 'te', 'se', 'le', 'lo', 'ya', 'muy',
            'mÃ¡s', 'tan', 'son', 'del', 'sus', 'mis', 'tus', 'dos', 'tres', 'mil',
            'app', 'web', 'blog', 'chat', 'email', 'wifi', 'online', 'software'
        }
        
        correct_count = 0
        found_abbreviations = []
        format_errors = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„ç¼©å†™æ¨¡å¼
        patterns_to_check = [
            # æ ‡å‡†å…¨å¤§å†™ç¼©å†™ (2-10ä¸ªå­—æ¯)
            r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]{2,10}\b',
            # å¸¦ç‚¹å·çš„ç¼©å†™ (å¦‚ S.A., S.L.)
            r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]\.(?:[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]\.)*\b',
            # å¸¦æ•°å­—çš„ç¼©å†™ (å¦‚ 4K, F1)
            r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]*\d+[A-ZÃÃ‰ÃÃ“ÃšÃ‘ÃœK]*\b|\b\d+[A-ZÃÃ‰ÃÃ“ÃšÃ‘ÃœK]+\b'
        ]
        
        seen_abbreviations = set()  # é˜²æ­¢é‡å¤è®¡æ•°
        
        for pattern in patterns_to_check:
            matches = re.finditer(pattern, text)
            for match in matches:
                abbrev = match.group()
                abbrev_lower = abbrev.lower()
                
                # è·³è¿‡å·²ç»è®¡æ•°çš„ç¼©å†™
                if abbrev in seen_abbreviations:
                    continue
                
                # è·³è¿‡å¸¸è§éç¼©å†™è¯æ±‡
                if abbrev_lower in non_abbreviations:
                    continue
                
                # åªç»Ÿè®¡å·²çŸ¥ç¼©å†™
                if abbrev_lower in known_abbreviations:
                    expected_format = known_abbreviations[abbrev_lower]
                    if abbrev == expected_format:
                        correct_count += 1
                        seen_abbreviations.add(abbrev)
                        found_abbreviations.append({
                            'abbreviation': abbrev,
                            'position': match.span(),
                            'full_form': abbrev_lower,
                            'type': 'correct'
                        })
        
        # æ£€æµ‹æ ¼å¼é”™è¯¯ï¼ˆç”¨äºåé¦ˆï¼‰
        error_patterns = [
            (r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]{2,10}\b', 'lowercase'),
            (r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]*[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼][A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]*\b', 'mixed_case'),
            (r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]\.(?:[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]\.)+\b', 'with_dots'),
            (r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼](?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼])*\b', 'with_spaces'),
            (r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]-(?:[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]-)*[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]\b', 'with_hyphens')
        ]
        
        for pattern, error_type in error_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                error_text = match.group()
                clean_text = re.sub(r'[^A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœa-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼]', '', error_text).lower()
                
                # è·³è¿‡å¸¸è§è¯æ±‡
                if clean_text in non_abbreviations:
                    continue
                
                # åªæŠ¥å‘Šå·²çŸ¥ç¼©å†™çš„æ ¼å¼é”™è¯¯
                if clean_text in known_abbreviations:
                    correct_format = known_abbreviations[clean_text]
                    if error_text != correct_format:
                        format_errors.append({
                            'error': error_text,
                            'correct': correct_format,
                            'type': error_type,
                            'position': match.span()
                        })
        
        return correct_count, found_abbreviations, format_errors
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„æ­£ç¡®ç¼©å†™
    total_count = 0
    all_found = []
    all_errors = []
    
    for text in cleaned_up_texts:
        count, found, errors = count_correct_abbreviations(text)
        total_count += count
        all_found.extend(found)
        all_errors.extend(errors)
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_count >= num:
        # æ˜¾ç¤ºæ‰¾åˆ°çš„ç¼©å†™ç¤ºä¾‹
        examples = []
        for abbrev_info in all_found[:15]:  # æœ€å¤šæ˜¾ç¤º15ä¸ªç¤ºä¾‹
            examples.append(abbrev_info['abbreviation'])
        
        example_text = f" Examples: {', '.join(examples)}" if examples else ""
        
        # å¦‚æœæœ‰æ ¼å¼é”™è¯¯ï¼Œä¹ŸæåŠä¸€ä¸‹
        error_note = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in all_errors[:3]]
            error_note = f" Note: Found {len(all_errors)} format errors: {', '.join(error_examples)}"
            if len(all_errors) > 3:
                error_note += f" (+{len(all_errors)-3} more)"
        
        return 1, f"âœ… Found {total_count} correct Spanish abbreviations (required: {num}).{example_text}{error_note} Requirement met."
    else:
        # æ˜¾ç¤ºæ‰¾åˆ°çš„ç¼©å†™å’Œé”™è¯¯ä¿¡æ¯
        found_text = ""
        if all_found:
            examples = [abbrev_info['abbreviation'] for abbrev_info in all_found]
            found_text = f" Found correct: {', '.join(examples)}"
        
        error_text = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in all_errors[:5]]
            error_text = f" Format errors found: {', '.join(error_examples)}"
            if len(all_errors) > 5:
                error_text += f" (+{len(all_errors)-5} more)"
        
        return 0, f"âŒ Found only {total_count} correct Spanish abbreviations (required: {num}).{found_text}{error_text} Does not meet the requirement."

    

def has_correct_spanish_number_format(texts, max_errors):
    """æ£€æµ‹æ–‡æœ¬ä¸­è¥¿ç­ç‰™è¯­æ•°å­—æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå°æ•°ç‚¹ç”¨é€—å·ï¼Œåƒåˆ†ä½ç”¨ç‚¹ï¼Œè´§å¸ç¬¦å·åœ¨åï¼‰"""
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def is_correct_spanish_number(number_text):
        """æ£€æŸ¥æ•°å­—æ˜¯å¦ç¬¦åˆè¥¿ç­ç‰™è¯­æ ¼å¼"""
        # 1. å°äº1000çš„æ•´æ•°
        if re.match(r'^\d{1,3}$', number_text):
            return True
        # 2. å¸¦åƒåˆ†ä½çš„æ•´æ•°ï¼š1.234, 12.345.678
        if re.match(r'^\d{1,3}(?:\.\d{3})+$', number_text):
            return True
        # 3. å°æ•°ï¼ˆé€—å·ä½œå°æ•°ç‚¹ï¼‰ï¼š12,5, 1.234,56
        if re.match(r'^\d{1,3}(?:\.\d{3})*,\d+$', number_text):
            return True
        return False
    
    def add_thousands_separator(number_text):
        """ä¸ºæ•°å­—æ·»åŠ åƒåˆ†ä½åˆ†éš”ç¬¦"""
        if len(number_text) <= 3:
            return number_text
        
        # ä»å³åˆ°å·¦æ¯3ä½æ·»åŠ ç‚¹
        formatted = ''
        for i, digit in enumerate(reversed(number_text)):
            if i > 0 and i % 3 == 0:
                formatted = '.' + formatted
            formatted = digit + formatted
        return formatted
    
    def check_number_format_errors(text):
        """æ£€æŸ¥æ–‡æœ¬ä¸­çš„æ•°å­—æ ¼å¼é”™è¯¯"""
        format_errors = []
        correct_numbers = []
        processed_positions = set()
        
        print(f"Debug - æ£€æŸ¥æ–‡æœ¬: {text[:100]}...")
        
        # æ’é™¤ç”µè¯å·ç åŒºåŸŸ
        phone_patterns = [
            r'\b\d{2,3}[-.\s]\d{3}[-.\s]\d{3,4}\b',
            r'\b\+34[-.\s]?\d{2,3}[-.\s]\d{3}[-.\s]\d{3,4}\b',
            r'\b[679]\d{8}\b',
            r'\b9[1-8]\d{7}\b'
        ]
        
        phone_positions = set()
        for pattern in phone_patterns:
            for match in re.finditer(pattern, text):
                phone_positions.add(match.span())
        
        # ğŸ”§ ä¿®å¤ï¼šåˆ†åˆ«å¤„ç†è´§å¸å’Œæ™®é€šæ•°å­—
        # 1. å…ˆæ£€æŸ¥è´§å¸æ ¼å¼
        currency_patterns = [
            # é”™è¯¯æ ¼å¼ï¼šè´§å¸ç¬¦å·åœ¨å‰
            r'([\$â‚¬Â£Â¥])\s*(\d+(?:[,\.]\d+)*)',
            # æ­£ç¡®æ ¼å¼ï¼šæ•°å­— + ç©ºæ ¼ + è´§å¸ç¬¦å·
            r'(\d+(?:[,\.]\d+)*)\s+([\$â‚¬Â£Â¥])',
        ]
        
        for i, pattern in enumerate(currency_patterns):
            for match in re.finditer(pattern, text):
                full_match = match.group(0)
                position = match.span()
                groups = match.groups()
                
                print(f"Debug - æ‰¾åˆ°è´§å¸: '{full_match}', ç»„: {groups}")
                
                # è·³è¿‡ç”µè¯å·ç åŒºåŸŸ
                is_phone = any(pos[0] <= position[0] and position[1] <= pos[1] for pos in phone_positions)
                if is_phone:
                    continue
                
                # è·³è¿‡å·²å¤„ç†çš„ä½ç½®
                overlap = any(pos[0] < position[1] and pos[1] > position[0] for pos in processed_positions)
                if overlap:
                    continue
                
                if i == 0:  # è´§å¸ç¬¦å·åœ¨å‰ï¼ˆé”™è¯¯æ ¼å¼ï¼‰
                    currency_symbol, number_text = groups
                    
                    # è·³è¿‡çŸ­æ•°å­—
                    if len(number_text.replace(',', '').replace('.', '')) < 4:
                        continue
                    
                    # åˆ†ææ•°å­—æ ¼å¼å¹¶ç”Ÿæˆå»ºè®®
                    if re.match(r'\d+,\d{3}(?:,\d{3})*$', number_text):
                        # è‹±è¯­æ ¼å¼ï¼š$150,000 â†’ 150.000 $
                        corrected_number = number_text.replace(',', '.')
                        description = 'Formato inglÃ©s: sÃ­mbolo de moneda antes del nÃºmero y usa coma como separador de miles'
                        suggested_format = f"{corrected_number} {currency_symbol}"
                    elif re.match(r'\d+,\d{3}(?:,\d{3})*\.\d+$', number_text):
                        # è‹±è¯­æ ¼å¼ï¼š$1,234.56 â†’ 1.234,56 $
                        corrected_number = number_text.replace(',', '|').replace('.', ',').replace('|', '.')
                        description = 'Formato inglÃ©s: sÃ­mbolo de moneda antes del nÃºmero'
                        suggested_format = f"{corrected_number} {currency_symbol}"
                    elif '.' in number_text and re.search(r'\.\d{1,2}$', number_text):
                        # ä½¿ç”¨ç‚¹ä½œå°æ•°ç‚¹ï¼š$123.45 â†’ 123,45 $
                        corrected_number = re.sub(r'\.(\d{1,2})$', r',\1', number_text)
                        description = 'SÃ­mbolo de moneda antes del nÃºmero y usa punto como separador decimal'
                        suggested_format = f"{corrected_number} {currency_symbol}"
                    elif len(number_text) >= 4 and '.' not in number_text and ',' not in number_text:
                        # ç¼ºå°‘åƒåˆ†ä½ï¼š$150000 â†’ 150.000 $
                        corrected_number = add_thousands_separator(number_text)
                        description = 'SÃ­mbolo de moneda antes del nÃºmero y falta separador de miles'
                        suggested_format = f"{corrected_number} {currency_symbol}"
                    else:
                        # å…¶ä»–æƒ…å†µï¼šåªæ˜¯è´§å¸ç¬¦å·ä½ç½®é”™è¯¯
                        description = 'SÃ­mbolo de moneda debe ir despuÃ©s del nÃºmero con espacio'
                        suggested_format = f"{number_text} {currency_symbol}"
                    
                    format_errors.append({
                        'error': full_match,
                        'correct': suggested_format,
                        'position': position,
                        'description': description
                    })
                    print(f"Debug - âŒ è´§å¸æ ¼å¼é”™è¯¯: {full_match} â†’ {suggested_format}")
                    
                else:  # è´§å¸ç¬¦å·åœ¨åï¼ˆå¯èƒ½æ­£ç¡®ï¼‰
                    number_text, currency_symbol = groups
                    
                    # è·³è¿‡çŸ­æ•°å­—
                    if len(number_text.replace(',', '').replace('.', '')) < 4:
                        continue
                    
                    if is_correct_spanish_number(number_text):
                        correct_numbers.append({
                            'number': number_text,
                            'full_match': full_match,
                            'position': position,
                            'type': 'correct_currency_format'
                        })
                        print(f"Debug - âœ… æ­£ç¡®è´§å¸æ ¼å¼: {full_match}")
                    else:
                        # è´§å¸ç¬¦å·ä½ç½®æ­£ç¡®ï¼Œä½†æ•°å­—æ ¼å¼é”™è¯¯
                        if re.match(r'\d+,\d{3}(?:,\d{3})*$', number_text):
                            corrected_number = number_text.replace(',', '.')
                            description = 'Usa coma como separador de miles (debe usar puntos)'
                            suggested_format = f"{corrected_number} {currency_symbol}"
                        elif re.match(r'\d+,\d{3}(?:,\d{3})*\.\d+$', number_text):
                            corrected_number = number_text.replace(',', '|').replace('.', ',').replace('|', '.')
                            description = 'Formato de nÃºmero inglÃ©s (coma para miles, punto para decimales)'
                            suggested_format = f"{corrected_number} {currency_symbol}"
                        elif '.' in number_text and re.search(r'\.\d{1,2}$', number_text):
                            corrected_number = re.sub(r'\.(\d{1,2})$', r',\1', number_text)
                            description = 'Usa punto como separador decimal (debe usar coma)'
                            suggested_format = f"{corrected_number} {currency_symbol}"
                        else:
                            corrected_number = add_thousands_separator(number_text)
                            description = 'Falta separador de miles'
                            suggested_format = f"{corrected_number} {currency_symbol}"
                        
                        format_errors.append({
                            'error': full_match,
                            'correct': suggested_format,
                            'position': position,
                            'description': description
                        })
                        print(f"Debug - âŒ æ•°å­—æ ¼å¼é”™è¯¯: {full_match} â†’ {suggested_format}")
                
                processed_positions.add(position)
        
        # 2. æ£€æŸ¥æ™®é€šæ•°å­—ï¼ˆéè´§å¸ï¼‰
        number_pattern = r'\b(\d+(?:[,\.]\d+)*)\b'
        for match in re.finditer(number_pattern, text):
            number_text = match.group(1)
            position = match.span()
            
            # è·³è¿‡ç”µè¯å·ç åŒºåŸŸ
            is_phone = any(pos[0] <= position[0] and position[1] <= pos[1] for pos in phone_positions)
            if is_phone:
                continue
            
            # è·³è¿‡å·²å¤„ç†çš„ä½ç½®
            overlap = any(pos[0] < position[1] and pos[1] > position[0] for pos in processed_positions)
            if overlap:
                continue
            
            # è·³è¿‡çŸ­æ•°å­—
            if len(number_text.replace(',', '').replace('.', '')) < 4:
                continue
            
            if is_correct_spanish_number(number_text):
                correct_numbers.append({
                    'number': number_text,
                    'full_match': number_text,
                    'position': position,
                    'type': 'correct_number_format'
                })
                print(f"Debug - âœ… æ­£ç¡®æ•°å­—æ ¼å¼: {number_text}")
            else:
                # åˆ†æé”™è¯¯ç±»å‹
                suggested_format = ""
                description = ""
                
                if re.match(r'\d+,\d{3}(?:,\d{3})*$', number_text):
                    suggested_format = number_text.replace(',', '.')
                    description = 'Formato inglÃ©s: usa coma como separador de miles'
                elif re.match(r'\d+,\d{3}(?:,\d{3})*\.\d+$', number_text):
                    suggested_format = number_text.replace(',', '|').replace('.', ',').replace('|', '.')
                    description = 'Formato inglÃ©s: coma para miles, punto para decimales'
                elif '.' in number_text and re.search(r'\.\d{1,2}$', number_text):
                    suggested_format = re.sub(r'\.(\d{1,2})$', r',\1', number_text)
                    description = 'Usa punto como separador decimal'
                elif len(number_text) >= 4 and '.' not in number_text and ',' not in number_text:
                    suggested_format = add_thousands_separator(number_text)
                    description = 'Falta separador de miles'
                
                if suggested_format:
                    format_errors.append({
                        'error': number_text,
                        'correct': suggested_format,
                        'position': position,
                        'description': description
                    })
                    print(f"Debug - âŒ æ•°å­—æ ¼å¼é”™è¯¯: {number_text} â†’ {suggested_format}")
            
            processed_positions.add(position)
        
        return len(format_errors), format_errors, len(correct_numbers), correct_numbers
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„æ ¼å¼é”™è¯¯
    total_errors = 0
    all_errors = []
    all_correct = []
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_numbers = check_number_format_errors(text)
        total_errors += error_count
        all_errors.extend(errors)
        all_correct.extend(correct_numbers)
    
    print(f"Debug - æ€»é”™è¯¯æ•°: {total_errors}")
    print(f"Debug - æ€»æ­£ç¡®æ•°: {len(all_correct)}")
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_errors <= max_errors:
        correct_examples = [correct['full_match'] for correct in all_correct[:5]]
        correct_info = f"Found {len(all_correct)} correctly formatted numbers"
        if correct_examples:
            correct_info += f": {', '.join(correct_examples)}"
        
        error_info = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}' ({err['description']})" for err in all_errors[:3]]
            error_info = f" Format errors: {'; '.join(error_examples)}"
            if len(all_errors) > 3:
                error_info += f" (+{len(all_errors)-3} more)"
        
        return 1, f"âœ… Spanish number format is acceptable. {correct_info}. Found {total_errors} format errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = [f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})" for error in all_errors[:5]]
        error_summary = "; ".join(error_details)
        if len(all_errors) > 5:
            error_summary += f" ... (+{len(all_errors)-5} more errors)"
        
        return 0, f"âŒ Found {total_errors} Spanish number format errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."


def has_correct_spanish_currency_format(texts, max_errors):
    """æ£€æµ‹æ–‡æœ¬ä¸­è¥¿ç­ç‰™è¯­é‡‘é¢æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆè´§å¸ç¬¦å·åœ¨æ•°å­—ä¹‹åï¼Œæœ‰ç©ºæ ¼ï¼‰"""
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_currency_format_errors(text):
        """æ£€æŸ¥æ–‡æœ¬ä¸­çš„é‡‘é¢æ ¼å¼é”™è¯¯"""
        
        format_errors = []
        correct_currencies = []
        processed_positions = set()
        
        print(f"Debug - æ£€æŸ¥é‡‘é¢æ ¼å¼ï¼Œæ–‡æœ¬: {text[:100]}...")
        
        # å®šä¹‰è´§å¸ç¬¦å·å’Œä»£ç 
        currency_symbols = ['â‚¬', '$', 'Â£', 'Â¥', 'â‚¹', 'â‚½', 'â‚©', 'â‚ª', 'â‚¦', 'â‚¡', 'â‚µ', 'â‚´']
        currency_codes = ['EUR', 'USD', 'GBP', 'JPY', 'CNY', 'RUB', 'KRW', 'MXN', 'ARS', 'COP', 'PEN', 'CLP']
        
        # ğŸ”§ ä¿®å¤ï¼šæ›´å…¨é¢çš„è´§å¸åŒ¹é…æ¨¡å¼
        currency_patterns = [
            # æ­£ç¡®æ ¼å¼ï¼šæ•°å­— + ç©ºæ ¼ + è´§å¸ç¬¦å·/ä»£ç 
            r'(\d+(?:\.\d{3})*(?:,\d{1,2})?)\s+([â‚¬$Â£Â¥â‚¹â‚½â‚©â‚ªâ‚¦â‚¡â‚µâ‚´])',
            r'(\d+(?:\.\d{3})*(?:,\d{1,2})?)\s+(EUR|USD|GBP|JPY|CNY|RUB|KRW|MXN|ARS|COP|PEN|CLP)\b',
            
            # é”™è¯¯æ ¼å¼1ï¼šè´§å¸ç¬¦å· + æ•°å­—ï¼ˆè‹±è¯­æ ¼å¼ï¼‰
            r'([â‚¬$Â£Â¥â‚¹â‚½â‚©â‚ªâ‚¦â‚¡â‚µâ‚´])\s*(\d+(?:[,\.]\d+)*)',
            r'(EUR|USD|GBP|JPY|CNY|RUB|KRW|MXN|ARS|COP|PEN|CLP)\s+(\d+(?:[,\.]\d+)*)',
            
            # é”™è¯¯æ ¼å¼2ï¼šæ•°å­— + è´§å¸ç¬¦å·ï¼ˆæ— ç©ºæ ¼ï¼‰
            r'(\d+(?:[,\.]\d+)*)([â‚¬$Â£Â¥â‚¹â‚½â‚©â‚ªâ‚¦â‚¡â‚µâ‚´])',
            r'(\d+(?:[,\.]\d+)*)(EUR|USD|GBP|JPY|CNY|RUB|KRW|MXN|ARS|COP|PEN|CLP)\b',
        ]
        
        found_currencies = []
        
        # æ”¶é›†æ‰€æœ‰è´§å¸è¡¨è¾¾å¼
        for i, pattern in enumerate(currency_patterns):
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                found_currencies.append({
                    'full_match': match.group(),
                    'position': match.span(),
                    'groups': match.groups(),
                    'pattern_index': i
                })
        
        print(f"Debug - æ‰¾åˆ°çš„è´§å¸è¡¨è¾¾å¼: {[fc['full_match'] for fc in found_currencies]}")
        
        # ğŸ”§ ä¿®å¤ï¼šæŒ‰ä½ç½®æ’åºï¼Œé¿å…é‡å¤å¤„ç†
        found_currencies.sort(key=lambda x: x['position'][0])
        
        # åˆ†ææ¯ä¸ªæ‰¾åˆ°çš„è´§å¸è¡¨è¾¾å¼
        for currency_info in found_currencies:
            full_text = currency_info['full_match']
            position = currency_info['position']
            groups = currency_info['groups']
            pattern_index = currency_info['pattern_index']
            
            # è·³è¿‡å·²å¤„ç†çš„ä½ç½®
            overlap = any(pos[0] < position[1] and pos[1] > position[0] for pos in processed_positions)
            if overlap:
                continue
            
            print(f"Debug - å¤„ç†è´§å¸: '{full_text}', æ¨¡å¼: {pattern_index}")
            
            is_correct = False
            error_type = ""
            description = ""
            suggested_format = ""
            
            if len(groups) == 2:
                first, second = groups
                
                # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®åŒ¹é…çš„æ¨¡å¼åˆ¤æ–­æ ¼å¼
                if pattern_index <= 1:
                    # æ­£ç¡®æ ¼å¼ï¼šæ•°å­— + ç©ºæ ¼ + è´§å¸
                    is_correct = True
                    print(f"Debug - âœ… æ­£ç¡®æ ¼å¼: {full_text}")
                    
                elif pattern_index <= 3:
                    # é”™è¯¯æ ¼å¼ï¼šè´§å¸ + æ•°å­—ï¼ˆè‹±è¯­æ ¼å¼ï¼‰
                    error_type = 'currency_before_number'
                    description = 'SÃ­mbolo de moneda antes del nÃºmero (debe ir despuÃ©s con espacio)'
                    
                    # ä¿®æ­£æ•°å­—æ ¼å¼ï¼ˆè‹±è¯­ â†’ è¥¿ç­ç‰™è¯­ï¼‰
                    corrected_number = second
                    if ',' in corrected_number and '.' in corrected_number:
                        # 1,234.56 â†’ 1.234,56
                        corrected_number = corrected_number.replace(',', '|').replace('.', ',').replace('|', '.')
                    elif ',' in corrected_number and len(corrected_number.split(',')[-1]) == 3:
                        # 150,000 â†’ 150.000
                        corrected_number = corrected_number.replace(',', '.')
                    elif '.' in corrected_number and len(corrected_number.split('.')[-1]) <= 2:
                        # 150.50 â†’ 150,50
                        corrected_number = re.sub(r'\.(\d{1,2})$', r',\1', corrected_number)
                    
                    suggested_format = f"{corrected_number} {first}"
                    print(f"Debug - âŒ è´§å¸åœ¨å‰: {full_text} â†’ {suggested_format}")
                    
                else:
                    # é”™è¯¯æ ¼å¼ï¼šæ•°å­— + è´§å¸ï¼ˆæ— ç©ºæ ¼ï¼‰
                    error_type = 'no_space_before_currency'
                    description = 'Falta espacio entre nÃºmero y sÃ­mbolo de moneda'
                    
                    # ä¿®æ­£æ•°å­—æ ¼å¼
                    corrected_number = first
                    if ',' in corrected_number and len(corrected_number.split(',')[-1]) == 3:
                        # 150,000 â†’ 150.000
                        corrected_number = corrected_number.replace(',', '.')
                    elif '.' in corrected_number and len(corrected_number.split('.')[-1]) <= 2:
                        # 150.50 â†’ 150,50
                        corrected_number = re.sub(r'\.(\d{1,2})$', r',\1', corrected_number)
                    
                    suggested_format = f"{corrected_number} {second}"
                    print(f"Debug - âŒ æ— ç©ºæ ¼: {full_text} â†’ {suggested_format}")
            
            # è®°å½•ç»“æœ
            if is_correct:
                correct_currencies.append({
                    'currency': full_text.strip(),
                    'position': position,
                    'type': 'correct_spanish_format'
                })
            elif suggested_format:
                format_errors.append({
                    'error': full_text.strip(),
                    'correct': suggested_format,
                    'type': error_type,
                    'position': position,
                    'description': description
                })
            
            processed_positions.add(position)
        
        print(f"Debug - æ­£ç¡®é‡‘é¢: {len(correct_currencies)}, é”™è¯¯é‡‘é¢: {len(format_errors)}")
        return len(format_errors), format_errors, len(correct_currencies), correct_currencies
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„æ ¼å¼é”™è¯¯
    total_errors = 0
    all_errors = []
    all_correct = []
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_currencies = check_currency_format_errors(text)
        total_errors += error_count
        all_errors.extend(errors)
        all_correct.extend(correct_currencies)
    
    print(f"Debug - æ€»é”™è¯¯æ•°: {total_errors}, æ€»æ­£ç¡®æ•°: {len(all_correct)}")
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_errors <= max_errors:
        correct_examples = [correct['currency'] for correct in all_correct[:5]]
        correct_info = f"Found {len(all_correct)} correctly formatted currencies"
        if correct_examples:
            correct_info += f": {', '.join(correct_examples)}"
        
        error_info = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}' ({err['description']})" for err in all_errors[:3]]
            error_info = f" Currency format errors: {'; '.join(error_examples)}"
            if len(all_errors) > 3:
                error_info += f" (+{len(all_errors)-3} more)"
        
        return 1, f"âœ… Spanish currency format is acceptable. {correct_info}. Found {total_errors} format errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = [f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})" for error in all_errors[:5]]
        error_summary = "; ".join(error_details)
        if len(all_errors) > 5:
            error_summary += f" ... (+{len(all_errors)-5} more errors)"
        
        return 0, f"âŒ Found {total_errors} Spanish currency format errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."



def has_correct_spanish_phone_format(texts, max_errors):
    """æ£€æµ‹æ–‡æœ¬ä¸­è¥¿ç­ç‰™è¯­ç”µè¯å·ç æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆä¸‰ä½ä¸€ç»„ï¼Œç©ºæ ¼åˆ†éš”ï¼‰"""
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_phone_format_errors(text):
        """æ£€æŸ¥æ–‡æœ¬ä¸­çš„ç”µè¯å·ç æ ¼å¼é”™è¯¯"""
        
        format_errors = []
        correct_phones = []
        processed_positions = set()
        
        # 1. æ£€æµ‹æ­£ç¡®çš„è¥¿ç­ç‰™è¯­ç”µè¯å·ç æ ¼å¼
        correct_patterns = [
            # æ ‡å‡†æ‰‹æœºå·ç ï¼š600 123 456 (ä¸‰ä½-ä¸‰ä½-ä¸‰ä½)
            r'\b[679]\d{2}\s\d{3}\s\d{3}\b',
            # å›ºå®šç”µè¯ï¼š91 123 45 67 (ä¸¤ä½åŒºå·-ä¸‰ä½-ä¸¤ä½-ä¸¤ä½)
            r'\b9[1-8]\s\d{3}\s\d{2}\s\d{2}\b',
            # å›ºå®šç”µè¯ï¼š958 12 34 56 (ä¸‰ä½åŒºå·-ä¸¤ä½-ä¸¤ä½-ä¸¤ä½)
            r'\b9[0-9]{2}\s\d{2}\s\d{2}\s\d{2}\b',
            # å›½é™…æ ¼å¼ï¼š+34 600 123 456
            r'\+34\s[679]\d{2}\s\d{3}\s\d{3}\b',
            # å›½é™…æ ¼å¼å›ºå®šç”µè¯ï¼š+34 91 123 45 67
            r'\+34\s9[1-8]\s\d{3}\s\d{2}\s\d{2}\b'
        ]
        
        for pattern in correct_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                position = match.span()
                overlap = any(pos[0] < position[1] and pos[1] > position[0] for pos in processed_positions)
                if not overlap:
                    correct_phones.append({
                        'phone': match.group().strip(),
                        'position': position,
                        'type': 'correct_spanish_format'
                    })
                    processed_positions.add(position)
        
        # 2. ğŸ”§ ä¿®å¤ï¼šæ›´å¹¿æ³›çš„ç”µè¯å·ç æ£€æµ‹æ¨¡å¼
        all_phone_patterns = [
            # å„ç§åˆ†éš”ç¬¦çš„ç”µè¯å·ç ï¼šè¿å­—ç¬¦ã€ç‚¹ã€ç©ºæ ¼
            r'\b(?:\+\d{1,3}[-.\s]?)?\d{2,4}[-.\s]\d{3,4}[-.\s]?\d{2,4}\b',
            # æ— åˆ†éš”ç¬¦çš„é•¿å·ç 
            r'\b(?:\+\d{1,3})?\d{7,12}\b',
            # çŸ­å·ç æ ¼å¼ï¼ˆå¦‚555-1234ï¼‰
            r'\b\d{3,4}[-.\s]?\d{4}\b',
            # å¸¦æ‹¬å·çš„åŒºå·æ ¼å¼
            r'\b\(\d{2,4}\)\s?\d{3,4}[-.\s]?\d{2,4}\b'
        ]
        
        # æ£€æµ‹æ‰€æœ‰å¯èƒ½çš„ç”µè¯å·ç 
        all_found_phones = []
        for pattern in all_phone_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                position = match.span()
                phone_text = match.group().strip()
                
                # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯ç”µè¯å·ç çš„æ•°å­—ï¼ˆå¦‚å¹´ä»½ã€æ—¶é—´ç­‰ï¼‰
                digits_only = re.sub(r'[^\d]', '', phone_text)
                if len(digits_only) >= 4 and len(digits_only) <= 15:
                    # æ£€æŸ¥æ˜¯å¦ä¸å·²å¤„ç†çš„ä½ç½®é‡å 
                    overlap = any(pos[0] < position[1] and pos[1] > position[0] for pos in processed_positions)
                    if not overlap:
                        all_found_phones.append({
                            'phone': phone_text,
                            'position': position,
                            'digits': digits_only
                        })
                        processed_positions.add(position)
        
        # 3. æ£€æŸ¥æ‰¾åˆ°çš„ç”µè¯å·ç æ ¼å¼æ˜¯å¦æ­£ç¡®
        for phone_info in all_found_phones:
            phone_text = phone_info['phone']
            position = phone_info['position']
            digits = phone_info['digits']
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯æ­£ç¡®æ ¼å¼
            is_correct_format = False
            for pattern in correct_patterns:
                if re.match(pattern, phone_text):
                    is_correct_format = True
                    break
            
            if not is_correct_format:
                # ç”Ÿæˆæ­£ç¡®æ ¼å¼å»ºè®®
                if digits.startswith('+34'):
                    country_code = '+34'
                    phone_digits = digits[2:]
                elif digits.startswith('34') and len(digits) > 9:
                    country_code = '+34'
                    phone_digits = digits[2:]
                else:
                    country_code = ''
                    phone_digits = digits
                
                # æ ¹æ®å·ç é•¿åº¦å’Œå¼€å¤´æ•°å­—æ ¼å¼åŒ–
                if len(phone_digits) == 9:
                    if phone_digits.startswith(('6', '7', '9')):
                        if phone_digits.startswith(('6', '7')):
                            # æ‰‹æœºå·ç ï¼šXXX XXX XXX
                            suggested_format = f"{phone_digits[:3]} {phone_digits[3:6]} {phone_digits[6:9]}"
                        elif phone_digits.startswith('9') and len(phone_digits) > 1 and phone_digits[1] in '12345678':
                            # å›ºå®šç”µè¯ï¼š9X XXX XX XX
                            suggested_format = f"{phone_digits[:2]} {phone_digits[2:5]} {phone_digits[5:7]} {phone_digits[7:9]}"
                        else:
                            # å…¶ä»–9å¼€å¤´ï¼šXXX XXX XXX
                            suggested_format = f"{phone_digits[:3]} {phone_digits[3:6]} {phone_digits[6:9]}"
                    else:
                        # å…¶ä»–9ä½å·ç ï¼šXXX XXX XXX
                        suggested_format = f"{phone_digits[:3]} {phone_digits[3:6]} {phone_digits[6:9]}"
                elif len(phone_digits) == 8:
                    # 8ä½å›ºå®šç”µè¯ï¼šXXX XX XXX
                    suggested_format = f"{phone_digits[:3]} {phone_digits[3:5]} {phone_digits[5:8]}"
                elif len(phone_digits) == 7:
                    # 7ä½å·ç ï¼šXXX XXXX
                    suggested_format = f"{phone_digits[:3]} {phone_digits[3:7]}"
                elif len(phone_digits) == 4:
                    # 4ä½çŸ­å·ç ï¼šXXXX (ä¿æŒåŸæ ·)
                    suggested_format = phone_digits
                else:
                    # å…¶ä»–é•¿åº¦ï¼šä¸‰ä½åˆ†ç»„
                    groups = [phone_digits[i:i+3] for i in range(0, len(phone_digits), 3)]
                    suggested_format = ' '.join(groups)
                
                if country_code:
                    suggested_format = f"{country_code} {suggested_format}"
                
                # åˆ¤æ–­é”™è¯¯ç±»å‹
                if '-' in phone_text:
                    error_type = 'hyphen_separator'
                    description = 'Usa guiones como separadores (debe usar espacios)'
                elif '.' in phone_text:
                    error_type = 'dot_separator'
                    description = 'Usa puntos como separadores (debe usar espacios)'
                elif not re.search(r'[\s\-.]', phone_text):
                    error_type = 'no_separator'
                    description = 'Sin separadores (debe agrupar con espacios)'
                else:
                    error_type = 'incorrect_format'
                    description = 'Formato incorrecto (debe seguir formato espaÃ±ol estÃ¡ndar)'
                
                format_errors.append({
                    'error': phone_text,
                    'correct': suggested_format,
                    'type': error_type,
                    'position': position,
                    'description': description
                })
        
        return len(format_errors), format_errors, len(correct_phones), correct_phones
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„æ ¼å¼é”™è¯¯
    total_errors = 0
    all_errors = []
    all_correct = []
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_phones = check_phone_format_errors(text)
        total_errors += error_count
        all_errors.extend(errors)
        all_correct.extend(correct_phones)
    
    # ğŸ†• ä¿ç•™ï¼šæ£€æŸ¥æ˜¯å¦å®Œå…¨æ²¡æœ‰ç”µè¯å·ç 
    total_phones_found = len(all_correct) + len(all_errors)
    
    if total_phones_found == 0:
        # æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç”µè¯å·ç ï¼ˆæ­£ç¡®æˆ–é”™è¯¯æ ¼å¼éƒ½æ²¡æœ‰ï¼‰
        total_errors += 1
        all_errors.append({
            'error': 'No phone number found',
            'correct': 'Should include contact phone number (e.g., 91 234 56 78 or 600 123 456)',
            'type': 'missing_phone_number',
            'description': 'Falta nÃºmero de telÃ©fono de contacto requerido'
        })
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_errors <= max_errors:
        if len(all_correct) > 0:
            correct_examples = [correct['phone'] for correct in all_correct[:5]]
            correct_info = f"Found {len(all_correct)} correctly formatted phone numbers: {', '.join(correct_examples)}"
        else:
            correct_info = "Found 0 correctly formatted phone numbers"
        
        error_info = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}' ({err['description']})" for err in all_errors[:3]]
            error_info = f" Errors found: {'; '.join(error_examples)}"
            if len(all_errors) > 3:
                error_info += f" (and {len(all_errors)-3} more)"
        
        return 1, f"âœ… Spanish phone number format is acceptable. {correct_info}. Found {total_errors} errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        if len(all_correct) > 0:
            correct_info = f"Found {len(all_correct)} correctly formatted phone numbers. "
        else:
            correct_info = "No correctly formatted phone numbers found. "
        
        error_details = [f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})" for error in all_errors[:5]]
        error_summary = "; ".join(error_details)
        if len(all_errors) > 5:
            error_summary += f" (and {len(all_errors)-5} more errors)"
        
        return 0, f"âŒ Found {total_errors} phone number errors (allowed: {max_errors}). {correct_info}Errors: {error_summary}. Does not meet the requirement."


def has_correct_spanish_question_accents(texts, max_errors):
    """æ£€æµ‹è¥¿ç­ç‰™è¯­ç–‘é—®å¥ä¸­çš„é‡éŸ³ç¬¦å·ä½¿ç”¨æ˜¯å¦æ­£ç¡®"""
    import re
    
    def clean_up_text(text):
        """åŸºç¡€æ–‡æœ¬æ¸…ç†"""
        return text.strip()
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_question_accent_errors(text):
        """æ£€æŸ¥ç–‘é—®å¥ä¸­çš„é‡éŸ³ç¬¦å·é”™è¯¯"""
        
        # æ­£ç¡®çš„ç–‘é—®è¯ï¼ˆå¸¦é‡éŸ³ï¼‰
        correct_question_words = {
            'quÃ©': 'what/which',
            'cuÃ¡l': 'which', 
            'cuÃ¡les': 'which (plural)',
            'quiÃ©n': 'who',
            'quiÃ©nes': 'who (plural)',
            'dÃ³nde': 'where',
            'cuÃ¡ndo': 'when',
            'cÃ³mo': 'how',
            'cuÃ¡nto': 'how much',
            'cuÃ¡nta': 'how much (fem)',
            'cuÃ¡ntos': 'how many (masc)',
            'cuÃ¡ntas': 'how many (fem)',
            'por quÃ©': 'why',
            'para quÃ©': 'what for',
            'adÃ³nde': 'where to',
            'de dÃ³nde': 'where from',
            'hasta cuÃ¡ndo': 'until when',
            'desde cuÃ¡ndo': 'since when'
        }
        
        # é”™è¯¯çš„ç–‘é—®è¯ï¼ˆæ— é‡éŸ³ï¼‰
        incorrect_question_words = {
            'que': 'quÃ©',
            'cual': 'cuÃ¡l',
            'cuales': 'cuÃ¡les', 
            'quien': 'quiÃ©n',
            'quienes': 'quiÃ©nes',
            'donde': 'dÃ³nde',
            'cuando': 'cuÃ¡ndo',
            'como': 'cÃ³mo',
            'cuanto': 'cuÃ¡nto',
            'cuanta': 'cuÃ¡nta',
            'cuantos': 'cuÃ¡ntos',
            'cuantas': 'cuÃ¡ntas',
            'por que': 'por quÃ©',
            'para que': 'para quÃ©',
            'adonde': 'adÃ³nde',
            'de donde': 'de dÃ³nde',
            'hasta cuando': 'hasta cuÃ¡ndo',
            'desde cuando': 'desde cuÃ¡ndo'
        }
        
        format_errors = []
        correct_uses = []
        
        # ğŸ”§ æ”¹è¿›çš„ç–‘é—®å¥è¯†åˆ« - æ›´ç²¾ç¡®çš„æ¨¡å¼
        question_sentences = []
        
        # æ–¹æ³•1: æ ‡å‡†è¥¿ç­ç‰™è¯­ç–‘é—®å¥ Â¿...?
        standard_questions = re.findall(r'Â¿[^Â¿?]*\?', text, re.DOTALL)
        question_sentences.extend(standard_questions)
        
        # æ–¹æ³•2: ç®€å•é—®å·ç»“å°¾ï¼ˆä½†è¦æ’é™¤ç¼©å†™ç­‰ï¼‰
        simple_questions = re.findall(r'[^.!Â¿]*[A-Za-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼ÃÃ‰ÃÃ“ÃšÃ‘Ãœ][^.!Â¿]*\?', text, re.DOTALL)
        question_sentences.extend(simple_questions)
        
        # ğŸ†• å»é‡å¹¶æ¸…ç†
        unique_questions = []
        seen_questions = set()
        
        for question in question_sentences:
            # æ¸…ç†é—®é¢˜æ–‡æœ¬
            clean_q = re.sub(r'\s+', ' ', question.strip())
            clean_q = clean_q.strip('Â¿?').strip()
            
            # è·³è¿‡å¤ªçŸ­çš„"é—®é¢˜"ï¼ˆå¯èƒ½æ˜¯ç¼©å†™æˆ–è¯¯è¯†åˆ«ï¼‰
            if len(clean_q) < 10:
                continue
                
            # å»é‡
            if clean_q.lower() not in seen_questions:
                seen_questions.add(clean_q.lower())
                unique_questions.append(question.strip())
        
        total_questions = len(unique_questions)
        questions_with_question_words = 0
        
        for question in unique_questions:
            question_has_question_word = False
            question_clean = question.strip()
            
            # ğŸ”§ æ£€æŸ¥æ­£ç¡®çš„ç–‘é—®è¯ - æ”¹è¿›åŒ¹é…
            for correct_word in correct_question_words:
                if ' ' in correct_word:
                    # å¤åˆç–‘é—®è¯å¦‚ "por quÃ©"
                    pattern = r'\b' + re.escape(correct_word) + r'\b'
                else:
                    # å•ä¸ªç–‘é—®è¯ - ç¡®ä¿è¯è¾¹ç•Œ
                    pattern = r'\b' + re.escape(correct_word) + r'\b'
                
                if re.search(pattern, question_clean, re.IGNORECASE):
                    correct_uses.append({
                        'word': correct_word,
                        'sentence': question_clean[:60] + "..." if len(question_clean) > 60 else question_clean,
                        'type': 'correct_accent'
                    })
                    question_has_question_word = True
            
            # ğŸ”§ æ£€æŸ¥é”™è¯¯çš„ç–‘é—®è¯ - é¿å…è¯¯æŠ¥
            for incorrect_word, correct_word in incorrect_question_words.items():
                if ' ' in incorrect_word:
                    pattern = r'\b' + re.escape(incorrect_word) + r'\b'
                else:
                    pattern = r'\b' + re.escape(incorrect_word) + r'\b'
                
                # ğŸ†• ç‰¹æ®Šå¤„ç†ï¼šé¿å…è¯¯æŠ¥å¸¸è§è¯æ±‡
                # "que" åœ¨å¾ˆå¤šæƒ…å†µä¸‹ä¸æ˜¯ç–‘é—®è¯
                if incorrect_word == 'que':
                    # åªåœ¨æ˜ç¡®çš„ç–‘é—®å¥å¼€å¤´æˆ–ç‰¹å®šæ¨¡å¼ä¸­æ‰æŠ¥é”™
                    if re.search(r'Â¿\s*que\b|^que\b.*\?', question_clean, re.IGNORECASE):
                        matches = re.findall(pattern, question_clean, re.IGNORECASE)
                        for match in matches:
                            format_errors.append({
                                'error': match,
                                'correct': correct_word,
                                'sentence': question_clean[:60] + "..." if len(question_clean) > 60 else question_clean,
                                'description': f'Falta acento en palabra interrogativa'
                            })
                            question_has_question_word = True
                else:
                    # å…¶ä»–ç–‘é—®è¯çš„å¸¸è§„æ£€æŸ¥
                    if re.search(pattern, question_clean, re.IGNORECASE):
                        matches = re.findall(pattern, question_clean, re.IGNORECASE)
                        for match in matches:
                            format_errors.append({
                                'error': match,
                                'correct': correct_word,
                                'sentence': question_clean[:60] + "..." if len(question_clean) > 60 else question_clean,
                                'description': f'Falta acento en palabra interrogativa'
                            })
                            question_has_question_word = True
            
            if question_has_question_word:
                questions_with_question_words += 1
        
        return len(format_errors), format_errors, len(correct_uses), correct_uses, total_questions, questions_with_question_words
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„é”™è¯¯
    total_errors = 0
    all_errors = []
    all_correct = []
    total_questions_count = 0
    total_questions_with_words = 0
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_uses, questions_count, questions_with_words = check_question_accent_errors(text)
        total_errors += error_count
        all_errors.extend(errors)
        all_correct.extend(correct_uses)
        total_questions_count += questions_count
        total_questions_with_words += questions_with_words
    
    # ğŸ”§ å»é‡å¤„ç† - é¿å…é‡å¤è®¡ç®—ç›¸åŒçš„é”™è¯¯
    unique_errors = []
    seen_errors = set()
    for error in all_errors:
        error_key = f"{error['error']}_{error['correct']}"
        if error_key not in seen_errors:
            seen_errors.add(error_key)
            unique_errors.append(error)
    
    unique_correct = []
    seen_correct = set()
    for correct in all_correct:
        correct_key = f"{correct['word']}"
        if correct_key not in seen_correct:
            seen_correct.add(correct_key)
            unique_correct.append(correct)
    
    total_errors = len(unique_errors)
    
    # ğŸ”§ æ”¹è¿›çš„ç»“æœåˆ¤æ–­é€»è¾‘
    if total_errors <= max_errors:
        # ğŸ†• ç‰¹æ®Šæƒ…å†µå¤„ç† - æ²¡æœ‰ç–‘é—®è¯çš„æƒ…å†µ
        if total_questions_count > 0 and total_questions_with_words == 0:
            return 1, f"âœ… Spanish question word accents are correct. No interrogative pronouns found in {total_questions_count} question{'s' if total_questions_count != 1 else ''} (likely yes/no questions or polite requests). This is acceptable. Requirement met."
        
        # æœ‰ç–‘é—®è¯çš„æƒ…å†µ
        correct_info = ""
        if unique_correct:
            correct_examples = [f"'{correct['word']}'" for correct in unique_correct[:5]]
            correct_info = f"Found {len(unique_correct)} correct question words: {', '.join(correct_examples)}"
            if len(unique_correct) > 5:
                correct_info += f" ... (+{len(unique_correct)-5} more)"
        
        # ç–‘é—®å¥ç»Ÿè®¡ä¿¡æ¯
        question_info = f"Analyzed {total_questions_count} question{'s' if total_questions_count != 1 else ''}"
        if total_questions_with_words > 0:
            question_info += f" ({total_questions_with_words} with interrogative words)"
        
        # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        error_info = ""
        if unique_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in unique_errors[:2]]
            error_info = f" Minor errors found: {'; '.join(error_examples)}"
            if len(unique_errors) > 2:
                error_info += f" (+{len(unique_errors)-2} more)"
        
        success_msg = f"âœ… Spanish question word accents are correct. {question_info}."
        if correct_info:
            success_msg += f" {correct_info}."
        success_msg += f" Found {total_errors} error{'s' if total_errors != 1 else ''} (allowed: {max_errors}).{error_info} Requirement met."
        
        return 1, success_msg
    
    else:
        # æ„å»ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_details = []
        for error in unique_errors[:3]:
            error_details.append(f"'{error['error']}' â†’ '{error['correct']}' in \"{error['sentence']}\"")
        if len(unique_errors) > 3:
            error_details.append(f"... and {len(unique_errors)-3} more errors")
        error_summary = "; ".join(error_details)
        
        question_info = f"Analyzed {total_questions_count} question{'s' if total_questions_count != 1 else ''}"
        if total_questions_with_words > 0:
            question_info += f" ({total_questions_with_words} with interrogative words)"
        
        return 0, f"âŒ Found {total_errors} question word accent error{'s' if total_errors != 1 else ''} (allowed: {max_errors}). {question_info}. Errors: {error_summary}. Does not meet the requirement."




def has_correct_spanish_date_names_case(texts, max_errors):
    """æ£€æµ‹è¥¿ç­ç‰™è¯­æœˆä»½/æ˜ŸæœŸåç§°æ˜¯å¦é¦–å­—æ¯å°å†™"""
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_date_names_case_errors(text):
        """æ£€æŸ¥æœˆä»½/æ˜ŸæœŸåç§°å¤§å°å†™é”™è¯¯"""
        
        # æ­£ç¡®çš„æœˆä»½åç§°ï¼ˆå°å†™ï¼‰
        correct_months = [
            'enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio',
            'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre'
        ]
        
        # æ­£ç¡®çš„æ˜ŸæœŸåç§°ï¼ˆå°å†™ï¼‰
        correct_weekdays = [
            'lunes', 'martes', 'miÃ©rcoles', 'jueves', 'viernes', 'sÃ¡bado', 'domingo'
        ]
        
        format_errors = []
        correct_uses = []
        
        # æ£€æŸ¥æœˆä»½
        for month in correct_months:
            # æŸ¥æ‰¾æ­£ç¡®çš„å°å†™å½¢å¼
            correct_matches = re.finditer(r'\b' + re.escape(month) + r'\b', text)
            for match in correct_matches:
                correct_uses.append({
                    'word': match.group(),
                    'type': 'month',
                    'position': match.span()
                })
            
            # æŸ¥æ‰¾é”™è¯¯çš„å¤§å†™å½¢å¼
            capitalized = month.capitalize()
            error_matches = re.finditer(r'\b' + re.escape(capitalized) + r'\b', text)
            for match in error_matches:
                format_errors.append({
                    'error': match.group(),
                    'correct': month,
                    'type': 'month',
                    'position': match.span(),
                    'description': 'Nombre de mes debe empezar con minÃºscula'
                })
        
        # æ£€æŸ¥æ˜ŸæœŸ
        for weekday in correct_weekdays:
            # æŸ¥æ‰¾æ­£ç¡®çš„å°å†™å½¢å¼
            correct_matches = re.finditer(r'\b' + re.escape(weekday) + r'\b', text)
            for match in correct_matches:
                correct_uses.append({
                    'word': match.group(),
                    'type': 'weekday',
                    'position': match.span()
                })
            
            # æŸ¥æ‰¾é”™è¯¯çš„å¤§å†™å½¢å¼
            capitalized = weekday.capitalize()
            error_matches = re.finditer(r'\b' + re.escape(capitalized) + r'\b', text)
            for match in error_matches:
                format_errors.append({
                    'error': match.group(),
                    'correct': weekday,
                    'type': 'weekday',
                    'position': match.span(),
                    'description': 'Nombre de dÃ­a debe empezar con minÃºscula'
                })
        
        return len(format_errors), format_errors, len(correct_uses), correct_uses
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„é”™è¯¯
    total_errors = 0
    all_errors = []
    all_correct = []
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_uses = check_date_names_case_errors(text)
        total_errors += error_count
        all_errors.extend(errors)
        all_correct.extend(correct_uses)
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_errors <= max_errors:
        correct_examples = [f"'{correct['word']}'" for correct in all_correct[:5]]
        correct_info = f"Found {len(all_correct)} correct date names" + (f": {', '.join(correct_examples)}" if correct_examples else "")
        
        error_info = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in all_errors]
            error_info = f" Date name case errors: {'; '.join(error_examples)}"
        
        return 1, f"âœ… Spanish date name cases are correct. {correct_info}. Found {total_errors} errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = [f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})" for error in all_errors]
        error_summary = "; ".join(error_details)
        
        return 0, f"âŒ Found {total_errors} date name case errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."

def has_correct_spanish_address_format(texts, max_errors):
    """æ£€æµ‹è¥¿ç­ç‰™è¯­åœ°å€æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆC/, Av., Âºç­‰ç¼©å†™ï¼‰"""
    import re
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_address_format_errors(text):
        """æ£€æŸ¥åœ°å€æ ¼å¼é”™è¯¯"""
        
        format_errors = []
        correct_addresses = []
        seen_errors = set()  # é˜²æ­¢é‡å¤è®¡æ•°
        
        # æ­£ç¡®çš„åœ°å€æ ¼å¼æ¨¡å¼
        correct_patterns = [
            r'\bC/\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\s]+,?\s*(?:nÃºmero\s+)?\d+(?:\s+\d+Âº[A-Z]?)?\b',
            r'\bAv\.\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\s]+,?\s*(?:nÃºmero\s+)?\d+(?:\s+\d+Âº[A-Z]?)?\b',
            r'\bPlaza\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\s]+,?\s*(?:nÃºmero\s+)?\d+(?:\s+\d+Âº[A-Z]?)?\b',
            r'\b\d+Âº[A-Z]?\b'
        ]
        
        for pattern in correct_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                correct_addresses.append({
                    'address': match.group().strip(),
                    'position': match.span(),
                    'type': 'correct_spanish_address'
                })
        
        # é”™è¯¯çš„åœ°å€æ ¼å¼æ¨¡å¼
        error_patterns = [
            {
                'pattern': r'\bCalle\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\s]+,?\s*(?:nÃºmero\s+)?\d+',
                'type': 'full_street_name',
                'description': 'Debe usar "C/" en lugar de "Calle"'
            },
            {
                'pattern': r'\bAvenida\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\s]+,?\s*(?:nÃºmero\s+)?\d+',
                'type': 'full_avenue_name',
                'description': 'Debe usar "Av." en lugar de "Avenida"'
            },
            {
                'pattern': r'\bpiso\s+\d+\b',
                'type': 'full_floor_word',
                'description': 'Debe usar formato "Âº" en lugar de "piso"'
            },
            {
                'pattern': r'\b\d+[A-Z]\b(?!Âº)',
                'type': 'missing_ordinal_symbol',
                'description': 'Falta sÃ­mbolo ordinal "Âº" en el piso'
            },
            {
                'pattern': r'\b\d+(?:st|nd|rd|th)\b',
                'type': 'english_ordinal',
                'description': 'Formato inglÃ©s, debe usar formato espaÃ±ol con "Âº"'
            }
        ]
        
        # æ£€æŸ¥é”™è¯¯æ ¼å¼
        for error_config in error_patterns:
            pattern = error_config['pattern']
            error_type = error_config['type']
            description = error_config['description']
            
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                error_text = match.group().strip()
                
                # åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦é¿å…é‡å¤
                error_key = f"{error_text}_{error_type}"
                if error_key in seen_errors:
                    continue
                seen_errors.add(error_key)
                
                # ç”Ÿæˆæ­£ç¡®æ ¼å¼å»ºè®®
                suggested_format = ""
                if error_type == 'full_street_name':
                    street_match = re.search(r'Calle\s+([A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ][a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼\s]+),?\s*(?:nÃºmero\s+)?(\d+)', error_text, re.IGNORECASE)
                    if street_match:
                        street_name = street_match.group(1).strip()
                        number = street_match.group(2)
                        suggested_format = f"C/ {street_name}, {number}"
                elif error_type == 'full_avenue_name':
                    suggested_format = error_text.replace('Avenida', 'Av.', 1)
                elif error_type == 'full_floor_word':
                    floor_match = re.search(r'piso\s+(\d+)', error_text, re.IGNORECASE)
                    if floor_match:
                        floor_num = floor_match.group(1)
                        suggested_format = f"{floor_num}Âº"
                elif error_type == 'missing_ordinal_symbol':
                    suggested_format = re.sub(r'(\d+)([A-Z])', r'\1Âº\2', error_text)
                elif error_type == 'english_ordinal':
                    number = re.search(r'\d+', error_text).group()
                    suggested_format = f"{number}Âº"
                
                format_errors.append({
                    'error': error_text,
                    'correct': suggested_format,
                    'type': error_type,
                    'position': match.span(),
                    'description': description
                })
        
        return len(format_errors), format_errors, len(correct_addresses), correct_addresses
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„é”™è¯¯ - å…¨å±€å»é‡
    total_errors = 0
    all_errors = []
    all_correct = []
    global_seen_errors = set()  # å…¨å±€å»é‡
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_addresses = check_address_format_errors(text)
        
        # å…¨å±€å»é‡
        for error in errors:
            error_key = f"{error['error']}_{error['type']}"
            if error_key not in global_seen_errors:
                global_seen_errors.add(error_key)
                all_errors.append(error)
        
        all_correct.extend(correct_addresses)
    
    total_errors = len(all_errors)
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_errors <= max_errors:
        correct_examples = [f"'{correct['address']}'" for correct in all_correct[:3]]
        correct_info = f"Found {len(all_correct)} correct address formats" + (f": {', '.join(correct_examples)}" if correct_examples else "")
        
        error_info = ""
        if all_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in all_errors[:3]]
            error_info = f" Address format errors: {'; '.join(error_examples)}"
            if len(all_errors) > 3:
                error_info += f" (+{len(all_errors)-3} more)"
        
        return 1, f"âœ… Spanish address formats are correct. {correct_info}. Found {total_errors} errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = [f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})" for error in all_errors[:3]]
        error_summary = "; ".join(error_details)
        if len(all_errors) > 3:
            error_summary += f" (+{len(all_errors)-3} more)"
        
        return 0, f"âŒ Found {total_errors} address format errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."



def total_has_complete_questions(texts, count_range):
    """æ£€æŸ¥æ•´ä¸ªå¯¹è¯ä¸­å®Œæ•´è¥¿ç­ç‰™è¯­ç–‘é—®å¥çš„æ€»æ•°é‡æ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…"""
    
    if not texts:
        return 0, f"âŒ No dialogue provided"
    
    # å¤„ç†å‚æ•°ï¼šå¯ä»¥æ˜¯å•ä¸ªæ•°å­—æˆ–èŒƒå›´
    if isinstance(count_range, list) and len(count_range) == 2:
        min_count, max_count = count_range
    elif isinstance(count_range, int):
        min_count = max_count = count_range  # ç²¾ç¡®åŒ¹é…
    else:
        min_count = max_count = 1  # é»˜è®¤å€¼
    
    # ç¡®ä¿ texts æ˜¯åˆ—è¡¨æ ¼å¼
    if isinstance(texts, str):
        dialogue_rounds = [texts]
    elif isinstance(texts, list):
        dialogue_rounds = texts
    else:
        dialogue_rounds = [str(texts)]
    
    # å®Œæ•´ç–‘é—®å¥çš„æ­£åˆ™æ¨¡å¼ï¼šÂ¿å¼€å¤´ï¼Œ?ç»“å°¾ï¼Œä¸­é—´ä¸åŒ…å«å…¶ä»–Â¿æˆ–?
    complete_question_pattern = r'Â¿[^Â¿?]*\?'
    
    total_questions = 0
    all_questions = []
    
    # ç»Ÿè®¡æ‰€æœ‰è½®æ¬¡ä¸­çš„ç–‘é—®å¥æ€»æ•°
    for i, round_text in enumerate(dialogue_rounds):
        round_content = str(round_text).strip()
        
        # æŸ¥æ‰¾å®Œæ•´çš„ç–‘é—®å¥
        matches = re.findall(complete_question_pattern, round_content, re.DOTALL)
        round_questions = len(matches)
        total_questions += round_questions
        
        # è®°å½•æ‰¾åˆ°çš„ç–‘é—®å¥
        for question in matches:
            display_question = question[:50] + "..." if len(question) > 50 else question
            all_questions.append(f"Round {i+1}: {display_question}")
    
    # æ£€æŸ¥æ˜¯å¦ç¬¦åˆè¦æ±‚
    if min_count <= total_questions <= max_count:
        question_list = "; ".join(all_questions[:10])  # æœ€å¤šæ˜¾ç¤º10ä¸ª
        if len(all_questions) > 10:
            question_list += f" ... (+{len(all_questions)-10} more)"
        
        if min_count == max_count:
            requirement_text = f"exactly {min_count}"
        elif max_count >= 1000:  # å®é™…ä¸Šæ˜¯"è‡³å°‘"çš„æ„æ€
            requirement_text = f"at least {min_count}"
        else:
            requirement_text = f"between {min_count} and {max_count}"
        
        return 1, f"âœ… Total dialogue contains {total_questions} complete questions ({requirement_text} required). Found: {question_list}. Requirement met."
    else:
        question_list = "; ".join(all_questions) if all_questions else "None found"
        
        if min_count == max_count:
            requirement_text = f"exactly {min_count}"
        elif max_count >= 1000:
            requirement_text = f"at least {min_count}"
        else:
            requirement_text = f"between {min_count} and {max_count}"
        
        return 0, f"âŒ Total dialogue contains {total_questions} complete questions ({requirement_text} required). Found: {question_list}. Does not meet the requirement."

def has_spanish_keywords_with_articles(texts, *args, **kwargs):
    """æ™ºèƒ½æ£€æµ‹åŸæ–‡åè¯å’Œå®šå† è¯æ­é…"""
    
    # ğŸ”§ çµæ´»çš„å‚æ•°å¤„ç†
    if len(args) == 1:
        # å•ä¸ªå‚æ•°ï¼šå¯èƒ½æ˜¯ min_countï¼Œæˆ–è€…æ˜¯ [min_count, max_count] åˆ—è¡¨
        if isinstance(args[0], (list, tuple)) and len(args[0]) == 2:
            min_count, max_count = args[0]
        else:
            min_count = args[0]
            max_count = args[0]
    elif len(args) == 2:
        min_count, max_count = args
    elif len(args) == 0:
        # ä» kwargs è·å–
        min_count = kwargs.get('min_count', 1)
        max_count = kwargs.get('max_count', min_count)
    else:
        # å¤„ç†æ›´å¤šå‚æ•°çš„æƒ…å†µ
        min_count = args[0]
        max_count = args[1] if len(args) > 1 else args[0]
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # åŸæ–‡ä¸­çš„åè¯åˆ—è¡¨
    original_nouns = [
        "palabras", "lenguaje", "comunicaciÃ³n", "papel", "susurros", 
        "corazÃ³n", "bolÃ­grafo", "pensamientos", "hogar", "estrellas", 
        "cielo", "sentimientos", "raÃ­ces"
    ]
    
    # è¥¿ç­ç‰™è¯­å®šå† è¯
    definite_articles = ["el", "la", "los", "las"]
    
    def find_keywords_in_text(text):
        """åœ¨æ–‡æœ¬ä¸­æŸ¥æ‰¾å…³é”®è¯"""
        import re
        found_keywords = []
        for noun in original_nouns:
            for article in definite_articles:
                pattern = rf'\b{article}\s+{noun}\b'
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    found_keywords.append(f"{article} {noun}")
                    break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†ï¼Œé¿å…é‡å¤è®¡ç®—
        return list(set(found_keywords))  # å»é‡
    
    # ğŸ¯ æ™ºèƒ½åˆ¤æ–­å¤„ç†æ¨¡å¼
    if isinstance(texts, str):
        # æ¨¡å¼1ï¼šå•ä¸ªæ–‡æœ¬ â†’ æ•´ç¯‡æ–‡ç« æ¨¡å¼
        text = texts
        keywords = find_keywords_in_text(text)
        keyword_count = len(keywords)
        
        meets_requirement = min_count <= keyword_count <= max_count
        
        if keywords:
            keyword_info = f"Found: {', '.join(keywords[:5])}"
            if len(keywords) > 5:
                keyword_info += f" (and {len(keywords)-5} more)"
        else:
            keyword_info = "No keywords found"
        
        if meets_requirement:
            return 1, f"âœ… Article contains {keyword_count} original nouns with definite articles (required: {min_count}-{max_count}). {keyword_info}"
        else:
            if keyword_count < min_count:
                return 0, f"âŒ Article contains only {keyword_count} original nouns with definite articles, need at least {min_count}. {keyword_info}"
            else:
                return 0, f"âŒ Article contains {keyword_count} original nouns with definite articles, exceeds maximum {max_count}. {keyword_info}"
    
    elif isinstance(texts, list):
        # ğŸ” è¿›ä¸€æ­¥åˆ¤æ–­ï¼šæ˜¯çœŸæ­£çš„å¤šæ¡è¯„è®ºï¼Œè¿˜æ˜¯å•ç¯‡æ–‡ç« è¢«åˆ†å‰²äº†
        
        # å¯å‘å¼åˆ¤æ–­ï¼šå¦‚æœåªæœ‰1ä¸ªå…ƒç´ ï¼Œæˆ–è€…æ‰€æœ‰å…ƒç´ éƒ½å¾ˆé•¿ï¼Œå¯èƒ½æ˜¯å•ç¯‡æ–‡ç« 
        if len(texts) == 1:
            # åªæœ‰1ä¸ªå…ƒç´  â†’ å½“ä½œå•ç¯‡æ–‡ç« å¤„ç†
            return has_spanish_keywords_with_articles(texts[0], min_count, max_count)
        
        # è®¡ç®—å¹³å‡é•¿åº¦æ¥åˆ¤æ–­
        avg_length = sum(len(str(text)) for text in texts) / len(texts)
        
        if avg_length > 500:  # å¦‚æœå¹³å‡æ¯æ¡è¶…è¿‡500å­—ç¬¦ï¼Œå¯èƒ½æ˜¯é•¿æ–‡ç« çš„æ®µè½
            # æ¨¡å¼1ï¼šé•¿æ®µè½ â†’ æ•´ç¯‡æ–‡ç« æ¨¡å¼
            combined_text = ' '.join(str(text) for text in texts)
            return has_spanish_keywords_with_articles(combined_text, min_count, max_count)
        
        else:
            # æ¨¡å¼2ï¼šçŸ­æ–‡æœ¬ â†’ å¤šæ¡è¯„è®ºæ¨¡å¼
            comment_details = []
            all_match = True
            
            for i, comment in enumerate(texts):
                comment_text = str(comment).strip()
                keywords = find_keywords_in_text(comment_text)
                keyword_count = len(keywords)
                
                meets_requirement = min_count <= keyword_count <= max_count
                if not meets_requirement:
                    all_match = False
                
                # è®°å½•è¯¦æƒ…
                status = "âœ…" if meets_requirement else "âŒ"
                if keywords:
                    display_keywords = keywords[:3]
                    keyword_info = f"({', '.join(display_keywords)}"
                    if len(keywords) > 3:
                        keyword_info += f" +{len(keywords)-3} more"
                    keyword_info += ")"
                else:
                    keyword_info = "(no keywords)"
                
                comment_details.append(f"Comment {i+1}: {keyword_count} keywords {status} {keyword_info}")
            
            detail_info = " | ".join(comment_details)
            
            if all_match:
                return 1, f"âœ… All {len(texts)} comments contain {min_count}-{max_count} original nouns with definite articles. {detail_info}"
            else:
                return 0, f"âŒ Some comments do NOT meet the requirement of {min_count}-{max_count} keywords with definite articles. {detail_info}"
    
    else:
        # å…¶ä»–ç±»å‹ â†’ è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¤„ç†
        return has_spanish_keywords_with_articles(str(texts), min_count, max_count)


def has_spanish_ningun_sentences(texts, count_range):
    """ç»Ÿè®¡åŒ…å«ningÃºn/ningunaçš„å¥å­æ•°é‡ï¼ˆæ›´ç²¾ç¡®çš„è¯†åˆ«ï¼‰"""
    
    # å¤„ç†å‚æ•°æ ¼å¼
    if isinstance(count_range, list) and len(count_range) == 2:
        min_count, max_count = count_range
    elif isinstance(count_range, (int, float)):
        min_count = max_count = int(count_range)
    else:
        min_count, max_count = 1, 1000  # é»˜è®¤èŒƒå›´
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
    if isinstance(texts, list):
        full_text = " ".join(str(text) for text in texts)
    else:
        full_text = str(texts)
    
    print(f"Debug - åˆ†ææ–‡æœ¬é•¿åº¦: {len(full_text)} å­—ç¬¦")
    print(f"Debug - æ–‡æœ¬å¼€å¤´: {full_text[:100]}...")
    
    # æ”¹è¿›çš„å¥å­åˆ†å‰²ï¼š
    # 1. æŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å‰²
    # 2. å¤„ç†çœç•¥å·å’Œå…¶ä»–æ ‡ç‚¹
    # 3. è¿‡æ»¤æ‰ç©ºå¥å­
    sentence_patterns = [
        r'[.!?]+\s+',  # æ ‡å‡†å¥æœ«æ ‡ç‚¹ + ç©ºæ ¼
        r'[.!?]+$',    # æ–‡æœ«æ ‡ç‚¹
        r'[.!?]+(?=[A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ])',  # æ ‡ç‚¹åç›´æ¥è·Ÿå¤§å†™å­—æ¯
    ]
    
    # å…ˆç»Ÿä¸€å¤„ç†ï¼Œç„¶ååˆ†å‰²
    text_for_split = full_text.strip()
    
    # ä½¿ç”¨å¤šä¸ªæ¨¡å¼åˆ†å‰²å¥å­
    sentences = []
    current_sentences = [text_for_split]
    
    for pattern in sentence_patterns:
        new_sentences = []
        for sentence in current_sentences:
            parts = re.split(pattern, sentence)
            new_sentences.extend([part.strip() for part in parts if part.strip()])
        current_sentences = new_sentences
    
    sentences = current_sentences
    
    print(f"Debug - åˆ†å‰²åå¥å­æ•°: {len(sentences)}")
    for i, sentence in enumerate(sentences[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"Debug - å¥å­ {i+1}: {sentence[:80]}...")
    
    # æŸ¥æ‰¾åŒ…å«ningÃºn/ningunaçš„å¥å­
    ningun_sentences = []
    ningun_usage_details = []
    
    for i, sentence in enumerate(sentences):
        sentence = sentence.strip()
        if not sentence:
            continue
            
        # æŸ¥æ‰¾å¥å­ä¸­çš„æ‰€æœ‰ningÃºn/ninguna
        ningun_matches = re.findall(r'\b(ningÃºn|ninguna)\b', sentence, re.IGNORECASE)
        
        if ningun_matches:
            ningun_sentences.append(sentence)
            
            # è¯¦ç»†è®°å½•æ¯ä¸ªä½¿ç”¨æƒ…å†µ
            for match in ningun_matches:
                # æŸ¥æ‰¾ningÃºn/ningunaåé¢çš„è¯æ±‡ï¼ˆç”¨äºæ›´å¥½çš„å±•ç¤ºï¼‰
                context_pattern = r'\b' + re.escape(match) + r'\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+(?:\s+[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+)*)'
                context_match = re.search(context_pattern, sentence, re.IGNORECASE)
                
                if context_match:
                    context = f"{match} {context_match.group(1)}"
                else:
                    context = match
                
                ningun_usage_details.append({
                    'sentence_num': i + 1,
                    'usage': context,
                    'full_sentence': sentence
                })
    
    found_sentence_count = len(ningun_sentences)
    total_ningun_count = len(ningun_usage_details)
    
    print(f"Debug - åŒ…å«ningÃºn/ningunaçš„å¥å­æ•°: {found_sentence_count}")
    print(f"Debug - ningÃºn/ningunaæ€»ä½¿ç”¨æ¬¡æ•°: {total_ningun_count}")
    
    for detail in ningun_usage_details[:5]:  # æ˜¾ç¤ºå‰5ä¸ªä½¿ç”¨æƒ…å†µ
        print(f"Debug - ä½¿ç”¨ {detail['sentence_num']}: {detail['usage']} -> {detail['full_sentence'][:60]}...")
    
    # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¦æ±‚
    if min_count <= found_sentence_count <= max_count:
        # æ„å»ºæˆåŠŸä¿¡æ¯
        examples = []
        sentence_shown = set()
        
        for detail in ningun_usage_details[:3]:  # æ˜¾ç¤ºå‰3ä¸ªä¸åŒå¥å­çš„ä¾‹å­
            sentence = detail['full_sentence']
            if sentence not in sentence_shown:
                sentence_shown.add(sentence)
                truncated = sentence[:50] + "..." if len(sentence) > 50 else sentence
                examples.append(f"'{truncated}'")
        
        examples_text = "; ".join(examples)
        if found_sentence_count > len(examples):
            examples_text += f" ... (+{found_sentence_count - len(examples)} more sentences)"
        
        # æ·»åŠ ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
        usage_info = ""
        if total_ningun_count != found_sentence_count:
            usage_info = f" (total {total_ningun_count} ningÃºn/ninguna usages)"
        
        return 1, f"âœ… Found {found_sentence_count} sentences with ningÃºn/ninguna{usage_info} (required: {min_count}-{max_count}). Examples: {examples_text}. Requirement met."
    else:
        # æ„å»ºå¤±è´¥ä¿¡æ¯
        examples_text = ""
        if ningun_sentences:
            examples = []
            for sentence in ningun_sentences[:2]:
                truncated = sentence[:50] + "..." if len(sentence) > 50 else sentence
                examples.append(f"'{truncated}'")
            examples_text = f" Examples: {'; '.join(examples)}"
            if len(ningun_sentences) > 2:
                examples_text += f" ... (+{len(ningun_sentences)-2} more)"
        
        usage_info = ""
        if total_ningun_count > 0:
            usage_info = f" (total {total_ningun_count} ningÃºn/ninguna usages)"
        
        return 0, f"âŒ Found {found_sentence_count} sentences with ningÃºn/ninguna{usage_info} (required: {min_count}-{max_count}).{examples_text} Does not meet the requirement."

def has_correct_spanish_ningun_agreement(texts, max_errors):
    """æ£€æµ‹ningÃºn/ningunaä¸åè¯æ€§æ•°æ˜¯å¦ä¸€è‡´"""
    import re
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
    if isinstance(texts, list):
        full_text = " ".join(str(text) for text in texts)
    else:
        full_text = str(texts)
    
    print(f"Debug - åˆ†ææ–‡æœ¬: {full_text[:100]}...")
    
    # å¸¸è§è¥¿ç­ç‰™è¯­åè¯çš„æ€§åˆ«è¯å…¸
    noun_genders = {
        # é˜³æ€§åè¯ (masculino)
        'problema': 'm',  # é‡è¦ï¼šproblemaè™½ç„¶ä»¥-aç»“å°¾ï¼Œä½†æ˜¯é˜³æ€§åè¯
        'estudiante': 'm', 'libro': 'm', 'lugar': 'm', 'tiempo': 'm', 
        'dinero': 'm', 'trabajo': 'm', 'producto': 'm', 'ruido': 'm',
        'hospital': 'm', 'parque': 'm', 'edificio': 'm', 'coche': 'm',
        'visitante': 'm', 'bibliotecario': 'm', 'pasillo': 'm',
        'ambiente': 'm', 'silencio': 'm', 'momento': 'm', 'espacio': 'm',
        'rincÃ³n': 'm', 'dÃ­a': 'm', 'sistema': 'm', 'tema': 'm',
        'pez': 'm', 'mar': 'm', 'viento': 'm', 'paisaje': 'm', 'mundo': 'm',
        'cuerpo': 'm', 'chisme': 'm', 'tipo': 'm', 'resto': 'm', 'deseo': 'm',
        'amor': 'm', 'ocÃ©ano': 'm', 'obstÃ¡culo': 'm', 'desafÃ­o': 'm', 'movimiento': 'm',
        # ğŸ”§ æ–°å¢ç¼ºå¤±çš„é˜³æ€§åè¯
        'interÃ©s': 'm', 'plato': 'm', 'hotel': 'm', 'restaurante': 'm', 'viaje': 'm',
        'servicio': 'm', 'personal': 'm', 'clima': 'm', 'centro': 'm', 'estudio': 'm',
        'horario': 'm', 'telÃ©fono': 'm', 'contacto': 'm', 'desarrollo': 'm', 'proyecto': 'm',
        'diseÃ±o': 'm', 'marketing': 'm', 'curso': 'm', 'taller': 'm', 'espectÃ¡culo': 'm',
        'evento': 'm', 'concierto': 'm', 'festival': 'm', 'museo': 'm', 'teatro': 'm',
        'cine': 'm', 'deporte': 'm', 'fÃºtbol': 'm', 'baloncesto': 'm', 'tenis': 'm',
        'golf': 'm', 'precio': 'm', 'descuento': 'm', 'pago': 'm', 'banco': 'm',
        'cajero': 'm', 'metro': 'm', 'autobÃºs': 'm', 'tren': 'm', 'aviÃ³n': 'm',
        'aeropuerto': 'm', 'puerto': 'm', 'barco': 'm', 'taxi': 'm', 'conductor': 'm',
        
        # é˜´æ€§åè¯ (femenino)
        'persona': 'f', 'casa': 'f', 'mesa': 'f', 'silla': 'f',
        'biblioteca': 'f', 'oficina': 'f', 'tienda': 'f', 'ciudad': 'f',
        'habitaciÃ³n': 'f', 'ventana': 'f', 'puerta': 'f', 'clase': 'f',
        'conversaciÃ³n': 'f', 'secciÃ³n': 'f', 'actividad': 'f',
        'luz': 'f', 'estanterÃ­a': 'f', 'pÃ¡gina': 'f', 'calma': 'f',
        'tranquilidad': 'f', 'quietud': 'f', 'iluminaciÃ³n': 'f', 'afluencia': 'f',
        'vida': 'f', 'libertad': 'f', 'diversidad': 'f', 'felicidad': 'f',
        'naturaleza': 'f', 'experiencia': 'f', 'comida': 'f', 'salud': 'f',
        'gente': 'f', 'biodiversidad': 'f', 'importancia': 'f', 'emociÃ³n': 'f',
        'belleza': 'f', 'lÃ¡mpara': 'f', 'sombra': 'f', 'necesidad': 'f',
        'preocupaciÃ³n': 'f', 'seguridad': 'f',
        # ğŸ”§ æ–°å¢å¸¸è§é˜´æ€§åè¯
        'playa': 'f', 'isla': 'f', 'montaÃ±a': 'f', 'estancia': 'f', 'expectativa': 'f',
        'vacaciÃ³n': 'f', 'reserva': 'f', 'cama': 'f', 'ducha': 'f', 'toalla': 'f',
        'piscina': 'f', 'terraza': 'f', 'vista': 'f', 'foto': 'f', 'cÃ¡mara': 'f',
        'maleta': 'f', 'ropa': 'f', 'camisa': 'f', 'falda': 'f', 'chaqueta': 'f',
        'empresa': 'f', 'consulta': 'f', 'cita': 'f', 'reuniÃ³n': 'f', 'presentaciÃ³n': 'f',
        'propuesta': 'f', 'soluciÃ³n': 'f', 'estrategia': 'f', 'campaÃ±a': 'f', 'publicidad': 'f',
        'educaciÃ³n': 'f', 'formaciÃ³n': 'f', 'universidad': 'f', 'escuela': 'f', 'academia': 'f',
        'mÃºsica': 'f', 'canciÃ³n': 'f', 'pelÃ­cula': 'f', 'obra': 'f', 'exposiciÃ³n': 'f',
        'entrada': 'f', 'salida': 'f', 'llegada': 'f', 'partida': 'f', 'estaciÃ³n': 'f',
        'parada': 'f', 'lÃ­nea': 'f', 'tarjeta': 'f', 'cuenta': 'f', 'factura': 'f'
    }
    
    # æ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼šæ›´ç²¾ç¡®åœ°åŒ¹é…ningÃºn/ninguna + åè¯
    # åŒ¹é…æ¨¡å¼ï¼šningÃºn/ninguna + (å¯é€‰çš„å½¢å®¹è¯) + åè¯
    pattern = r'\b(ningÃºn|ninguna)\s+(?:[a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+\s+)*?([a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+)(?=\s|[.,!?;:]|$)'
    matches = re.findall(pattern, full_text, re.IGNORECASE)
    
    print(f"Debug - æ­£åˆ™åŒ¹é…ç»“æœ: {matches}")
    
    format_errors = []
    correct_uses = []
    unknown_nouns = []
    
    for negation, noun in matches:
        negation_lower = negation.lower()
        noun_lower = noun.lower()
        
        print(f"Debug - æ£€æŸ¥ç»„åˆ: {negation} {noun}")
        
        if noun_lower in noun_genders:
            noun_gender = noun_genders[noun_lower]
            
            # æ£€æŸ¥æ€§åˆ«ä¸€è‡´æ€§
            # ningÃºn ç”¨äºé˜³æ€§åè¯ (masculino)
            # ninguna ç”¨äºé˜´æ€§åè¯ (femenino)
            if (negation_lower == 'ningÃºn' and noun_gender == 'm') or \
               (negation_lower == 'ninguna' and noun_gender == 'f'):
                correct_uses.append(f"{negation_lower} {noun_lower}")
                print(f"Debug - âœ… æ­£ç¡®: {negation} {noun} ({noun_gender})")
            else:
                correct_form = 'ningÃºn' if noun_gender == 'm' else 'ninguna'
                format_errors.append({
                    'error': f"{negation} {noun}",
                    'correct': f"{correct_form} {noun}",
                    'description': f"Gender mismatch: '{noun}' is {noun_gender} ({'masculino' if noun_gender == 'm' else 'femenino'}), should use '{correct_form}'"
                })
                print(f"Debug - âŒ é”™è¯¯: {negation} {noun} -> åº”è¯¥æ˜¯ {correct_form} {noun}")
        else:
            # å¯¹äºä¸åœ¨è¯å…¸ä¸­çš„åè¯ï¼Œè®°å½•ä½†ä¸ç®—é”™è¯¯ï¼ˆå‡è®¾æ­£ç¡®ï¼‰
            unknown_nouns.append(f"{negation_lower} {noun_lower}")
            print(f"Debug - âš ï¸ æœªçŸ¥åè¯: {negation} {noun} (å‡è®¾æ­£ç¡®)")
    
    total_errors = len(format_errors)
    
    print(f"Debug - æ­£ç¡®ä½¿ç”¨: {len(correct_uses)}, é”™è¯¯: {total_errors}, æœªçŸ¥: {len(unknown_nouns)}")
    
    if total_errors <= max_errors:
        # ğŸ”§ ä¿®å¤ï¼šæ”¹è¿›æ˜¾ç¤ºé€»è¾‘ï¼Œé¿å…é€»è¾‘çŸ›ç›¾
        total_correct_uses = len(correct_uses) + len(unknown_nouns)
        
        # ç»Ÿè®¡å·²çŸ¥çš„æ­£ç¡®ç»„åˆ
        correct_combinations = {}
        for use in correct_uses:
            correct_combinations[use] = correct_combinations.get(use, 0) + 1
        
        # ç»Ÿè®¡æœªçŸ¥ç»„åˆ
        unknown_combinations = {}
        for noun in unknown_nouns:
            unknown_combinations[noun] = unknown_combinations.get(noun, 0) + 1
        
        # ğŸ”§ ä¿®å¤ï¼šæ„å»ºæ›´æ¸…æ™°çš„æ˜¾ç¤ºä¿¡æ¯
        if len(correct_uses) > 0 and len(unknown_nouns) == 0:
            # åªæœ‰å·²çŸ¥æ­£ç¡®ç”¨æ³•
            combination_details = []
            for combo, count in correct_combinations.items():
                if count > 1:
                    combination_details.append(f"'{combo}' ({count} times)")
                else:
                    combination_details.append(f"'{combo}'")
            
            correct_info = f"Found {total_correct_uses} correct ningÃºn/ninguna uses: {', '.join(combination_details[:5])}"
            if len(combination_details) > 5:
                correct_info += f" (+{len(combination_details)-5} more)"
            unknown_info = ""
            
        elif len(correct_uses) == 0 and len(unknown_nouns) > 0:
            # åªæœ‰æœªçŸ¥åè¯
            unknown_details = []
            for combo, count in unknown_combinations.items():
                if count > 1:
                    unknown_details.append(f"'{combo}' ({count} times)")
                else:
                    unknown_details.append(f"'{combo}'")
            
            correct_info = f"Found {total_correct_uses} correct ningÃºn/ninguna uses"
            unknown_info = f" Unknown nouns (assumed correct): {', '.join(unknown_details[:3])}"
            if len(unknown_details) > 3:
                unknown_info += f" (+{len(unknown_details)-3} more)"
                
        elif len(correct_uses) > 0 and len(unknown_nouns) > 0:
            # æ—¢æœ‰å·²çŸ¥ä¹Ÿæœ‰æœªçŸ¥
            combination_details = []
            for combo, count in correct_combinations.items():
                if count > 1:
                    combination_details.append(f"'{combo}' ({count} times)")
                else:
                    combination_details.append(f"'{combo}'")
            
            unknown_details = []
            for combo, count in unknown_combinations.items():
                if count > 1:
                    unknown_details.append(f"'{combo}' ({count} times)")
                else:
                    unknown_details.append(f"'{combo}'")
            
            correct_info = f"Found {total_correct_uses} correct ningÃºn/ninguna uses: {', '.join(combination_details[:3])}"
            if len(combination_details) > 3:
                correct_info += f" (+{len(combination_details)-3} more known)"
                
            unknown_info = f" Unknown nouns (assumed correct): {', '.join(unknown_details[:2])}"
            if len(unknown_details) > 2:
                unknown_info += f" (+{len(unknown_details)-2} more unknown)"
        else:
            # æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç”¨æ³•
            correct_info = "Found 0 correct ningÃºn/ninguna uses"
            unknown_info = ""
        
        return 1, f"âœ… NingÃºn/ninguna gender agreements are correct. {correct_info}.{unknown_info} Found {total_errors} errors (allowed: {max_errors}). Requirement met."
    else:
        error_details = [f"'{err['error']}' â†’ '{err['correct']}' ({err['description']})" for err in format_errors]
        error_summary = "; ".join(error_details)
        
        return 0, f"âŒ Found {total_errors} ningÃºn/ninguna gender errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."


def has_correct_spanish_ordinal_format(texts, max_errors):
    """æ£€æµ‹åºæ•°è¯ç¼©å†™æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆå¿…é¡»æœ‰å¥ç‚¹å’Œä¸Šæ ‡ç¬¦å·ï¼‰"""
    import re
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
    if isinstance(texts, list):
        full_text = " ".join(str(text) for text in texts)
    else:
        full_text = str(texts)
    
    print(f"Debug - æ£€æµ‹åºæ•°è¯æ ¼å¼ï¼Œå®Œæ•´æ–‡æœ¬: {repr(full_text[:300])}")
    
    # âœ… æ­£ç¡®æ ¼å¼ï¼šå¿…é¡»æœ‰å¥ç‚¹å’Œä¸Šæ ‡ç¬¦å·
    correct_patterns = [
        # 1. åœ¨ Planta/Piso/Nivel ä¸Šä¸‹æ–‡ä¸­
        r'(\d{1,2})\.(Âº|Âª)\s+(Planta|Piso|Nivel|planta|piso|nivel)\b',
        # 2. åœ¨ Oficina ä¸Šä¸‹æ–‡ä¸­
        r'(Oficina|oficina)\s+(\d{1,2})\.(Âº|Âª)(\d*)\b',
        # 3. å…¶ä»–ä¸Šä¸‹æ–‡ä¸­çš„æ­£ç¡®æ ¼å¼
        r'\b(\d{1,2})\.(Âº|Âª)\b'
    ]
    
    correct_abbreviations = []
    
    for pattern in correct_patterns:
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            full_match = match.group(0)
            # é¿å…é‡å¤æ·»åŠ 
            if not any(ca['full_match'] == full_match for ca in correct_abbreviations):
                correct_abbreviations.append({
                    'abbreviation': full_match,
                    'full_match': full_match,
                    'position': match.span(),
                    'context': 'ordinal_context'
                })
    
    print(f"Debug - æ‰¾åˆ°çš„æ­£ç¡®åºæ•°è¯: {[ca['abbreviation'] for ca in correct_abbreviations]}")
    
    # âŒ æ£€æµ‹é”™è¯¯æ ¼å¼ï¼Œæ‰©å±•ä¸Šä¸‹æ–‡èŒƒå›´
    format_errors = []
    
    # ğŸ”§ ä¿®å¤ï¼šæ‰©å±•åºæ•°è¯ä¸Šä¸‹æ–‡æ£€æµ‹
    ordinal_error_contexts = [
        # 1. Planta/Piso/Nivel ä¸Šä¸‹æ–‡
        r'(\d{1,2})([aoÂº Âª])\s+(Planta|Piso|Nivel|planta|piso|nivel)\b',
        # 2. Oficina ä¸Šä¸‹æ–‡ - è¿™æ˜¯å…³é”®ï¼
        r'(Oficina|oficina)\s+(\d{1,2})([aoÂºÂª])(\d*)\b',
        # 3. å…¶ä»–å¯èƒ½çš„åºæ•°è¯ä¸Šä¸‹æ–‡
        r'\b(\d{1,2})([ao])\s+(planta|piso|nivel|oficina)\b',
        # 4. ç‹¬ç«‹çš„åºæ•°è¯ï¼ˆä½†è¦è°¨æ…ï¼Œé¿å…è¯¯åˆ¤ç¼–å·ï¼‰
        r'\b(\d{1,2})([ao])\b(?=\s|$|[^\w])',
    ]
    
    for i, pattern in enumerate(ordinal_error_contexts):
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            full_match = match.group(0)
            groups = match.groups()
            
            print(f"Debug - æ£€æŸ¥æ½œåœ¨é”™è¯¯: '{full_match}', ç»„: {groups}")
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»è¢«è¯†åˆ«ä¸ºæ­£ç¡®æ ¼å¼
            is_already_correct = any(
                ca['position'][0] <= match.start() <= ca['position'][1] or
                ca['position'][0] <= match.end() <= ca['position'][1]
                for ca in correct_abbreviations
            )
            
            if is_already_correct:
                print(f"Debug - è·³è¿‡å·²æ­£ç¡®: {full_match}")
                continue
            
            # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®ä¸åŒä¸Šä¸‹æ–‡åˆ†æé”™è¯¯
            error_text = ""
            correct_text = ""
            description = ""
            
            if i == 0:  # Planta/Piso/Nivel ä¸Šä¸‹æ–‡
                number, suffix, context_word = groups[0], groups[1], groups[2]
                error_text = f"{number}{suffix}"
                if suffix.lower() == 'a':
                    correct_text = f"{number}.Âª"
                elif suffix.lower() == 'o':
                    correct_text = f"{number}.Âº"
                else:
                    continue  # å·²ç»æ˜¯æ­£ç¡®çš„ä¸Šæ ‡ç¬¦å·
                description = f'En contexto de {context_word.lower()} debe usar punto y sÃ­mbolo de superÃ­ndice'
                
            elif i == 1:  # Oficina ä¸Šä¸‹æ–‡ - å…³é”®ä¿®å¤ï¼
                context_word, number, suffix, additional = groups
                error_text = f"{number}{suffix}{additional}"
                
                if suffix.lower() == 'a':
                    correct_text = f"{number}.Âª{additional}"
                elif suffix.lower() == 'o':
                    correct_text = f"{number}.Âº{additional}"
                elif suffix == 'Âª':
                    # ç¼ºå°‘å¥ç‚¹
                    correct_text = f"{number}.Âª{additional}"
                    error_text = f"{number}Âª{additional}"
                elif suffix == 'Âº':
                    # ç¼ºå°‘å¥ç‚¹
                    correct_text = f"{number}.Âº{additional}"
                    error_text = f"{number}Âº{additional}"
                else:
                    continue
                    
                description = f'En contexto de oficina debe usar punto y sÃ­mbolo de superÃ­ndice'
                
            elif i == 2:  # å…¶ä»–ä¸Šä¸‹æ–‡
                number, suffix = groups[0], groups[1]
                error_text = f"{number}{suffix}"
                if suffix.lower() == 'a':
                    correct_text = f"{number}.Âª"
                else:  # 'o'
                    correct_text = f"{number}.Âº"
                description = 'Debe usar punto y sÃ­mbolo de superÃ­ndice (Âº/Âª)'
                
            elif i == 3:  # ç‹¬ç«‹åºæ•°è¯
                number, suffix = groups
                # åªå¤„ç†æ˜æ˜¾çš„åºæ•°è¯é”™è¯¯ï¼Œé¿å…è¯¯åˆ¤ç¼–å·
                if len(number) <= 2 and suffix.lower() in ['a', 'o']:
                    error_text = f"{number}{suffix}"
                    if suffix.lower() == 'a':
                        correct_text = f"{number}.Âª"
                    else:
                        correct_text = f"{number}.Âº"
                    description = 'Formato de ordinal incorrecto, debe usar punto y sÃ­mbolo de superÃ­ndice'
                else:
                    continue
            
            if error_text and correct_text:
                format_errors.append({
                    'error': error_text,
                    'correct': correct_text,
                    'type': f'ordinal_error_context_{i}',
                    'position': match.span(),
                    'description': description,
                    'context': full_match
                })
                print(f"Debug - âŒ é”™è¯¯æ ¼å¼: {error_text} â†’ {correct_text}")
    
    # æ£€æŸ¥æ˜¯å¦å®Œå…¨æ²¡æœ‰åºæ•°è¯
    total_ordinals_found = len(correct_abbreviations) + len(format_errors)
    
    if total_ordinals_found == 0:
        format_errors.append({
            'error': 'No ordinal abbreviations found',
            'correct': 'Should include ordinal abbreviations like 1.Âº, 2.Âª, etc.',
            'type': 'missing_ordinals',
            'position': (0, 0),
            'description': 'No se encontraron abreviaturas ordinales en contextos apropiados'
        })
    
    total_errors = len(format_errors)
    
    print(f"Debug - æ­£ç¡®æ ¼å¼æ•°é‡: {len(correct_abbreviations)}")
    print(f"Debug - é”™è¯¯æ•°é‡: {total_errors}")
    print(f"Debug - é”™è¯¯è¯¦æƒ…: {[(err['error'], err['correct'], err.get('context', '')) for err in format_errors]}")
    
    if total_errors <= max_errors:
        correct_examples = [abbrev['abbreviation'] for abbrev in correct_abbreviations[:5]]
        correct_info = f"Found {len(correct_abbreviations)} correctly formatted ordinal abbreviations"
        if correct_examples:
            correct_info += f": {', '.join(correct_examples)}"
        
        error_info = ""
        if format_errors and any(err['type'] != 'missing_ordinals' for err in format_errors):
            format_error_list = [err for err in format_errors if err['type'] != 'missing_ordinals']
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}' (in '{err.get('context', '')}')" for err in format_error_list[:3]]
            error_info = f" Format errors found: {'; '.join(error_examples)}"
            if len(format_error_list) > 3:
                error_info += f" (+{len(format_error_list)-3} more)"
        
        return 1, f"âœ… Spanish ordinal abbreviation formats are correct. {correct_info}. Found {total_errors} errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = []
        for error in format_errors:
            if error['type'] == 'missing_ordinals':
                error_details.append(f"{error['description']}")
            else:
                error_details.append(f"'{error['error']}' â†’ '{error['correct']}' (in '{error.get('context', '')}')")
        
        error_summary = "; ".join(error_details[:5])
        if len(error_details) > 5:
            error_summary += f" ... (+{len(error_details)-5} more errors)"
        
        return 0, f"âŒ Found {total_errors} ordinal abbreviation format errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."



def has_correct_spanish_time_articles(texts, max_errors):
    """æ£€æµ‹é’Ÿç‚¹è¡¨è¾¾çš„å† è¯æ˜¯å¦æ­£ç¡®ï¼ˆ1ç‚¹ç”¨la unaï¼Œå…¶ä½™ç”¨lasï¼‰"""
    import re
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
    if isinstance(texts, list):
        full_text = " ".join(str(text) for text in texts)
    else:
        full_text = str(texts)
    
    print(f"Debug - æ£€æµ‹é’Ÿç‚¹å† è¯ï¼Œæ–‡æœ¬: {full_text[:100]}...")
    
    format_errors = []
    correct_uses = []
    all_time_expressions = []
    
    # ğŸ”§ ä¿®å¤ï¼šæ‰©å±•æ—¶é—´è¡¨è¾¾æ£€æµ‹æ¨¡å¼
    time_detection_patterns = [
        # å¸¦å† è¯çš„æ—¶é—´è¡¨è¾¾ï¼šla una, las dos, etc.
        r'\b(la|las)\s+(una|dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce|trece|catorce|quince|diecisÃ©is|diecisiete|dieciocho|diecinueve|veinte|veintiuna|veintidÃ³s|veintitrÃ©s)\b',
        r'\b(la|las)\s+([1-9]|1[0-9]|2[0-3])\b',
        
        # ğŸ†• æ–°å¢ï¼šä¸å¸¦å† è¯çš„æ—¶é—´è¡¨è¾¾
        # "De siete de la maÃ±ana", "a las cinco", etc.
        r'\b(?:de|a)\s+(una|dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce)\s+de\s+la\s+(maÃ±ana|tarde|noche)\b',
        r'\b(?:de|a)\s+(una|dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce)\b(?!\s+de\s+la)',
        
        # ğŸ†• æ–°å¢ï¼šæ•°å­—å½¢å¼çš„æ—¶é—´
        r'\b(?:de|a)\s+([1-9]|1[0-2])\s+de\s+la\s+(maÃ±ana|tarde|noche)\b',
        r'\b(?:de|a)\s+([1-9]|1[0-2])\b(?!\s+de\s+la)',
        
        # ğŸ†• æ–°å¢ï¼šå…¶ä»–æ—¶é—´è¡¨è¾¾æ ¼å¼
        r'\b(desde|hasta)\s+(la|las)?\s*(una|dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce)\b',
        r'\b(desde|hasta)\s+(la|las)?\s*([1-9]|1[0-2])\b'
    ]
    
    # æ£€æµ‹æ‰€æœ‰æ—¶é—´è¡¨è¾¾
    for pattern in time_detection_patterns:
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            time_text = match.group().strip()
            all_time_expressions.append({
                'expression': time_text,
                'position': match.span(),
                'full_match': match.groups()
            })
    
    print(f"Debug - æ£€æµ‹åˆ°çš„æ—¶é—´è¡¨è¾¾: {[expr['expression'] for expr in all_time_expressions]}")
    
    # æ­£ç¡®çš„æ—¶é—´è¡¨è¾¾æ¨¡å¼ï¼ˆå¸¦å† è¯çš„ï¼‰
    correct_patterns = [
        # æ­£ç¡®ï¼šla una (1ç‚¹)
        r'\bla\s+una\b',
        r'\bla\s+1\b',
        
        # æ­£ç¡®ï¼šlas + å…¶ä»–æ•°å­— (2-12ç‚¹)
        r'\blas\s+(dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce)\b',
        r'\blas\s+(trece|catorce|quince|diecisÃ©is|diecisiete|dieciocho|diecinueve|veinte|veintiuna|veintidÃ³s|veintitrÃ©s)\b',
        r'\blas\s+([2-9]|1[0-9]|2[0-3])\b'
    ]
    
    # æ£€æŸ¥æ­£ç¡®ä½¿ç”¨ï¼ˆåªæ£€æŸ¥å¸¦å† è¯çš„è¡¨è¾¾ï¼‰
    for pattern in correct_patterns:
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            time_text = match.group().strip()
            correct_uses.append({
                'expression': time_text,
                'position': match.span()
            })
    
    # é”™è¯¯çš„æ—¶é—´è¡¨è¾¾æ¨¡å¼
    error_patterns = [
        # é”™è¯¯ï¼šlas una (åº”è¯¥æ˜¯ la una)
        {
            'pattern': r'\blas\s+una\b',
            'correct': 'la una',
            'description': 'Para la 1:00 se usa "la una", no "las una"'
        },
        {
            'pattern': r'\blas\s+1\b',
            'correct': 'la 1',
            'description': 'Para la 1:00 se usa "la 1", no "las 1"'
        },
        
        # é”™è¯¯ï¼šla + otros nÃºmeros (åº”è¯¥æ˜¯ las + nÃºmeros)
        {
            'pattern': r'\bla\s+(dos|tres|cuatro|cinco|seis|siete|ocho|nueve|diez|once|doce)\b',
            'correct': 'las',
            'description': 'Para las horas 2-12 se usa "las", no "la"'
        },
        {
            'pattern': r'\bla\s+(trece|catorce|quince|diecisÃ©is|diecisiete|dieciocho|diecinueve|veinte|veintiuna|veintidÃ³s|veintitrÃ©s)\b',
            'correct': 'las',
            'description': 'Para las horas 13-23 se usa "las", no "la"'
        },
        {
            'pattern': r'\bla\s+([2-9]|1[0-9]|2[0-3])\b',
            'correct': 'las',
            'description': 'Para las horas 2-23 se usa "las", no "la"'
        }
    ]
    
    # æ£€æŸ¥é”™è¯¯ä½¿ç”¨
    for error_config in error_patterns:
        pattern = error_config['pattern']
        correct_template = error_config['correct']
        description = error_config['description']
        
        matches = re.finditer(pattern, full_text, re.IGNORECASE)
        for match in matches:
            error_text = match.group().strip()
            
            # ç”Ÿæˆæ­£ç¡®æ ¼å¼
            if correct_template == 'la una':
                correct_text = 'la una'
            elif correct_template == 'la 1':
                correct_text = 'la 1'
            else:  # correct_template == 'las'
                # ä¿æŒåŸæ•°å­—/è¯æ±‡ï¼Œåªæ”¹å† è¯
                time_part = error_text.split()[1]  # è·å–æ•°å­—/è¯æ±‡éƒ¨åˆ†
                correct_text = f"las {time_part}"
            
            format_errors.append({
                'error': error_text,
                'correct': correct_text,
                'position': match.span(),
                'description': description
            })
    
    total_errors = len(format_errors)
    
    print(f"Debug - æ‰¾åˆ° {len(correct_uses)} ä¸ªæ­£ç¡®çš„é’Ÿç‚¹å† è¯")
    print(f"Debug - æ‰¾åˆ° {total_errors} ä¸ªå† è¯é”™è¯¯")
    print(f"Debug - æ€»æ—¶é—´è¡¨è¾¾æ•°: {len(all_time_expressions)}")
    
    # ğŸ”§ ä¿®å¤ï¼šæ›´å‡†ç¡®çš„åˆ¤æ–­é€»è¾‘
    if len(all_time_expressions) == 0:
        # å®Œå…¨æ²¡æœ‰æ—¶é—´è¡¨è¾¾
        return 1, f"âœ… No time expressions found in text, so no article errors detected. Requirement met."
    elif len(correct_uses) == 0 and len(format_errors) == 0:
        # æœ‰æ—¶é—´è¡¨è¾¾ä½†éƒ½ä¸å¸¦å† è¯ï¼ˆè¿™æ˜¯æ­£ç¡®çš„ï¼Œå› ä¸º"De siete de la maÃ±ana"ä¸éœ€è¦å† è¯ï¼‰
        time_examples = [expr['expression'] for expr in all_time_expressions[:3]]
        return 1, f"âœ… Found {len(all_time_expressions)} time expressions without articles (correct usage): {', '.join(time_examples)}. No article errors detected. Requirement met."
    
    if total_errors <= max_errors:
        if len(correct_uses) > 0:
            correct_examples = [use['expression'] for use in correct_uses[:5]]
            correct_info = f"Found {len(correct_uses)} correct time expressions with articles: {', '.join(correct_examples)}"
        else:
            correct_info = f"Found {len(all_time_expressions)} time expressions (no articles needed)"
        
        error_info = ""
        if format_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in format_errors[:3]]
            error_info = f" Time article errors: {'; '.join(error_examples)}"
            if len(format_errors) > 3:
                error_info += f" (+{len(format_errors)-3} more)"
        
        return 1, f"âœ… Spanish time article usage is correct. {correct_info}. Found {total_errors} errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = []
        for error in format_errors:
            error_details.append(f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})")
        
        error_summary = "; ".join(error_details[:5])  # æ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
        if len(error_details) > 5:
            error_summary += f" ... (+{len(error_details)-5} more errors)"
        
        return 0, f"âŒ Found {total_errors} time article errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."

def has_correct_subject_omission_with_verb_conjugation(texts, max_errors):
    """æ£€æŸ¥è¥¿ç­ç‰™è¯­æ˜¯å¦æ­£ç¡®çœç•¥äººç§°ä¸»è¯­å¹¶ä½¿ç”¨æ­£ç¡®çš„åŠ¨è¯å˜ä½"""
    import re
    
    errors = []
    correct_examples = []
    
    # æ›´å…¨é¢çš„äººç§°ä»£è¯åˆ—è¡¨
    subject_pronouns = [
        r'\byo\b', r'\btÃº\b', r'\busted\b', r'\bÃ©l\b', r'\bella\b',
        r'\bnosotros\b', r'\bnosotras\b', r'\bvosotros\b', r'\bvosotras\b',
        r'\bustedes\b', r'\bellos\b', r'\bellas\b'
    ]
    
    # æ›´å…¨é¢çš„åŠ¨è¯å˜ä½æ¨¡å¼
    verb_patterns = [
        # seråŠ¨è¯
        r'\b(soy|eres|es|somos|sois|son)\b',
        # estaråŠ¨è¯
        r'\b(estoy|estÃ¡s|estÃ¡|estamos|estÃ¡is|estÃ¡n)\b',
        # teneråŠ¨è¯
        r'\b(tengo|tienes|tiene|tenemos|tenÃ©is|tienen)\b',
        # iråŠ¨è¯
        r'\b(voy|vas|va|vamos|vais|van)\b',
        # å¸¸è§è§„åˆ™åŠ¨è¯ç°åœ¨æ—¶å˜ä½ (-aråŠ¨è¯)
        r'\b\w+(o|as|a|amos|Ã¡is|an)\b',
        # å¸¸è§è§„åˆ™åŠ¨è¯ç°åœ¨æ—¶å˜ä½ (-er/-iråŠ¨è¯)
        r'\b\w+(o|es|e|emos|Ã©is|en)\b',
        # è¿‡å»æ—¶å˜ä½
        r'\b\w+(Ã©|aste|Ã³|amos|asteis|aron)\b',
        r'\b\w+(Ã­|iste|iÃ³|imos|isteis|ieron)\b',
        # ç‰¹å®šåŠ¨è¯ï¼ˆæ ¹æ®ä½ çš„æ–‡æœ¬ï¼‰
        r'\b(mantiene|mantienen|sorprende|sorprenden|fascina|fascinan)\b',
        r'\b(perturba|perturban|atrapa|atrapan|evoluciona|evolucionan)\b',
        # å½¢å®¹è¯ä½œè°“è¯­ï¼ˆä¸ser/estarè¿ç”¨ï¼‰
        r'\b(fascinante|perturbadora|impecable|intensa|magistral|inolvidable)\b'
    ]
    
    for text in texts:
        text = text.strip()
        if not text:
            continue
            
        # æŒ‰åˆ†å·åˆ†å‰²å¥å­åˆ†åˆ«æ£€æŸ¥
        sentences = [s.strip() for s in text.split(';')]
        
        for sentence in sentences:
            if not sentence:
                continue
                
            # è·³è¿‡çº¯ç²¹çš„åè¯çŸ­è¯­ï¼ˆå¦‚"Intriga constante"ï¼‰
            if len(sentence.split()) <= 2 and not any(re.search(pattern, sentence, re.IGNORECASE) for pattern in verb_patterns):
                # è¿™å¯èƒ½æ˜¯çœç•¥äº†åŠ¨è¯çš„åè¯çŸ­è¯­ï¼Œè§†ä¸ºæ­£ç¡®
                correct_examples.append(sentence[:30] + "...")
                continue
                
            # æ£€æŸ¥äººç§°ä»£è¯
            found_pronouns = []
            for pronoun_pattern in subject_pronouns:
                matches = re.findall(pronoun_pattern, sentence, re.IGNORECASE)
                if matches:
                    found_pronouns.extend(matches)
            
            if found_pronouns:
                errors.append(f"åŒ…å«äººç§°ä»£è¯: {', '.join(found_pronouns)} åœ¨ '{sentence}'")
            else:
                # æ£€æŸ¥åŠ¨è¯æˆ–å½¢å®¹è¯è°“è¯­
                has_verb_or_predicate = any(re.search(pattern, sentence, re.IGNORECASE) 
                                          for pattern in verb_patterns)
                
                if has_verb_or_predicate:
                    correct_examples.append(sentence[:30] + "...")
                else:
                    # å¦‚æœæ—¢æ²¡æœ‰äººç§°ä»£è¯ä¹Ÿæ²¡æœ‰åŠ¨è¯ï¼Œå¯èƒ½æ˜¯ä¸å®Œæ•´çš„å¥å­
                    if len(sentence.split()) > 2:  # åªå¯¹è¾ƒé•¿çš„å¥å­æŠ¥é”™
                        errors.append(f"ç¼ºå°‘åŠ¨è¯æˆ–è°“è¯­: '{sentence}'")
    
    total_errors = len(errors)
    
    if total_errors <= max_errors:
        if correct_examples:
            examples_str = "; ".join(correct_examples[:3])
            return 1, f"âœ… æ­£ç¡®çœç•¥äººç§°ä¸»è¯­ã€‚ç¤ºä¾‹: {examples_str}. é”™è¯¯æ•°: {total_errors}/{max_errors}."
        else:
            return 1, f"âœ… æœªå‘ç°äººç§°ä»£è¯é”™è¯¯ã€‚é”™è¯¯æ•°: {total_errors}/{max_errors}."
    else:
        error_summary = "; ".join(errors[:3])
        if len(errors) > 3:
            error_summary += f" ... (+{len(errors)-3} more)"
        return 0, f"âŒ äººç§°ä¸»è¯­çœç•¥é”™è¯¯: {error_summary}. å‘ç° {total_errors} ä¸ªé”™è¯¯ (æœ€å¤šå…è®¸: {max_errors})."
 
def has_correct_spanish_article_gender_agreement(texts, max_errors):
    """æ£€æŸ¥å† è¯ä¸åè¯æ€§æ•°ä¸€è‡´æ€§"""
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # ç¡®ä¿ texts æ˜¯åˆ—è¡¨æ ¼å¼
    if isinstance(texts, str):
        texts = [texts]
    elif not isinstance(texts, list):
        texts = [str(texts)]
    
    cleaned_up_texts = [clean_up_text(text) for text in texts]
    
    def check_article_noun_agreement(text):
        """æ£€æŸ¥å† è¯ä¸åè¯çš„æ€§æ•°ä¸€è‡´æ€§"""
        
        # ğŸ”§ æ‰©å±•çš„è¥¿ç­ç‰™è¯­åè¯æ€§åˆ«è¯å…¸
        noun_gender = {
            # === é˜³æ€§å•æ•° ===
            'pez': 'masc_sing', 'mar': 'masc_sing', 'tipo': 'masc_sing', 'viento': 'masc_sing',
            'cuerpo': 'masc_sing', 'resto': 'masc_sing', 'mundo': 'masc_sing', 'paisaje': 'masc_sing',
            'libro': 'masc_sing', 'papel': 'masc_sing', 'corazÃ³n': 'masc_sing', 'bolÃ­grafo': 'masc_sing',
            'cielo': 'masc_sing', 'lenguaje': 'masc_sing', 'hogar': 'masc_sing', 'dÃ­a': 'masc_sing',
            'problema': 'masc_sing', 'trabajo': 'masc_sing', 'tiempo': 'masc_sing', 'amor': 'masc_sing',
            'momento': 'masc_sing', 'deseo': 'masc_sing', 'chisme': 'masc_sing', 'alma': 'masc_sing',
            'cuidado': 'masc_sing', 'lugar': 'masc_sing', 'horizonte': 'masc_sing', 'hombre': 'masc_sing',
            'ocÃ©ano': 'masc_sing', 'elemento': 'masc_sing', 'aspecto': 'masc_sing', 'detalle': 'masc_sing',
            
            # === é˜´æ€§å•æ•° ===
            'persona': 'fem_sing', 'vida': 'fem_sing', 'comida': 'fem_sing', 'emociÃ³n': 'fem_sing',
            'casa': 'fem_sing', 'mesa': 'fem_sing', 'comunicaciÃ³n': 'fem_sing', 'palabra': 'fem_sing',
            'estrella': 'fem_sing', 'raÃ­z': 'fem_sing', 'mano': 'fem_sing', 'foto': 'fem_sing',
            'vez': 'fem_sing', 'gente': 'fem_sing', 'cosa': 'fem_sing', 'parte': 'fem_sing',
            'felicidad': 'fem_sing', 'libertad': 'fem_sing', 'importancia': 'fem_sing', 'historia': 'fem_sing',
            'decisiÃ³n': 'fem_sing', 'opiniÃ³n': 'fem_sing', 'biodiversidad': 'fem_sing', 'diversidad': 'fem_sing',
            'naturaleza': 'fem_sing', 'experiencia': 'fem_sing', 'existencia': 'fem_sing', 'salud': 'fem_sing',
            'belleza': 'fem_sing', 'variedad': 'fem_sing', 'celebraciÃ³n': 'fem_sing', 'tradiciÃ³n': 'fem_sing',
            'conexiÃ³n': 'fem_sing', 'sensaciÃ³n': 'fem_sing', 'admiraciÃ³n': 'fem_sing', 'reflexiÃ³n': 'fem_sing',
            # ğŸ†• ä»¥-eç»“å°¾çš„é˜´æ€§è¯
            'mente': 'fem_sing', 'noche': 'fem_sing', 'clase': 'fem_sing', 'base': 'fem_sing',
            'fase': 'fem_sing', 'carne': 'fem_sing', 'leche': 'fem_sing', 'fiebre': 'fem_sing',
            'suerte': 'fem_sing', 'muerte': 'fem_sing', 'fuente': 'fem_sing', 'corriente': 'fem_sing',
            
            # === é˜³æ€§å¤æ•° ===
            'peces': 'masc_plur', 'mares': 'masc_plur', 'tipos': 'masc_plur', 'vientos': 'masc_plur',
            'cuerpos': 'masc_plur', 'restos': 'masc_plur', 'mundos': 'masc_plur', 'paisajes': 'masc_plur',
            'libros': 'masc_plur', 'papeles': 'masc_plur', 'corazones': 'masc_plur', 'bolÃ­grafos': 'masc_plur',
            'cielos': 'masc_plur', 'lenguajes': 'masc_plur', 'hogares': 'masc_plur', 'dÃ­as': 'masc_plur',
            'problemas': 'masc_plur', 'trabajos': 'masc_plur', 'tiempos': 'masc_plur', 'amores': 'masc_plur',
            'momentos': 'masc_plur', 'deseos': 'masc_plur', 'chismes': 'masc_plur', 'hombres': 'masc_plur',
            'elementos': 'masc_plur', 'aspectos': 'masc_plur', 'detalles': 'masc_plur', 'ocÃ©anos': 'masc_plur',
            
            # === é˜´æ€§å¤æ•° ===
            'personas': 'fem_plur', 'vidas': 'fem_plur', 'comidas': 'fem_plur', 'emociones': 'fem_plur',
            'casas': 'fem_plur', 'mesas': 'fem_plur', 'comunicaciones': 'fem_plur', 'palabras': 'fem_plur',
            'estrellas': 'fem_plur', 'raÃ­ces': 'fem_plur', 'manos': 'fem_plur', 'fotos': 'fem_plur',
            'veces': 'fem_plur', 'gentes': 'fem_plur', 'cosas': 'fem_plur', 'partes': 'fem_plur',
            'mentes': 'fem_plur', 'noches': 'fem_plur', 'clases': 'fem_plur', 'historias': 'fem_plur',
            # ğŸ†• ä¿®å¤è¿™äº›å…³é”®è¯
            'decisiones': 'fem_plur', 'opiniones': 'fem_plur', 'tradiciones': 'fem_plur',
            'celebraciones': 'fem_plur', 'conexiones': 'fem_plur', 'sensaciones': 'fem_plur',
            'oportunidades': 'fem_plur', 'experiencias': 'fem_plur',
        }
        
        # æ­£ç¡®çš„å† è¯æ­é…
        correct_articles = {
            'masc_sing': ['el'],
            'fem_sing': ['la'], 
            'masc_plur': ['los'],
            'fem_plur': ['las']
        }
        
        errors = []
        correct_uses = []
        
        # æŸ¥æ‰¾æ‰€æœ‰å®šå† è¯+åè¯ç»„åˆ
        pattern = r'\b(el|la|los|las)\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+)\b'
        matches = re.finditer(pattern, text, re.IGNORECASE)
        
        for match in matches:
            article = match.group(1).lower()
            noun = match.group(2).lower()
            
            if noun in noun_gender:
                expected_gender = noun_gender[noun]
                correct_article_list = correct_articles[expected_gender]
                
                if article in correct_article_list:
                    correct_uses.append({
                        'combination': f"{article} {noun}",
                        'position': match.span(),
                        'type': 'correct_agreement'
                    })
                else:
                    # æ‰¾åˆ°æ­£ç¡®çš„å† è¯å»ºè®®
                    correct_article = correct_article_list[0]
                    gender_desc = expected_gender.replace('_', ' ')
                    errors.append({
                        'error': f"{article} {noun}",
                        'correct': f"{correct_article} {noun}",
                        'position': match.span(),
                        'description': f'Discordancia de gÃ©nero/nÃºmero: "{noun}" es {gender_desc}'
                    })
            else:
                # å¯¹äºè¯å…¸ä¸­æ²¡æœ‰çš„åè¯ï¼Œä½¿ç”¨æ”¹è¿›çš„å¯å‘å¼è§„åˆ™
                predicted_gender = predict_noun_gender(noun)
                if predicted_gender:
                    expected_articles = correct_articles[predicted_gender]
                    if article not in expected_articles:
                        correct_article = expected_articles[0]
                        errors.append({
                            'error': f"{article} {noun}",
                            'correct': f"{correct_article} {noun}",
                            'position': match.span(),
                            'description': f'Posible discordancia: "{noun}" probablemente es {predicted_gender.replace("_", " ")}'
                        })
                    else:
                        correct_uses.append({
                            'combination': f"{article} {noun}",
                            'position': match.span(),
                            'type': 'likely_correct'
                        })
        
        return len(errors), errors, len(correct_uses), correct_uses
    
    def predict_noun_gender(noun):
        """ğŸ”§ æ”¹è¿›çš„åŸºäºè¯å°¾é¢„æµ‹åè¯æ€§åˆ«ï¼ˆå¯å‘å¼è§„åˆ™ï¼‰"""
        noun = noun.lower()
        
        # ğŸ†• ç‰¹æ®Šçš„ä»¥-eç»“å°¾çš„é˜´æ€§è¯ï¼ˆæ‰©å±•åˆ—è¡¨ï¼‰
        feminine_e_endings = [
            'mente', 'gente', 'parte', 'noche', 'clase', 'base', 'fase', 'carne', 'leche', 'fiebre',
            'suerte', 'muerte', 'fuente', 'corriente', 'frente', 'llave', 'nave', 'nube', 'sede',
            'serie', 'superficie', 'especie', 'torre', 'sangre', 'costumbre', 'muchedumbre'
        ]
        
        if noun in feminine_e_endings:
            return 'fem_sing'
        
        # ğŸ†• ç‰¹æ®Šçš„ä»¥-aç»“å°¾çš„é˜³æ€§è¯
        masculine_a_endings = [
            'problema', 'sistema', 'tema', 'programa', 'drama', 'clima', 'idioma', 'planeta',
            'poeta', 'atleta', 'turista', 'artista', 'especialista', 'dentista', 'pianista'
        ]
        
        if noun in masculine_a_endings:
            return 'masc_sing'
        
        # ğŸ†• ä»¥-ionesç»“å°¾çš„éƒ½æ˜¯é˜´æ€§å¤æ•°ï¼ˆå…³é”®ä¿®å¤ï¼‰
        if noun.endswith('iones'):
            return 'fem_plur'
        
        # ğŸ†• ä»¥-iÃ³nç»“å°¾çš„éƒ½æ˜¯é˜´æ€§å•æ•°
        if noun.endswith('iÃ³n'):
            return 'fem_sing'
        
        # é˜´æ€§å¤æ•°è§„åˆ™
        if noun.endswith('as'):
            # æ£€æŸ¥æ˜¯å¦æ˜¯é˜³æ€§è¯çš„å¤æ•°å½¢å¼
            singular = noun[:-1]  # å»æ‰s
            if singular in masculine_a_endings:
                return 'masc_plur'
            return 'fem_plur'
        
        # ä»¥-esç»“å°¾çš„å¤æ•°
        if noun.endswith('es'):
            # å°è¯•è¿˜åŸå•æ•°å½¢å¼
            if len(noun) > 3:
                # å»æ‰-esï¼Œçœ‹æ˜¯å¦æ˜¯å·²çŸ¥çš„é˜´æ€§è¯
                singular_candidate = noun[:-2]
                if singular_candidate in feminine_e_endings:
                    return 'fem_plur'
            return 'masc_plur'
        
        # é˜³æ€§å¤æ•°è§„åˆ™
        if noun.endswith('os'):
            return 'masc_plur'
        
        # é˜´æ€§å•æ•°è§„åˆ™
        if noun.endswith(('dad', 'tad', 'ez', 'is', 'sis', 'tis')):
            return 'fem_sing'
        
        # ä»¥-aç»“å°¾çš„è¯ï¼ˆæ’é™¤å·²çŸ¥é˜³æ€§è¯ï¼‰
        if noun.endswith('a') and noun not in masculine_a_endings:
            return 'fem_sing'
        
        # é˜³æ€§å•æ•°è§„åˆ™
        if noun.endswith(('o', 'r', 'l', 'n', 's', 'j', 'x')):
            return 'masc_sing'
        
        # ä»¥-eç»“å°¾çš„è¯ï¼ˆæ’é™¤å·²çŸ¥é˜´æ€§è¯ï¼‰é»˜è®¤ä¸ºé˜³æ€§
        if noun.endswith('e') and noun not in feminine_e_endings:
            return 'masc_sing'
        
        return None  # æ— æ³•é¢„æµ‹
    
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬ä¸­çš„é”™è¯¯
    total_errors = 0
    all_errors = []
    all_correct = []
    
    for text in cleaned_up_texts:
        error_count, errors, correct_count, correct_uses = check_article_noun_agreement(text)
        total_errors += error_count
        all_errors.extend(errors)
        all_correct.extend(correct_uses)
    
    # å»é‡å¤„ç†
    unique_errors = []
    seen_errors = set()
    for error in all_errors:
        error_key = f"{error['error']}"
        if error_key not in seen_errors:
            seen_errors.add(error_key)
            unique_errors.append(error)
    
    total_errors = len(unique_errors)
    
    # æ„å»ºç»“æœä¿¡æ¯
    if total_errors <= max_errors:
        correct_examples = [f"'{correct['combination']}'" for correct in all_correct[:5]]
        correct_info = f"Found {len(all_correct)} correct article-noun agreements"
        if correct_examples:
            correct_info += f": {', '.join(correct_examples)}"
            if len(all_correct) > 5:
                correct_info += f" (+{len(all_correct)-5} more)"
        
        error_info = ""
        if unique_errors:
            error_examples = [f"'{err['error']}' â†’ '{err['correct']}'" for err in unique_errors[:2]]
            error_info = f" Minor errors: {'; '.join(error_examples)}"
            if len(unique_errors) > 2:
                error_info += f" (+{len(unique_errors)-2} more)"
        
        return 1, f"âœ… Spanish article-noun gender agreement is correct. {correct_info}. Found {total_errors} errors (allowed: {max_errors}).{error_info} Requirement met."
    else:
        error_details = [f"'{error['error']}' â†’ '{error['correct']}' ({error['description']})" for error in unique_errors[:3]]
        error_summary = "; ".join(error_details)
        if len(unique_errors) > 3:
            error_summary += f" ... (+{len(unique_errors)-3} more)"
        
        return 0, f"âŒ Found {total_errors} article-noun gender agreement errors (allowed: {max_errors}). Errors: {error_summary}. Does not meet the requirement."

def has_definite_article_noun_combinations(texts, min_count, max_count=None, original_text=None):
    """æ£€æŸ¥æ¯ä¸ªå¥å­ä¸­å®šå† è¯+åè¯ç»„åˆçš„æ•°é‡"""
    import re
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    if max_count is None:
        max_count = min_count
    
    if isinstance(texts, str):
        texts = [texts]
    elif not isinstance(texts, list):
        texts = [str(texts)]
    
    def get_target_nouns():
        """è·å–ç›®æ ‡åè¯åˆ—è¡¨"""
        # ğŸ”§ ç¡®ä¿åŒ…å«æ‰€æœ‰åŸæ–‡åè¯
        return {
            'pez', 'peces', 'mar', 'mares', 'persona', 'personas', 'tipo', 'tipos',
            'viento', 'vientos', 'emociÃ³n', 'emociones', 'cuerpo', 'cuerpos',
            'resto', 'restos', 'vida', 'vidas', 'mundo', 'mundos', 'comida', 'comidas',
            'paisaje', 'paisajes', 'vez', 'veces', 'gente', 'chisme', 'chismes', 
            'amor', 'cuidado', 'cuidados', 'trabajo', 'trabajos'
        }
    
    def count_combinations(text):
        """ç»Ÿè®¡ç»„åˆæ•°é‡"""
        target_nouns = get_target_nouns()
        
        # ğŸ”§ ä¸¥æ ¼æ’é™¤éåŸæ–‡åè¯
        excluded_nouns = {
            'libertad', 'diversidad', 'elementos', 'aspectos', 'experiencias',
            'existencia', 'alma', 'felicidad', 'salud', 'bienestar', 'camino',
            'equilibrio', 'naturaleza', 'fuerzas', 'oportunidades', 'placeres',
            'opiniones', 'entorno', 'mesa', 'culturas', 'tradiciones', 'celebraciÃ³n',
            'sabores', 'variedad', 'riqueza', 'tranquilidad', 'reflexiÃ³n', 'momento',
            'ojos', 'hogar', 'rincÃ³n', 'admiraciÃ³n', 'detalle', 'sensaciÃ³n', 'frescura',
            'vecindario', 'orilla', 'oportunidad'
        }
        
        combinations = []
        used_positions = set()
        
        # ğŸ”§ åŒ¹é…æ¨¡å¼
        pattern = r'\b(del|al|el|la|los|las)\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+)\b'
        
        for match in re.finditer(pattern, text, re.IGNORECASE):
            start = match.start()
            article = match.group(1).lower()
            noun = match.group(2).lower()
            
            # ğŸ”§ ä¸‰é‡æ£€æŸ¥
            if (noun in target_nouns and 
                noun not in excluded_nouns and 
                start not in used_positions):
                
                combinations.append(f"{article} {noun}")
                used_positions.add(start)
        
        return len(combinations), combinations
    
    # æ£€æŸ¥æ¯ä¸ªå¥å­
    sentence_details = []
    all_pass = True
    
    for i, sentence in enumerate(texts):
        sentence = sentence.strip()
        count, combos = count_combinations(sentence)
        
        meets_req = min_count <= count <= max_count
        if not meets_req:
            all_pass = False
        
        status = "âœ…" if meets_req else "âŒ"
        combo_info = f"({', '.join(combos)})" if combos else "(none)"
        
        sentence_details.append(f"Sentence {i+1}: {count} combinations {status} {combo_info}")
    
    detail_info = " | ".join(sentence_details)
    
    source_info = "from original text" if original_text else "from comprehensive noun list"
    
    if all_pass:
        return 1, f"âœ… All {len(texts)} sentences contain {min_count}-{max_count} definite article+noun combinations {source_info}. {detail_info}"
    else:
        failed = sum(1 for sentence in texts if not (min_count <= count_combinations(sentence.strip())[0] <= max_count))
        return 0, f"âŒ {failed}/{len(texts)} sentences do NOT meet the requirement of {min_count}-{max_count} definite article+noun combinations {source_info}. {detail_info}"



def has_total_definite_article_noun_combinations(texts, min_count, max_count=None):
    """æ£€æŸ¥æ•´ç¯‡æ–‡ç« ä¸­å®šå† è¯+åè¯ç»„åˆçš„æ€»æ•°é‡"""
    import re
    
    def clean_up_text(text):
        return text.strip()
    
    if not texts:
        return 0, f"âŒ No text provided"
    
    # è®¾ç½®é»˜è®¤æœ€å¤§å€¼
    if max_count is None:
        max_count = min_count
    
    # ç¡®ä¿ texts æ˜¯åˆ—è¡¨æ ¼å¼
    if isinstance(texts, str):
        texts = [texts]
    elif not isinstance(texts, list):
        texts = [str(texts)]
    
    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ä¸ºä¸€ä¸ªæ•´ä½“
    full_text = " ".join([clean_up_text(text) for text in texts])
    
    def count_definite_article_noun_combinations(text):
        """ç»Ÿè®¡æ–‡æœ¬ä¸­å®šå† è¯+åè¯ç»„åˆçš„æ•°é‡"""
        
        # ğŸ†• æ‰©å±•çš„æ’é™¤è¯æ±‡åˆ—è¡¨
        excluded_words = {
            # åŠ¨è¯ (å¤§å¹…æ‰©å±•)
            'ver', 'ser', 'estar', 'hacer', 'tener', 'decir', 'ir', 'venir', 'dar', 'saber',
            'poder', 'querer', 'poner', 'parecer', 'seguir', 'encontrar', 'llamar', 'volver',
            'salir', 'llegar', 'pasar', 'deber', 'dejar', 'sentir', 'quedar', 'creer',
            'hablar', 'llevar', 'comenzar', 'empezar', 'terminar', 'acabar', 'disfrutar',
            'explorar', 'observar', 'reflexionar', 'mantener', 'cuidar', 'afectar', 'influir',
            'ofrecer', 'propagar', 'convertir', 'definir', 'enriquecer', 'fascinar', 'inspirar',
            'extender', 'relajar', 'liberar', 'buscar', 'nadar', 'soplar', 'crear', 'unir',
            'desplegar', 'albergar', 'circular', 'proporcionar', 'necesitar', 'alcanzar',
            'valorar', 'permitir', 'simbolizar', 'reflejar', 'recordar', 'acariciar',
            'despertar', 'eclipsar', 'conocer', 'explorar', 'transformar', 'concretar',
            'resonar', 'vibrar', 'trasciender', 'entrelazar', 'calmar', 'brillar',
            
            # å½¢å®¹è¯ (å¤§å¹…æ‰©å±•)
            'vasto', 'grande', 'pequeÃ±o', 'hermoso', 'delicioso', 'profundo', 'sereno',
            'misterioso', 'Ãºnico', 'constante', 'impredecible', 'esencial', 'sobresaliente',
            'natural', 'fundamental', 'acuÃ¡tico', 'querido', 'fascinante', 'ajeno',
            'suave', 'libre', 'feliz', 'brillante', 'ordinario', 'diferente', 'raro',
            'lento', 'pleno', 'inolvidable', 'diverso', 'propio', 'compartido', 'intangible',
            'invisible', 'etÃ©reo', 'universal', 'mÃ¡gico', 'simple', 'verdadero', 'humano',
            
            # å…¶ä»–éœ€è¦æ’é™¤çš„è¯
            'momento', 'ojos', 'rincÃ³n', 'hogar', 'admiraciÃ³n', 'detalle', 'sensaciÃ³n',
            'frescura', 'objeto', 'rumores', 'placer', 'compaÃ±Ã­a', 'oportunidades',
            'lugares', 'fascinantes', 'historia', 'emociÃ³n', 'vez', 'dÃ­a', 'vida',
            'tiempo', 'lugar', 'forma', 'manera', 'parte', 'caso', 'ejemplo'
        }
        
        combinations = []
        processed_spans = []  # è®°å½•å·²å¤„ç†çš„æ–‡æœ¬èŒƒå›´
        
        # ğŸ”§ ç»Ÿä¸€çš„æ¨¡å¼åŒ¹é…ï¼šæ‰€æœ‰å®šå† è¯å½¢å¼
        all_patterns = [
            # ç¼©å†™å½¢å¼
            (r'\b(del|al)\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+)\b', 'contraction'),
            # æ ‡å‡†å®šå† è¯
            (r'\b(el|la|los|las)\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼A-ZÃÃ‰ÃÃ“ÃšÃ‘Ãœ]+)\b', 'standard'),
        ]
        
        for pattern, pattern_type in all_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            
            for match in matches:
                start, end = match.span()
                article = match.group(1).lower()
                noun = match.group(2).lower()
                
                # ğŸ”§ æ’é™¤åŠ¨è¯ã€å½¢å®¹è¯ç­‰
                if noun in excluded_words:
                    continue
                
                # ğŸ”§ æ£€æŸ¥æ˜¯å¦ä¸å·²å¤„ç†çš„èŒƒå›´é‡å 
                overlapped = False
                for proc_start, proc_end in processed_spans:
                    if not (end <= proc_start or start >= proc_end):
                        overlapped = True
                        break
                
                if not overlapped:
                    processed_spans.append((start, end))
                    combinations.append(f"{article} {noun}")
        
        return len(combinations), combinations
    
    # ç»Ÿè®¡æ•´ç¯‡æ–‡ç« çš„ç»„åˆæ•°é‡
    total_count, all_combinations = count_definite_article_noun_combinations(full_text)
    
    # æ£€æŸ¥æ˜¯å¦æ»¡è¶³è¦æ±‚
    meets_requirement = min_count <= total_count <= max_count
    
    # ğŸ”§ æ„å»ºè¯¦ç»†ä¿¡æ¯
    if all_combinations:
        # å»é‡å¹¶ä¿æŒé¡ºåº
        unique_combinations = list(dict.fromkeys(all_combinations))
        display_combinations = unique_combinations[:8]  # æ˜¾ç¤ºå‰8ä¸ª
        combo_info = f"Found combinations: {', '.join(display_combinations)}"
        if len(unique_combinations) > 8:
            combo_info += f" (+{len(unique_combinations)-8} more)"
    else:
        combo_info = "No valid combinations found"
    
    # è¿”å›ç»“æœ
    if meets_requirement:
        status = "âœ…"
        return 1, f"âœ… Article contains {total_count} definite article+noun combinations (required: {min_count}-{max_count}). {combo_info}. Requirement met."
    else:
        status = "âŒ"
        if total_count < min_count:
            reason = f"Too few combinations ({total_count} < {min_count})"
        else:
            reason = f"Too many combinations ({total_count} > {max_count})"
        
        return 0, f"âŒ Article contains {total_count} definite article+noun combinations (required: {min_count}-{max_count}). {reason}. {combo_info}. Does not meet the requirement."




if __name__ == "__main__":
    text = [
"1Âª planta\nEstudio Creativo\nHorario: de siete de la maÃ±ana a siete de la tarde\nTelÃ©fono: 555 123 4567\nEspacio para diseÃ±o grÃ¡fico y ediciÃ³n de contenido digital.",
"2Âª planta\nEstudio Legal\nHorario: de ocho de la maÃ±ana a seis de la tarde\nTelÃ©fono: 555 234 5678\nAsesorÃ­a jurÃ­dica y consultorÃ­a para empresas y particulares.",
"3Âª planta\nEstudio Contable\nHorario: de nueve de la maÃ±ana a cinco de la tarde\nTelÃ©fono: 555 345 6789\nServicios de contabilidad, impuestos y gestiÃ³n financiera.",
 "4Âª planta\nEstudio Wellness\nHorario: de diez de la maÃ±ana a seis de la tarde\nTelÃ©fono: 555 456 7890\nConsultas de bienestar, coaching y talleres de relajaciÃ³n."
]
    text = [
 "Xiao Ming: Hola, soy Xiao Ming, el repartidor de leche. Â¿PodrÃ­a confirmarme la direcciÃ³n exacta para la entrega, por favor?",
 "Cliente: Claro, mi direcciÃ³n es Calle Primavera nÃºmero 28, Unidad 3, Piso 5.",
 "Xiao Ming: Muchas gracias. Â¿Hay alguien en casa ahora para recibir la leche?",
 "Cliente: SÃ­, estoy en casa y puedo recibir la entrega.",
 "Xiao Ming: Perfecto, Â¿la fecha de entrega es hoy, 12 de junio, verdad?",
 "Cliente: SÃ­, la entrega es para hoy, 12 de junio. Â¡Gracias por confirmar!"
]
    print(has_correct_spanish_date_format(text,0))
    # print(has_correct_spanish_phone_format(text,0))