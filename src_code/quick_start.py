#!/usr/bin/env python3
"""
OG_meeseeks å¿«é€Ÿå¯åŠ¨è„šæœ¬
ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œç±»ä¼¼åŸå§‹evaluate.pyçš„ç›´æ¥è¿è¡Œæ–¹å¼
"""

import sys
import subprocess
import os

def install_requirements():
    """è‡ªåŠ¨å®‰è£…requirements.txtä¸­çš„ä¾èµ–åŒ…"""
    requirements_file = os.path.join(os.path.dirname(__file__), 'requirements.txt')

    if os.path.exists(requirements_file):
        print("ğŸ”§ æ£€æŸ¥å¹¶å®‰è£…ä¾èµ–åŒ…...")
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", "-r", requirements_file, "-q"
            ])
            print("âœ… ä¾èµ–åŒ…æ£€æŸ¥å®Œæˆ!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ å®‰è£…ä¾èµ–åŒ…æ—¶å‡ºé”™: {e}")

# åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰å…ˆå®‰è£…ä¾èµ–
install_requirements()

import json
import time
import requests
from process_corresponding_parts import extract_content
from process_evaluation import process_all_items
from multi_round_template_added import multi_round_template_added
from LLM_APIs.qwen_api import set_qwen_url
from LLM_APIs.qwen_coder_api import set_qwen_coder_url
from LLM_APIs.tested_model_api import set_tested_model_url, call_tested_model


def test_single_api(url, api_name, test_prompt="Hello"):
    """æµ‹è¯•å•ä¸ªAPIæ˜¯å¦å¯ç”¨"""
    print(f"ğŸ”— Testing {api_name}: {url}")

    payload = {
        "prompt": test_prompt,
        "max_new_tokens": 50,
        "temperature": 0.00,
        "top_k": 1
    }
    headers = {
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=1800)

        if response.status_code == 200:
            try:
                response_json = response.json()
                if 'completions' in response_json and response_json['completions']:
                    print(f"âœ… {api_name} is working")
                    return True
                else:
                    print(f"âŒ {api_name} returned invalid format")
                    return False
            except json.JSONDecodeError:
                print(f"âŒ {api_name} returned non-JSON response")
                return False
        else:
            print(f"âŒ {api_name} returned HTTP {response.status_code}")
            return False

    except requests.exceptions.ConnectionError:
        print(f"âŒ {api_name} connection failed")
        return False
    except requests.exceptions.Timeout:
        print(f"âŒ {api_name} timeout")
        return False
    except Exception as e:
        print(f"âŒ {api_name} error: {e}")
        return False


def test_all_apis(qwen_url, qwen_coder_url, tested_model_url):
    """æµ‹è¯•æ‰€æœ‰ä¸‰ä¸ªAPIæ˜¯å¦å¯ç”¨"""
    print("ğŸ§ª Testing API connections...")
    print("=" * 50)

    results = {}
    results['qwen'] = test_single_api(qwen_url, "Qwen API")
    results['qwen_coder'] = test_single_api(qwen_coder_url, "Qwen Coder API")
    results['tested_model'] = test_single_api(tested_model_url, "Tested Model API")

    print("=" * 50)

    all_working = all(results.values())
    if all_working:
        print("âœ… All APIs are working properly!")
        return True
    else:
        print("âŒ Some APIs are not working:")
        for api_name, status in results.items():
            status_icon = "âœ…" if status else "âŒ"
            print(f"   {status_icon} {api_name}: {'Working' if status else 'Failed'}")

        print("\nğŸ’¡ Please check:")
        print("   - API services are running")
        print("   - URLs are correct")
        print("   - Network connectivity")
        print("   - Firewall settings")

        user_input = input("\nâ“ Continue anyway? (y/N): ").strip().lower()
        return user_input in ['y', 'yes']

# é»˜è®¤é…ç½® - åŸºäºåŸå§‹evaluate.py
BATCH_SIZE = 500
ROUNDS = 2
FILE_PATH = ""

# API URLs - åŸºäºåŸå§‹evaluate.py
QWEN_URL = "http://10.164.51.197:8080"
QWEN_CODER_URL = "http://10.166.176.56:8080"
TESTED_MODEL_URL = "http://10.164.51.197:8080"  # é»˜è®¤ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹

def process_in_batches(data, batch_size=BATCH_SIZE):
    """æ‰¹é‡å¤„ç†æ•°æ®ï¼Œè°ƒç”¨è¢«æµ‹æ¨¡å‹è·å–å“åº”"""
    total_items = len(data)
    for batch_start in range(0, total_items, batch_size):
        batch_end = min(batch_start + batch_size, total_items)
        current_batch = data[batch_start:batch_end]

        # Print processing progress
        print(f"ğŸ“Š Processing items {batch_start}-{batch_end-1} out of {total_items} total items...")

        try:
            # Batch get questions and call model
            batch_questions = [item["question"] for item in current_batch]
            batch_responses = call_tested_model(batch_questions)

            # Assign responses back to data items
            for item, response in zip(current_batch, batch_responses):
                item["model_response"] = response

        except Exception as e:
            print(f"âŒ Error occurred while processing batch {batch_start}-{batch_end-1}: {str(e)}")
            print("âš ï¸  Setting empty responses for failed batch...")
            # ç¡®ä¿å³ä½¿APIè°ƒç”¨å¤±è´¥ï¼Œä¹Ÿç»™æ¯ä¸ªitemæ·»åŠ model_responseå­—æ®µ
            for item in current_batch:
                if "model_response" not in item:
                    item["model_response"] = ""  # è®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œé¿å…åç»­KeyError

def iferror(item):
    """æ£€æŸ¥æ˜¯å¦æœ‰è¯„ä¼°é”™è¯¯"""
    for subq in item["sub_questions"]:
        if subq["eval_result"] == 0:
            return True
    return False

def fix_json_data(data):
    """ä¿®å¤JSONæ•°æ®ç»“æ„"""
    for item in data:
        if "json_schema" in item:
            og_subqs = [
                {
                    "point_id": 0,
                    "question": "Does it meet schema requirements",
                    "rule": "SCHEMA:json_schema",
                    "dep": [],
                    "è¢«ä¾èµ–": False,
                    "èƒ½åŠ›é¡¹": "JSON"
                }]
            for subq in item["sub_questions"]:
                if subq["point_id"] > 0:
                    og_subqs.append(subq)
            item["sub_questions"] = og_subqs

    return data

if __name__ == "__main__":
    print("ğŸš€ OG_meeseeks å¿«é€Ÿå¯åŠ¨")
    print("=" * 50)

    # è®¾ç½®API URLs
    set_qwen_url(QWEN_URL)
    set_qwen_coder_url(QWEN_CODER_URL)
    set_tested_model_url(TESTED_MODEL_URL)

    print(f"ğŸ”§ é…ç½®ä¿¡æ¯:")
    print(f"   - Qwen URL: {QWEN_URL}")
    print(f"   - Qwen Coder URL: {QWEN_CODER_URL}")
    print(f"   - Tested Model URL: {TESTED_MODEL_URL}")
    print(f"   - Collecting Batch Size: {COLLECTING_BATCH_SIZE}")
    print(f"   - Processing Batch Size: {PROCESSING_BATCH_SIZE}")
    print(f"   - Rounds: {ROUNDS}")
    print(f"   - Data Path: {FILE_PATH}")
    print()

    # æµ‹è¯•APIè¿æ¥
    if not test_all_apis(QWEN_URL, QWEN_CODER_URL, TESTED_MODEL_URL):
        print("ğŸ›‘ APIæµ‹è¯•å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        exit(1)

    print()  # æ·»åŠ ç©ºè¡Œåˆ†éš”

    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(FILE_PATH):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {FILE_PATH}")
        print("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æˆ–ä¿®æ”¹ FILE_PATH å˜é‡")
        print("ğŸ’¡ æˆ–è€…ä½¿ç”¨ run_with_defaults.py è„šæœ¬æŒ‡å®šè‡ªå®šä¹‰è·¯å¾„")
        exit(1)

    # åŠ è½½æ•°æ®
    print(f"ğŸ“‚ Loading data from: {FILE_PATH}")
    with open(FILE_PATH, "r", encoding="utf-8") as f:
        current_data = json.load(f)

    # ä¿å­˜åŸå§‹é—®é¢˜
    for item in current_data:
        item["og_question"] = item["question"]

    print(f"ğŸ“Š Loaded {len(current_data)} items")
    print("=" * 80)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("evaluation_results", exist_ok=True)

    # å¤šè½®è¯„ä¼°
    for round_num in range(ROUNDS):
        print(f"ğŸš€ Starting Round {round_num + 1} Evaluation")
        print("=" * 60)

        # ç¬¬ä¸€è½®ä¹‹åï¼Œåªå¤„ç†æœ‰é”™è¯¯çš„é¡¹ç›®
        if round_num != 0:
            current_data = [item for item in current_data if iferror(item)]
            current_data = multi_round_template_added(current_data)
            current_data = fix_json_data(current_data)
            print(f"ğŸ“Š Processing {len(current_data)} items with errors from previous round")

        if not current_data:
            print("âœ… No items to process in this round. All evaluations passed!")
            break

        print("ğŸ“ Getting model responses for evaluation...")
        process_in_batches(current_data)

        # å¼€å§‹è¯„ä¼°
        og_start_time = time.time()
        print(f"ğŸ”„ Round {round_num + 1} Processing Started")

        # æ­¥éª¤1ï¼šæå–å¯¹åº”éƒ¨åˆ†
        start_time = time.time()
        print("ğŸ” Step 1: Extracting corresponding parts from all responses...")
        current_data = extract_content(current_data)
        print("âœ… Corresponding parts extraction completed successfully")
        end_time = time.time()
        print(f"â±ï¸  Time taken: {end_time - start_time:.2f} seconds")
        print()

        # æ­¥éª¤2ï¼šå¤„ç†å’Œè¯„ä¼°
        start_time = time.time()
        print("ğŸ” Step 2: Processing and evaluating all items...")
        current_data = process_all_items(current_data)
        print("âœ… Item processing and evaluation completed successfully")
        end_time = time.time()
        print(f"â±ï¸  Time taken: {end_time - start_time:.2f} seconds")
        print()

        total_time = end_time - og_start_time
        print("=" * 60)
        print(f"ğŸ‰ Round {round_num + 1} Completed Successfully!")
        print(f"â±ï¸  Total round time: {total_time:.2f} seconds")
        print("=" * 60)

        # ä¿å­˜ç»“æœ
        output_file = f"evaluation_results/round_{round_num + 1}.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(current_data, f, ensure_ascii=False, indent=4)
        print(f"ğŸ’¾ Results saved to: {output_file}")
        print()

        # ç»Ÿè®¡æœ¬è½®ç»“æœ
        total_items = len(current_data)
        error_items = len([item for item in current_data if iferror(item)])
        success_items = total_items - error_items
        print(f"ğŸ“ˆ Round {round_num + 1} Statistics:")
        print(f"   - Total items: {total_items}")
        print(f"   - Successful items: {success_items}")
        print(f"   - Items with errors: {error_items}")
        print(f"   - Success rate: {success_items/total_items*100:.2f}%")
        print()

    print("ğŸŠ All rounds completed successfully!")
